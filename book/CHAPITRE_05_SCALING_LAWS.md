# CHAPITRE 5 : SCALING LAWS DES LLMs
## Les Lois Secr√®tes qui Gouvernent l'IA

> *"Give me a bigger GPU and more data, and I'll give you a better model. That's not science, that's a scaling law."*
> ‚Äî Jared Kaplan, OpenAI (2020)

---

## üí¨ Dialogue d'Introduction : La D√©couverte

**Alice** : Bob, j'ai une question bizarre. Pourquoi GPT-4 est meilleur que GPT-3 ? C'est juste parce qu'il est plus grand ?

**Bob** : Excellente intuition ! Mais c'est plus subtil que √ßa. Il y a des **lois math√©matiques** qui pr√©disent exactement comment la performance √©volue avec la taille.

**Alice** : Des lois ? Genre comme la gravit√© en physique ?

**Bob** : Exactement ! Les **Scaling Laws**. En 2020, des chercheurs d'OpenAI ont d√©couvert que la performance des LLMs suit des √©quations simples en fonction de trois variables :
1. **N** : Nombre de param√®tres (taille du mod√®le)
2. **D** : Quantit√© de donn√©es d'entra√Ænement
3. **C** : Compute (FLOPs utilis√©s)

**Alice** : Et √ßa pr√©dit quoi ?

**Bob** : Que si tu doubles le compute, la loss diminue de X%. Si tu doubles les param√®tres, elle diminue de Y%. C'est pr√©visible comme une horloge !

**Alice** : Donc... on pourrait pr√©dire GPT-5 avant m√™me de l'entra√Æner ?

**Bob** : Bingo ! Et c'est exactement ce qu'OpenAI, DeepMind et Anthropic font. Ils **planifient** les mod√®les futurs en utilisant les scaling laws. üìà

**Alice** : Attends... √ßa veut dire que l'IA devient meilleure de mani√®re **pr√©visible** ?

**Bob** : Oui. Et √ßa change TOUT. Viens, je te montre les √©quations qui ont boulevers√© l'industrie.

---

## 5.1 Introduction : Pourquoi les Scaling Laws Comptent

### üìú Anecdote Historique : La D√©couverte de 2020

**Janvier 2020**, OpenAI. Jared Kaplan et son √©quipe entra√Ænent des centaines de mod√®les de tailles diff√©rentes (de 1M √† 1.5B param√®tres) pour r√©pondre √† une question simple :

> *"Si on veut un mod√®le 10x meilleur, faut-il 10x plus de param√®tres ? 10x plus de donn√©es ? 10x plus de compute ?"*

Pendant des mois, ils tracent des courbes. Et soudain : **les courbes sont des lignes droites** en √©chelle log-log ! ü§Ø

Leur paper [*"Scaling Laws for Neural Language Models"*](https://arxiv.org/abs/2001.08361) r√©v√®le :
- La loss suit des **power laws** (lois de puissance)
- La performance est **pr√©visible** sur 6 ordres de magnitude
- On peut **extrapoler** : si un mod√®le 1B fonctionne comme pr√©vu, un mod√®le 100B le fera aussi

**Impact imm√©diat** :
- OpenAI d√©cide d'investir massivement dans GPT-3 (175B)
- Google cr√©e PaLM (540B)
- DeepMind construit Chinchilla
- Tous parient sur le scaling ‚Üí √ßa marche !

---

### üéØ Ce Que Vous Allez Apprendre

- **Lois empiriques** : Les √©quations qui pr√©disent la performance
- **Compute optimal** : Comment allouer le budget entre param√®tres et donn√©es
- **Chinchilla scaling** : La r√©volution 2022 (param√®tres ‚â† tout !)
- **Fronti√®res actuelles** : Jusqu'o√π peut-on scaler ?
- **Pr√©dictions** : GPT-5, 6, 7... o√π allons-nous ?

---

## 5.2 Les Lois de Kaplan (2020) : La D√©couverte Originale

### 5.2.1 Les Trois Scaling Laws

**Loi #1 : Scaling avec les Param√®tres (N)**

```
L(N) = (Nc / N)^Œ±N

o√π:
- L : Loss (perplexit√©)
- N : Nombre de param√®tres
- Nc ‚âà 8.8 √ó 10^13 (constante empirique)
- Œ±N ‚âà 0.076 (exposant)
```

**Interpr√©tation** : Si tu **doubles** les param√®tres, la loss diminue de ~5%.

**Exemple concret** :
- GPT-2 (1.5B params) : Loss ‚âà 3.0
- GPT-3 (175B params, 117x plus grand) : Loss ‚âà 2.0
- R√©duction : **33%** (pr√©dit : 32% ‚úÖ)

---

**Loi #2 : Scaling avec les Donn√©es (D)**

```
L(D) = (Dc / D)^Œ±D

o√π:
- D : Nombre de tokens d'entra√Ænement
- Dc ‚âà 5.4 √ó 10^13
- Œ±D ‚âà 0.095
```

**Interpr√©tation** : Si tu **doubles** les donn√©es, la loss diminue de ~6.5%.

---

**Loi #3 : Scaling avec le Compute (C)**

```
L(C) = (Cc / C)^Œ±C

o√π:
- C : Compute total (PetaFLOP/s-days)
- Cc ‚âà 3.1 √ó 10^8
- Œ±C ‚âà 0.050
```

**Interpr√©tation** : Si tu **doubles** le compute, la loss diminue de ~3.5%.

---

### üí¨ Dialogue : Comprendre les Power Laws

**Alice** : Bob, ces √©quations... elles disent que plus = mieux, c'est tout ?

**Bob** : Non ! Elles disent **combien** mieux. Par exemple :
- 10x plus de param√®tres ‚Üí 12% de r√©duction de loss
- 100x plus de param√®tres ‚Üí 24% de r√©duction
- 1000x plus de param√®tres ‚Üí 36% de r√©duction

**Alice** : Donc les gains **ralentissent** ?

**Bob** : Exactement ! C'est une **loi de puissance** avec exposant < 1. Les gains sont **logarithmiques** :
- Passer de 1B √† 10B : gros gain
- Passer de 100B √† 1000B : gain plus petit
- Mais gain quand m√™me !

**Alice** : √áa veut dire qu'il y a une limite ?

**Bob** : Oui et non. Th√©oriquement, tu peux toujours am√©liorer. Pratiquement, √† un moment le co√ªt devient prohibitif pour des gains marginaux.

---

### 5.2.2 Visualisation des Scaling Laws

**Code pour tracer les scaling laws**

```python
import numpy as np
import matplotlib.pyplot as plt

def kaplan_loss_params(N, Nc=8.8e13, alpha=0.076):
    """
    Loi de scaling avec les param√®tres (Kaplan et al. 2020)

    Args:
        N: Nombre de param√®tres
        Nc: Constante de scaling
        alpha: Exposant

    Returns:
        Loss pr√©dite
    """
    return (Nc / N) ** alpha

def kaplan_loss_data(D, Dc=5.4e13, alpha=0.095):
    """
    Loi de scaling avec les donn√©es
    """
    return (Dc / D) ** alpha

def kaplan_loss_compute(C, Cc=3.1e8, alpha=0.050):
    """
    Loi de scaling avec le compute
    """
    return (Cc / C) ** alpha

# G√©n√©rer des mod√®les de diff√©rentes tailles
model_sizes = np.logspace(6, 12, 100)  # 1M √† 1T param√®tres
data_sizes = np.logspace(9, 13, 100)   # 1B √† 10T tokens
compute_sizes = np.logspace(18, 24, 100)  # PetaFLOPs

# Calculer les losses
losses_params = kaplan_loss_params(model_sizes)
losses_data = kaplan_loss_data(data_sizes)
losses_compute = kaplan_loss_compute(compute_sizes)

# Plot
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Scaling avec param√®tres
axes[0].loglog(model_sizes, losses_params, 'b-', linewidth=2)
axes[0].scatter([1.5e9, 175e9], [kaplan_loss_params(1.5e9), kaplan_loss_params(175e9)],
                c='red', s=100, zorder=5, label='GPT-2, GPT-3')
axes[0].set_xlabel('Nombre de Param√®tres', fontsize=12)
axes[0].set_ylabel('Loss', fontsize=12)
axes[0].set_title('Scaling Law: Param√®tres', fontsize=14)
axes[0].grid(True, alpha=0.3)
axes[0].legend()

# Scaling avec donn√©es
axes[1].loglog(data_sizes, losses_data, 'g-', linewidth=2)
axes[1].set_xlabel('Tokens d\'entra√Ænement', fontsize=12)
axes[1].set_ylabel('Loss', fontsize=12)
axes[1].set_title('Scaling Law: Donn√©es', fontsize=14)
axes[1].grid(True, alpha=0.3)

# Scaling avec compute
axes[2].loglog(compute_sizes, losses_compute, 'r-', linewidth=2)
axes[2].set_xlabel('Compute (FLOPs)', fontsize=12)
axes[2].set_ylabel('Loss', fontsize=12)
axes[2].set_title('Scaling Law: Compute', fontsize=14)
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('scaling_laws_kaplan.png', dpi=300, bbox_inches='tight')
plt.show()

print("üìä Scaling Laws de Kaplan (2020)")
print("\n=== Pr√©dictions ===")

# GPT-2 vs GPT-3
gpt2_loss = kaplan_loss_params(1.5e9)
gpt3_loss = kaplan_loss_params(175e9)
improvement = (1 - gpt3_loss/gpt2_loss) * 100

print(f"GPT-2 (1.5B) : Loss ‚âà {gpt2_loss:.3f}")
print(f"GPT-3 (175B) : Loss ‚âà {gpt3_loss:.3f}")
print(f"Am√©lioration : {improvement:.1f}%")

# Extrapolation GPT-4, GPT-5
gpt4_loss = kaplan_loss_params(1e12)  # 1T params (hypoth√®se)
gpt5_loss = kaplan_loss_params(10e12)  # 10T params (hypoth√®se)

print(f"\n=== Extrapolations ===")
print(f"GPT-4 (1T) : Loss ‚âà {gpt4_loss:.3f}")
print(f"GPT-5 (10T) : Loss ‚âà {gpt5_loss:.3f}")
```

**Output attendu** :
```
üìä Scaling Laws de Kaplan (2020)

=== Pr√©dictions ===
GPT-2 (1.5B) : Loss ‚âà 3.123
GPT-3 (175B) : Loss ‚âà 2.104
Am√©lioration : 32.6%

=== Extrapolations ===
GPT-4 (1T) : Loss ‚âà 1.687
GPT-5 (10T) : Loss ‚âà 1.432
```

---

### 5.2.3 Le Budget Optimal : N vs D

**Question cl√©** : Avec un compute budget fixe C, comment allouer entre param√®tres N et donn√©es D ?

**R√©ponse de Kaplan (2020)** :

```
N_opt ‚àù C^0.73
D_opt ‚àù C^0.27

Ratio : N_opt / D_opt ‚àù C^0.46
```

**Interpr√©tation** : Pour un budget C donn√© :
- Investir **73% du scaling** dans les param√®tres
- Investir **27% du scaling** dans les donn√©es

**Exemple concret** :
- Budget : 10x plus de compute
- Param√®tres : √ó 10^0.73 ‚âà √ó 5.4
- Donn√©es : √ó 10^0.27 ‚âà √ó 1.9

**üí¨ Dialogue**

**Alice** : Donc Kaplan dit de mettre presque tout dans les param√®tres ?

**Bob** : Oui ! C'est pour √ßa que GPT-3 (175B) a √©t√© entra√Æn√© sur "seulement" 300B tokens. Ratio : 175B / 300B ‚âà 0.58.

**Alice** : "Seulement" 300 milliards ? üòÖ

**Bob** : En 2020, oui ! Mais attends... en 2022, DeepMind d√©couvre que Kaplan avait **tort** ! ü§Ø

---

## 5.3 Chinchilla Scaling Laws (2022) : La R√©volution

### üìú Anecdote : DeepMind Chamboule Tout

**Mars 2022** : DeepMind publie [*"Training Compute-Optimal Large Language Models"*](https://arxiv.org/abs/2203.15556) (le "Chinchilla paper").

Leur d√©couverte choquante :
> *"Tous les mod√®les r√©cents (GPT-3, Gopher, etc.) sont **sous-entra√Æn√©s** ! On devrait utiliser 20x plus de donn√©es pour la m√™me taille."*

**Le Mod√®le Chinchilla** :
- 70B param√®tres (4x **moins** que Gopher 280B)
- 1.4T tokens (4x **plus** que Gopher)
- **M√™me compute** budget
- **R√©sultat** : Meilleur que Gopher sur tous les benchmarks ! üèÜ

**Coup de tonnerre dans l'industrie** : On gaspillait du compute en faisant des mod√®les trop gros et sous-entra√Æn√©s !

---

### 5.3.1 Les Nouvelles Lois

**Chinchilla Optimal Scaling** :

```
N_opt ‚àù C^0.50
D_opt ‚àù C^0.50

Ratio : N_opt / D_opt = constante ‚âà 20

R√®gle simple : D_opt ‚âà 20 √ó N_opt
```

**Interpr√©tation** : Pour un mod√®le de N param√®tres, entra√Æner sur **20N tokens** !

**Exemples** :
- 1B params ‚Üí 20B tokens
- 10B params ‚Üí 200B tokens
- 70B params ‚Üí 1.4T tokens (Chinchilla)
- 175B params ‚Üí 3.5T tokens (GPT-3 aurait d√ª !)

---

### üí¨ Dialogue : Kaplan vs Chinchilla

**Alice** : Attends Bob, Kaplan dit N/D ‚àù C^0.46 (favorise params), Chinchilla dit N/D = constant (√©quilibre). Qui a raison ?!

**Bob** : Chinchilla ! Kaplan a fait une erreur m√©thodologique : il n'a test√© que des petits mod√®les (<1.5B) entra√Æn√©s longtemps. Chinchilla a test√© des gros mod√®les (jusqu'√† 280B) avec plus de variations.

**Alice** : Donc GPT-3 √©tait mal entra√Æn√© ?

**Bob** : Oui ! GPT-3 (175B) a √©t√© entra√Æn√© sur 300B tokens. Selon Chinchilla, il aurait fallu :
- 175B √ó 20 = **3.5 TRILLIONS de tokens** !
- Soit 12x plus de donn√©es

**Alice** : Et si OpenAI refait GPT-3 avec Chinchilla scaling ?

**Bob** : C'est ce qu'ils ont fait ! Regarde :
- GPT-3.5 : retrained avec plus de donn√©es
- GPT-4 : probablement plus petit que pr√©vu, mais BEAUCOUP plus de tokens

---

### 5.3.2 Comparaison Kaplan vs Chinchilla

**Code pour comparer les deux approches**

```python
import numpy as np
import matplotlib.pyplot as plt

def kaplan_optimal_allocation(C):
    """
    Allocation optimale selon Kaplan (2020)
    C : compute budget (FLOPs)
    """
    # N ‚àù C^0.73, D ‚àù C^0.27
    N_opt = (C / 6e6) ** (0.73)  # Normalized
    D_opt = (C / 6e6) ** (0.27)
    return N_opt, D_opt

def chinchilla_optimal_allocation(C):
    """
    Allocation optimale selon Chinchilla (2022)
    C : compute budget (FLOPs)
    """
    # N ‚àù C^0.50, D ‚àù C^0.50, D ‚âà 20N
    N_opt = (C / 6e6) ** (0.50) / np.sqrt(20)  # Normalized
    D_opt = 20 * N_opt
    return N_opt, D_opt

# Range de compute budgets
compute_budgets = np.logspace(20, 25, 100)  # 1e20 √† 1e25 FLOPs

# Allocations optimales
kaplan_N = []
kaplan_D = []
chinchilla_N = []
chinchilla_D = []

for C in compute_budgets:
    kN, kD = kaplan_optimal_allocation(C)
    cN, cD = chinchilla_optimal_allocation(C)
    kaplan_N.append(kN)
    kaplan_D.append(kD)
    chinchilla_N.append(cN)
    chinchilla_D.append(cD)

# Visualisation
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Plot 1: N et D en fonction de C
axes[0].loglog(compute_budgets, kaplan_N, 'b-', label='Kaplan N', linewidth=2)
axes[0].loglog(compute_budgets, kaplan_D, 'b--', label='Kaplan D', linewidth=2)
axes[0].loglog(compute_budgets, chinchilla_N, 'r-', label='Chinchilla N', linewidth=2)
axes[0].loglog(compute_budgets, chinchilla_D, 'r--', label='Chinchilla D', linewidth=2)
axes[0].set_xlabel('Compute Budget (FLOPs)', fontsize=12)
axes[0].set_ylabel('Param√®tres / Tokens (normalized)', fontsize=12)
axes[0].set_title('Kaplan vs Chinchilla: Allocation Optimale', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Plot 2: Ratio N/D
kaplan_ratio = np.array(kaplan_N) / np.array(kaplan_D)
chinchilla_ratio = np.array(chinchilla_N) / np.array(chinchilla_D)

axes[1].semilogx(compute_budgets, kaplan_ratio, 'b-', label='Kaplan', linewidth=2)
axes[1].semilogx(compute_budgets, chinchilla_ratio, 'r-', label='Chinchilla', linewidth=2)
axes[1].set_xlabel('Compute Budget (FLOPs)', fontsize=12)
axes[1].set_ylabel('Ratio N/D', fontsize=12)
axes[1].set_title('Ratio Param√®tres/Tokens', fontsize=14)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('kaplan_vs_chinchilla.png', dpi=300, bbox_inches='tight')
plt.show()

# Tableau comparatif pour mod√®les r√©els
print("=" * 80)
print("COMPARAISON KAPLAN VS CHINCHILLA")
print("=" * 80)

models = [
    ("GPT-2", 1.5e9, 40e9),
    ("GPT-3", 175e9, 300e9),
    ("Gopher", 280e9, 300e9),
    ("Chinchilla", 70e9, 1.4e12),
    ("LLaMA 7B", 7e9, 1e12),
    ("LLaMA 65B", 65e9, 1.4e12),
]

print(f"\n{'Model':<15} {'Params':<12} {'Tokens':<15} {'Ratio':<10} {'Chinchilla?':<12}")
print("-" * 80)

for name, N, D in models:
    ratio = D / N
    chinchilla_optimal = 20
    status = "‚úÖ" if ratio >= 15 else "‚ùå Sous-entra√Æn√©"

    print(f"{name:<15} {N/1e9:>10.1f}B {D/1e9:>13.0f}B {ratio:>8.1f}x {status:<12}")

print("\nüí° Chinchilla optimal : D ‚âà 20 √ó N")
print("üìä Mod√®les post-2022 suivent tous Chinchilla !")
```

**Output attendu** :
```
================================================================================
COMPARAISON KAPLAN VS CHINCHILLA
================================================================================

Model           Params       Tokens          Ratio      Chinchilla?
--------------------------------------------------------------------------------
GPT-2                 1.5B           40B     26.7x ‚úÖ
GPT-3               175.0B          300B      1.7x ‚ùå Sous-entra√Æn√©
Gopher              280.0B          300B      1.1x ‚ùå Sous-entra√Æn√©
Chinchilla           70.0B         1400B     20.0x ‚úÖ
LLaMA 7B              7.0B         1000B    142.9x ‚úÖ
LLaMA 65B            65.0B         1400B     21.5x ‚úÖ

üí° Chinchilla optimal : D ‚âà 20 √ó N
üìä Mod√®les post-2022 suivent tous Chinchilla !
```

---

## 5.4 Implications Pratiques des Scaling Laws

### 5.4.1 Pour les Chercheurs : Pr√©dire Avant d'Entra√Æner

**Use Case** : Tu veux savoir si un mod√®le 10B vaut le coup d'√™tre entra√Æn√©.

**M√©thode** :
1. Entra√Æner plusieurs petits mod√®les (100M, 500M, 1B)
2. Tracer la loss en fonction de N (√©chelle log-log)
3. Extrapoler pour 10B
4. D√©cider si le gain justifie le co√ªt

```python
def predict_large_model_performance(small_models_data):
    """
    Pr√©dit la performance d'un gros mod√®le bas√© sur petits mod√®les

    Args:
        small_models_data: Liste de (N, loss) pour petits mod√®les

    Returns:
        Fonction de pr√©diction
    """
    import numpy as np
    from scipy.optimize import curve_fit

    # Extraire N et losses
    Ns = np.array([d[0] for d in small_models_data])
    losses = np.array([d[1] for d in small_models_data])

    # Fit power law: L(N) = a * N^b
    def power_law(N, a, b):
        return a * N ** b

    # Log-transform pour fit lin√©aire
    log_Ns = np.log(Ns)
    log_losses = np.log(losses)

    # Fit lin√©aire en log-space
    coeffs = np.polyfit(log_Ns, log_losses, 1)
    b = coeffs[0]  # Exposant
    a = np.exp(coeffs[1])  # Constante

    print(f"üìê Loi de puissance fitt√©e : L(N) = {a:.3f} * N^({b:.3f})")

    # Fonction de pr√©diction
    def predict(N_target):
        return power_law(N_target, a, b)

    return predict

# Exemple: pr√©dire 10B bas√© sur runs de 100M, 500M, 1B
small_runs = [
    (100e6, 3.8),   # 100M params ‚Üí loss 3.8
    (500e6, 3.2),   # 500M params ‚Üí loss 3.2
    (1e9, 2.9),     # 1B params ‚Üí loss 2.9
]

predict_fn = predict_large_model_performance(small_runs)

# Pr√©dictions
for N in [5e9, 10e9, 50e9, 100e9]:
    predicted_loss = predict_fn(N)
    print(f"Mod√®le {N/1e9:.0f}B params ‚Üí Loss pr√©dite: {predicted_loss:.3f}")
```

**Output** :
```
üìê Loi de puissance fitt√©e : L(N) = 156.432 * N^(-0.082)
Mod√®le 5B params ‚Üí Loss pr√©dite: 2.701
Mod√®le 10B params ‚Üí Loss pr√©dite: 2.585
Mod√®le 50B params ‚Üí Loss pr√©dite: 2.333
Mod√®le 100B params ‚Üí Loss pr√©dite: 2.252
```

**D√©cision** : Si passer de 1B (loss 2.9) √† 10B (loss 2.585) vaut le co√ªt **10x** sup√©rieur ‚Üí GO !

---

### 5.4.2 Pour les Startups : Optimiser le Budget

**Sc√©nario** : Tu as un budget de $10,000 pour entra√Æner un mod√®le. Comment allouer ?

**Donn√©es** :
- A100 40GB : $2/heure
- 1 TFLOP/s = 1e12 FLOPs/seconde
- A100 : ~300 TFLOPS (FP16)

**Calcul** :

```python
def optimize_training_budget(budget_usd, cost_per_hour=2.0, tflops=300):
    """
    Optimise l'allocation N vs D pour un budget donn√©

    Args:
        budget_usd: Budget en dollars
        cost_per_hour: Co√ªt GPU par heure
        tflops: TFLOPs du GPU

    Returns:
        N_opt, D_opt (param√®tres et tokens optimaux)
    """
    # Heures GPU disponibles
    hours = budget_usd / cost_per_hour

    # Compute total (FLOPs)
    flops_per_second = tflops * 1e12
    total_compute = flops_per_second * hours * 3600  # secondes

    print(f"üí∞ Budget: ${budget_usd:,}")
    print(f"‚è∞ Heures GPU: {hours:,.0f}h")
    print(f"üñ•Ô∏è  Compute total: {total_compute:.2e} FLOPs")

    # Chinchilla optimal: C ‚âà 6ND (approximation)
    # N * D = C / 6, avec D = 20N
    # N * 20N = C / 6
    # N^2 = C / 120
    # N = sqrt(C / 120)

    N_opt = np.sqrt(total_compute / 120)
    D_opt = 20 * N_opt

    print(f"\nüìä Allocation optimale (Chinchilla):")
    print(f"   Param√®tres: {N_opt/1e9:.2f}B")
    print(f"   Tokens: {D_opt/1e9:.0f}B")
    print(f"   Ratio D/N: {D_opt/N_opt:.1f}x")

    return N_opt, D_opt

# Exemples
budgets = [1000, 10000, 100000, 1000000]

for budget in budgets:
    print("\n" + "=" * 60)
    optimize_training_budget(budget)
```

**Output** :
```
============================================================
üí∞ Budget: $1,000
‚è∞ Heures GPU: 500h
üñ•Ô∏è  Compute total: 5.40e+20 FLOPs

üìä Allocation optimale (Chinchilla):
   Param√®tres: 0.67B
   Tokens: 13B
   Ratio D/N: 20.0x

============================================================
üí∞ Budget: $10,000
‚è∞ Heures GPU: 5,000h
üñ•Ô∏è  Compute total: 5.40e+21 FLOPs

üìä Allocation optimale (Chinchilla):
   Param√®tres: 2.12B
   Tokens: 42B
   Ratio D/N: 20.0x

============================================================
üí∞ Budget: $100,000
‚è∞ Heures GPU: 50,000h
üñ•Ô∏è  Compute total: 5.40e+22 FLOPs

üìä Allocation optimale (Chinchilla):
   Param√®tres: 6.71B
   Tokens: 134B
   Ratio D/N: 20.0x

============================================================
üí∞ Budget: $1,000,000
‚è∞ Heures GPU: 500,000h
üñ•Ô∏è  Compute total: 5.40e+23 FLOPs

üìä Allocation optimale (Chinchilla):
   Param√®tres: 21.21B
   Tokens: 424B
   Ratio D/N: 20.0x
```

**Conclusion** : Avec $10k, viser un mod√®le ~2B entra√Æn√© sur ~40B tokens (pas un mod√®le 10B sous-entra√Æn√© !).

---

## 5.5 Les Fronti√®res des Scaling Laws

### 5.5.1 Jusqu'o√π Peut-on Scaler ?

**üí¨ Dialogue**

**Alice** : Bob, si les scaling laws continuent, on peut juste faire des mod√®les infinis ?

**Bob** : Bonne question ! Il y a plusieurs **limites** :

**Limite #1 : Les Donn√©es**

En 2026, on a d√©j√† utilis√© :
- Tout CommonCrawl : ~10T tokens
- Tous les livres : ~1T tokens
- Tous les articles scientifiques : ~500B tokens
- GitHub : ~1T tokens

**Total disponible** : ~15-20T tokens de haute qualit√©.

Pour un mod√®le 1T params (Chinchilla optimal), il faut **20T tokens**. On y est presque !

**Solution** :
- Donn√©es synth√©tiques (g√©n√©r√©es par LLMs)
- Multimodal (images, vid√©os)
- Augmentation de donn√©es

---

**Limite #2 : Le Compute**

**Co√ªt d'entra√Ænement actuel** :
- GPT-3 (175B) : ~$5M
- PaLM (540B) : ~$20M
- GPT-4 (estimation 1.7T) : ~$100M ?

**Extrapolation** :
- 10T params : ~$1B üí∏
- 100T params : ~$10B üí∏üí∏

√Ä un moment, m√™me les GAFAM h√©sitent !

---

**Limite #3 : L'√ânergie**

- GPT-3 training : ~1,300 MWh (= consommation annuelle de 120 foyers US)
- GPT-4 training (estim√©) : ~50,000 MWh
- 10T model : ~500,000 MWh (= petite centrale nucl√©aire pendant 1 mois)

**Impact environnemental** devient un facteur limitant.

---

### 5.5.2 √âmergence et Discontinuit√©s

**‚ö†Ô∏è Attention** : Les scaling laws pr√©disent la **loss**, pas les capacit√©s √©mergentes !

**Exemple** :
- Loss GPT-2 ‚Üí GPT-3 : r√©duction continue (pr√©dit ‚úÖ)
- Capacit√©s few-shot : apparaissent soudainement √† 13B params (pas pr√©dit ‚ùå)

**Capacit√©s √©mergentes observ√©es** :
- **Few-shot learning** : >10B params
- **Chain-of-thought** : >50B params
- **Instruction following** : >100B params (+ RLHF)

üé® **Analogie** : C'est comme l'eau :
- 0¬∞C ‚Üí 99¬∞C : temp√©rature monte lin√©airement
- 100¬∞C : **√©bullition** (changement de phase soudain !)

**Bob** : Les scaling laws nous disent que le mod√®le s'am√©liore. Mais elles ne pr√©disent PAS *comment* il s'am√©liore qualitativement.

---

## 5.6 Quiz et Exercices

### üéØ Quiz : Testez Vos Connaissances !

**Question 1** : Selon Kaplan (2020), si tu doubles les param√®tres, de combien diminue la loss ?

A) ~1%
B) ~5%
C) ~10%
D) ~20%

<details>
<summary>R√©ponse</summary>

**B) ~5%**

Explication : L(N) = (Nc/N)^0.076
- Si N ‚Üí 2N : L(2N) / L(N) = (1/2)^0.076 ‚âà 0.95
- R√©duction : 5%
</details>

---

**Question 2** : Selon Chinchilla (2022), combien de tokens faut-il pour entra√Æner un mod√®le 70B de mani√®re optimale ?

A) 70B tokens
B) 350B tokens
C) 1.4T tokens
D) 7T tokens

<details>
<summary>R√©ponse</summary>

**C) 1.4T tokens**

Explication : Chinchilla optimal : D ‚âà 20 √ó N
- 70B params √ó 20 = 1,400B tokens = 1.4T tokens
- C'est exactement ce qu'a fait Chinchilla !
</details>

---

**Question 3** : GPT-3 (175B params, 300B tokens) √©tait-il optimal selon Chinchilla ?

A) Oui, parfaitement optimal
B) Non, sur-entra√Æn√© (trop de tokens)
C) Non, sous-entra√Æn√© (pas assez de tokens)

<details>
<summary>R√©ponse</summary>

**C) Non, sous-entra√Æn√©**

Explication :
- GPT-3 : 175B params, 300B tokens ‚Üí ratio 1.7x
- Chinchilla optimal : 175B params √ó 20 = 3,500B tokens
- GPT-3 aurait d√ª √™tre entra√Æn√© sur **12x plus de donn√©es** !
</details>

---

**Question 4** : Pourquoi ne peut-on pas scaler ind√©finiment ?

A) Les scaling laws s'arr√™tent √† 1T params
B) Limites de donn√©es, compute, √©nergie
C) Les GPUs ne sont pas assez puissants
D) C'est math√©matiquement impossible

<details>
<summary>R√©ponse</summary>

**B) Limites de donn√©es, compute, √©nergie**

Explication :
- **Donn√©es** : On approche de tout le texte disponible (~20T tokens)
- **Compute** : Entra√Æner 10T params co√ªterait ~$1 milliard
- **√ânergie** : Impact environnemental devient prohibitif
- **Pratique** : Gains marginaux ne justifient plus le co√ªt
</details>

---

### üíª Exercices Pratiques

**Exercice 1 : Impl√©menter une Scaling Law** (D√©butant)

Cr√©ez une fonction qui pr√©dit la loss d'un mod√®le selon ses param√®tres.

```python
def predict_loss(N, Nc=8.8e13, alpha=0.076):
    """
    Pr√©dit la loss selon Kaplan scaling law

    Args:
        N: Nombre de param√®tres
        Nc: Constante
        alpha: Exposant

    Returns:
        Loss pr√©dite
    """
    # TODO: Impl√©menter
    pass

# Test
models = [
    ("GPT-2", 1.5e9),
    ("GPT-3", 175e9),
    ("Hypothetical 1T", 1e12),
]

for name, N in models:
    loss = predict_loss(N)
    print(f"{name}: {loss:.3f}")
```

<details>
<summary>Solution</summary>

```python
def predict_loss(N, Nc=8.8e13, alpha=0.076):
    """
    Pr√©dit la loss selon Kaplan scaling law
    """
    return (Nc / N) ** alpha

# Test
models = [
    ("GPT-2", 1.5e9),
    ("GPT-3", 175e9),
    ("Hypothetical 1T", 1e12),
]

print("üìä Pr√©dictions de Loss (Kaplan 2020)")
print(f"{'Model':<20} {'Params':<15} {'Loss Pr√©dite'}")
print("-" * 50)

for name, N in models:
    loss = predict_loss(N)
    print(f"{name:<20} {N/1e9:>12.1f}B {loss:>12.3f}")

# Output:
# üìä Pr√©dictions de Loss (Kaplan 2020)
# Model                Params          Loss Pr√©dite
# --------------------------------------------------
# GPT-2                        1.5B        3.123
# GPT-3                      175.0B        2.104
# Hypothetical 1T           1000.0B        1.687
```
</details>

---

**Exercice 2 : Optimiser un Budget** (Interm√©diaire)

Vous avez $50,000 pour entra√Æner un mod√®le. Utilisez Chinchilla scaling pour d√©terminer N et D optimaux.

<details>
<summary>Solution</summary>

```python
def optimize_chinchilla(budget_usd, gpu_cost_hour=2.0, gpu_tflops=300):
    """
    Optimise N et D selon Chinchilla pour un budget donn√©
    """
    import numpy as np

    # Compute disponible
    hours = budget_usd / gpu_cost_hour
    flops_per_sec = gpu_tflops * 1e12
    total_compute = flops_per_sec * hours * 3600

    # Chinchilla: C ‚âà 6ND, D = 20N
    # C = 6N(20N) = 120N^2
    # N = sqrt(C/120)
    N_opt = np.sqrt(total_compute / 120)
    D_opt = 20 * N_opt

    # Co√ªt r√©el d'entra√Ænement (v√©rification)
    # FLOPs per token ‚âà 6N
    tokens_per_second = flops_per_sec / (6 * N_opt)
    training_time_hours = D_opt / (tokens_per_second * 3600)
    actual_cost = training_time_hours * gpu_cost_hour

    print(f"üí∞ Budget: ${budget_usd:,}")
    print(f"\nüìä Allocation Optimale (Chinchilla):")
    print(f"   Param√®tres: {N_opt/1e9:.2f}B")
    print(f"   Tokens: {D_opt/1e9:.0f}B")
    print(f"   Ratio D/N: {D_opt/N_opt:.1f}x")
    print(f"\n‚è±Ô∏è  Temps d'entra√Ænement: {training_time_hours:,.0f} heures")
    print(f"üíµ Co√ªt r√©el: ${actual_cost:,.0f}")

    return N_opt, D_opt

# Test avec $50k
optimize_chinchilla(50000)

# Output:
# üí∞ Budget: $50,000
#
# üìä Allocation Optimale (Chinchilla):
#    Param√®tres: 4.74B
#    Tokens: 95B
#    Ratio D/N: 20.0x
#
# ‚è±Ô∏è  Temps d'entra√Ænement: 25,000 heures
# üíµ Co√ªt r√©el: $50,000
```
</details>

---

## üéâ Conclusion : L'√Çge de la Pr√©visibilit√©

### üí¨ Dialogue Final

**Alice** : Bob, on vient de voir que l'√©volution de l'IA est... pr√©visible ? C'est fou !

**Bob** : Oui ! Les scaling laws sont peut-√™tre **la d√©couverte la plus importante** de l'IA moderne. Avant 2020, on t√¢tonnait. Maintenant, on **planifie**.

**Alice** : Donc OpenAI sait exactement ce que GPT-5 fera avant de l'entra√Æner ?

**Bob** : Ils ont une tr√®s bonne id√©e de la **loss**, oui. Mais attention : les scaling laws ne pr√©disent pas :
- Les capacit√©s √©mergentes (few-shot, reasoning)
- L'utilit√© pratique
- Les probl√®mes de s√©curit√©

**Alice** : C'est comme avoir la carte d'un territoire, mais pas savoir ce qu'on y trouvera ?

**Bob** : Exactement ! On sait que GPT-5 sera "X% meilleur" que GPT-4. Mais sera-t-il capable de faire des d√©couvertes scientifiques ? De r√©soudre des probl√®mes impossibles ? √áa, les scaling laws ne le disent pas.

**Alice** : Et les limites ? On peut scaler jusqu'o√π ?

**Bob** : Probablement jusqu'√† **10-100T params** dans les 5-10 prochaines ann√©es. Apr√®s :
- On manque de donn√©es (fini le texte humain)
- Co√ªt prohibitif ($1B+ par mod√®le)
- Impact environnemental inacceptable

**Alice** : Donc apr√®s, quoi ? L'IA stagne ?

**Bob** : Non ! On trouvera d'autres axes :
- Architectures plus efficaces (Mamba, RWKV)
- Donn√©es synth√©tiques (self-play, RL)
- Multimodalit√© (vision, audio, robotics)
- Meilleur alignement (RLHF 2.0)

Le scaling n'est qu'une **phase** de l'√©volution de l'IA. Mais quelle phase ! üöÄ

---

### üìä R√©capitulatif

**Scaling Laws de Kaplan (2020)** :
- L(N) ‚àù N^(-0.076) ‚Üí doubler params = -5% loss
- Allocation : 73% params, 27% donn√©es
- A men√© √† GPT-3 (175B, 300B tokens)

**Scaling Laws de Chinchilla (2022)** :
- D_opt ‚âà 20 √ó N_opt
- Allocation : 50-50 entre params et donn√©es
- GPT-3 √©tait **sous-entra√Æn√©** (aurait d√ª avoir 3.5T tokens)

**Implications** :
- On peut pr√©dire la performance avant d'entra√Æner
- Optimiser budgets (startup : $10k ‚Üí mod√®le 2B optimal)
- Fronti√®res : ~10-100T params (limites donn√©es/compute/√©nergie)

**Limites** :
- Ne pr√©disent pas les capacit√©s √©mergentes
- Scaling physiquement limit√©
- Nouveaux paradigmes n√©cessaires au-del√†

---

### üìö Ressources

**Papers** :
- [Kaplan et al. 2020 - Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)
- [Hoffmann et al. 2022 - Training Compute-Optimal LLMs (Chinchilla)](https://arxiv.org/abs/2203.15556)

**Analyses** :
- [Scaling Laws Visualizer](https://scale.anthropic.com)
- [Epoch AI - Trends in ML](https://epochai.org)

---

**Prochain Chapitre** : [Chapitre 6 : Evaluation des LLMs](./CHAPITRE_06_EVALUATION_LLMS.md)

---

> *"The future is predictable. We just need more compute."*
> ‚Äî Sam Altman (probablement)

**Fin du Chapitre 5** üéì

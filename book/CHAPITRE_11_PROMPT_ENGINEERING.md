# CHAPITRE 11 : PROMPT ENGINEERING - L'ART DE PARLER AUX LLMs

> *Â« Le prompt engineering, c'est transformer un LLM gÃ©nÃ©raliste en expert spÃ©cialisÃ©... sans une seule ligne de code. Â»*

---

## Introduction : La Communication Homme-Machine RÃ©inventÃ©e

### ğŸ­ Dialogue : Le Pouvoir des Mots

**Alice** : Bob, j'ai essayÃ© ChatGPT pour gÃ©nÃ©rer du code Python. Parfois c'est brillant, parfois c'est nul. Pourquoi ?

**Bob** : Montre-moi tes prompts.

**Alice** : "Ã‰cris du code pour trier une liste"

**Bob** : VoilÃ  ton problÃ¨me. Compare avec :

```
Prompt amÃ©liorÃ©:
"Tu es un expert Python. Ã‰cris une fonction `sort_list(items)` qui:
1. Prend une liste de nombres en entrÃ©e
2. La trie par ordre croissant
3. Retourne la liste triÃ©e
4. Inclut docstring et tests unitaires
5. Utilise la complexitÃ© optimale O(n log n)

Exemple d'utilisation:
>>> sort_list([3, 1, 4, 1, 5])
[1, 1, 3, 4, 5]"
```

**Alice** : Wow, Ã§a change tout !

**Bob** : Exactement. Le **prompt engineering** transforme un modÃ¨le mÃ©diocre en assistant brillant. C'est l'interface entre ton intention et le modÃ¨le.

### ğŸ“Š Ã‰volution du Prompting

| Ãˆre | MÃ©thode | Exemple | Performance |
|-----|---------|---------|-------------|
| **2018-2020** | Zero-shot simple | "Traduis en anglais: Bonjour" | Faible |
| **2020-2021** | Few-shot | 3 exemples + tÃ¢che | Moyenne |
| **2021-2022** | Chain-of-Thought | "Pensons Ã©tape par Ã©tape..." | Bonne |
| **2022-2023** | Advanced (ReAct, ToT) | Raisonnement + Actions | Excellente |
| **2023+** | Multimodal + Tools | Texte + Images + API calls | SOTA |

### ğŸ¯ Anecdote : GPT-3 et le "Let's think step by step"

**Mai 2022, Google Research**

Kojima et al. testent GPT-3 sur des problÃ¨mes de maths. Performance : **17% accuracy**.

Puis ils ajoutent une phrase magique au prompt : **"Let's think step by step."**

**RÃ©sultat** : **78% accuracy** !

Aucun fine-tuning, aucun exemple. Juste 5 mots qui dÃ©clenchent le raisonnement du modÃ¨le.

**Impact** : Naissance du **Chain-of-Thought prompting**, technique devenue standard pour GPT-4, Claude, etc.

### ğŸ¯ Objectifs du Chapitre

Ã€ la fin de ce chapitre, vous saurez :

- âœ… Concevoir des prompts efficaces (structure, clartÃ©, contexte)
- âœ… Appliquer few-shot learning pour des tÃ¢ches spÃ©cifiques
- âœ… Utiliser Chain-of-Thought pour problÃ¨mes complexes
- âœ… ImplÃ©menter des techniques avancÃ©es (ReAct, Tree of Thoughts)
- âœ… Optimiser automatiquement vos prompts
- âœ… GÃ©rer les hallucinations et biais
- âœ… Ã‰valuer la qualitÃ© des prompts

**DifficultÃ©** : ğŸŸ¡ğŸŸ¡âšªâšªâšª (IntermÃ©diaire)
**PrÃ©requis** : Utilisation basique d'un LLM (ChatGPT, Claude, etc.)
**Temps de lecture** : ~110 minutes

---

## Anatomie d'un Bon Prompt

### Les 6 Composants Essentiels

#### 1. RÃ´le (Persona)

**Principe** : DÃ©finir l'expertise du modÃ¨le.

```
âŒ Mauvais: "Explique la relativitÃ©"

âœ… Bon: "Tu es un physicien thÃ©oricien. Explique la relativitÃ© gÃ©nÃ©rale..."
```

**Exemples de rÃ´les** :
- Expert technique : "Tu es un dÃ©veloppeur senior Python avec 10 ans d'expÃ©rience"
- PÃ©dagogue : "Tu es un professeur qui explique Ã  un enfant de 10 ans"
- CrÃ©atif : "Tu es un romancier primÃ© spÃ©cialisÃ© en science-fiction"

#### 2. TÃ¢che

**Principe** : SpÃ©cifier clairement l'action attendue.

```
âŒ Vague: "Aide-moi avec ce texte"

âœ… PrÃ©cis: "RÃ©sume ce texte en 3 bullet points, en conservant les chiffres clÃ©s"
```

**Verbes d'action** :
- Analyse : RÃ©sume, Classifie, Compare, Ã‰value
- CrÃ©ation : GÃ©nÃ¨re, Ã‰cris, ConÃ§ois, Imagine
- Transformation : Traduis, Reformule, Simplifie, DÃ©veloppe

#### 3. Contexte

**Principe** : Fournir les informations nÃ©cessaires.

```python
prompt = f"""
Contexte: Tu analyses des avis clients pour une boutique e-commerce.

Texte: "{customer_review}"

TÃ¢che: Extraire le sentiment (positif/nÃ©gatif/neutre) et les aspects mentionnÃ©s (prix, qualitÃ©, livraison).
"""
```

#### 4. Exemples (Few-Shot)

**Principe** : Montrer des exemples de sortie attendue.

```
Exemple 1:
Input: "Ce produit est cher mais la qualitÃ© est au rendez-vous"
Output: {"sentiment": "positif", "aspects": ["prix": "nÃ©gatif", "qualitÃ©": "positif"]}

Exemple 2:
Input: "Livraison rapide, je recommande!"
Output: {"sentiment": "positif", "aspects": ["livraison": "positif"]}

Maintenant, analyse ceci:
Input: "{new_review}"
Output:
```

#### 5. Format de Sortie

**Principe** : SpÃ©cifier le format exact attendu.

```
âŒ Vague: "Liste les capitales europÃ©ennes"

âœ… PrÃ©cis: "Liste 5 capitales europÃ©ennes au format JSON:
{
  "cities": [
    {"name": "Paris", "country": "France", "population": 2161000},
    ...
  ]
}"
```

#### 6. Contraintes

**Principe** : DÃ©finir les limites et exigences.

```
Contraintes:
- Maximum 200 mots
- Ton professionnel
- Ã‰viter le jargon technique
- Inclure au moins 2 exemples concrets
- Format Markdown avec titres
```

### Template de Prompt Complet

```python
PROMPT_TEMPLATE = """
[RÃ”LE]
Tu es {role}.

[CONTEXTE]
{context}

[TÃ‚CHE]
{task}

[EXEMPLES]
{examples}

[FORMAT]
RÃ©ponds au format suivant:
{output_format}

[CONTRAINTES]
- {constraint_1}
- {constraint_2}
- {constraint_3}

Maintenant, procÃ¨de:
{input}
"""

# Utilisation
prompt = PROMPT_TEMPLATE.format(
    role="un analyste financier expert",
    context="Tu analyses des rapports trimestriels d'entreprises tech",
    task="Extraire les mÃ©triques clÃ©s (revenue, profit, croissance)",
    examples="...",
    output_format="JSON avec clÃ©s 'revenue', 'profit', 'growth_rate'",
    constraint_1="Chiffres en millions USD",
    constraint_2="Croissance en pourcentage",
    constraint_3="Ajouter comparaison vs trimestre prÃ©cÃ©dent",
    input=company_report
)
```

---

## Zero-Shot, One-Shot, Few-Shot

### Zero-Shot : Sans Exemple

**Principe** : Le modÃ¨le infÃ¨re la tÃ¢che depuis la description.

```python
def zero_shot_classification(text, labels):
    """
    Classification zero-shot.
    """
    prompt = f"""
Classifie le texte suivant dans une de ces catÃ©gories: {', '.join(labels)}

Texte: "{text}"

CatÃ©gorie:"""

    return prompt

# Exemple
text = "Ce film est absolument gÃ©nial, j'ai adorÃ© !"
labels = ["positif", "nÃ©gatif", "neutre"]

prompt = zero_shot_classification(text, labels)
# ModÃ¨le devrait retourner: "positif"
```

**Quand utiliser** :
- âœ… TÃ¢ches simples et communes (sentiment, traduction)
- âœ… ModÃ¨les puissants (GPT-4, Claude)
- âŒ TÃ¢ches spÃ©cialisÃ©es ou format strict

### One-Shot : Un Exemple

```python
def one_shot_extraction(text):
    prompt = f"""
Extrais les entitÃ©s (personnes, lieux, organisations) du texte.

Exemple:
Input: "Barack Obama a visitÃ© Paris en 2015 pour rencontrer le prÃ©sident franÃ§ais."
Output: {{
  "personnes": ["Barack Obama"],
  "lieux": ["Paris"],
  "organisations": [],
  "dates": ["2015"]
}}

Maintenant:
Input: "{text}"
Output:"""

    return prompt
```

### Few-Shot : Plusieurs Exemples

**RÃ¨gle d'or** : 3-5 exemples optimaux.

```python
def few_shot_translation(text, source_lang, target_lang, examples):
    """
    Traduction few-shot avec exemples.
    """
    examples_str = "\n\n".join([
        f"{source_lang}: {ex['source']}\n{target_lang}: {ex['target']}"
        for ex in examples
    ])

    prompt = f"""
Traduis du {source_lang} vers le {target_lang}.

Exemples:
{examples_str}

Maintenant:
{source_lang}: {text}
{target_lang}:"""

    return prompt

# Utilisation
examples = [
    {"source": "Bonjour, comment allez-vous ?", "target": "Hello, how are you?"},
    {"source": "Je vais bien, merci.", "target": "I'm fine, thank you."},
    {"source": "Quelle heure est-il ?", "target": "What time is it?"}
]

prompt = few_shot_translation(
    "OÃ¹ se trouve la gare ?",
    "FranÃ§ais",
    "Anglais",
    examples
)
```

### SÃ©lection Dynamique d'Exemples

**Principe** : Choisir les exemples les plus similaires Ã  l'input.

```python
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import numpy as np

class DynamicFewShot:
    """
    SÃ©lectionne dynamiquement les meilleurs exemples.
    """
    def __init__(self, example_pool, num_examples=3):
        self.example_pool = example_pool
        self.num_examples = num_examples

        # Encoder
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')

        # PrÃ©-calculer embeddings des exemples
        self.example_texts = [ex['input'] for ex in example_pool]
        self.example_embeddings = self.encoder.encode(self.example_texts)

    def select_examples(self, query):
        """
        SÃ©lectionne les N exemples les plus similaires.
        """
        # Embedding de la query
        query_embedding = self.encoder.encode([query])

        # SimilaritÃ©s
        similarities = cosine_similarity(query_embedding, self.example_embeddings)[0]

        # Top-N indices
        top_indices = np.argsort(similarities)[::-1][:self.num_examples]

        # Retourner exemples
        selected = [self.example_pool[i] for i in top_indices]
        return selected

# Utilisation
example_pool = [
    {"input": "Ce produit est excellent", "output": "positif"},
    {"input": "TrÃ¨s dÃ©Ã§u de cet achat", "output": "nÃ©gatif"},
    {"input": "QualitÃ© correcte pour le prix", "output": "neutre"},
    # ... 100+ exemples
]

selector = DynamicFewShot(example_pool, num_examples=3)

# Pour une nouvelle query
query = "Je recommande vivement ce service"
selected_examples = selector.select_examples(query)

# Construire prompt avec exemples sÃ©lectionnÃ©s
# ...
```

---

## Chain-of-Thought (CoT) Prompting

### Principe : DÃ©composer le Raisonnement

**Sans CoT** :
```
Q: Roger a 5 balles de tennis. Il achÃ¨te 2 boÃ®tes de 3 balles. Combien a-t-il de balles maintenant ?
A: 11
```

**Avec CoT** :
```
Q: Roger a 5 balles de tennis. Il achÃ¨te 2 boÃ®tes de 3 balles. Combien a-t-il de balles maintenant ?
A: RÃ©flÃ©chissons Ã©tape par Ã©tape.
1. Roger commence avec 5 balles
2. Il achÃ¨te 2 boÃ®tes de 3 balles chacune
3. 2 boÃ®tes Ã— 3 balles = 6 balles
4. Total : 5 + 6 = 11 balles
La rÃ©ponse est 11.
```

### Zero-Shot CoT : "Let's think step by step"

```python
def zero_shot_cot(question):
    """
    Chain-of-Thought zero-shot.
    """
    prompt = f"""
Question: {question}

Let's think step by step:"""

    return prompt

# Exemple
question = "Si un train part de Paris Ã  14h Ã  120 km/h et arrive Ã  Lyon (450 km) Ã  quelle heure ?"

prompt = zero_shot_cot(question)

# RÃ©ponse attendue:
# 1. Distance = 450 km
# 2. Vitesse = 120 km/h
# 3. Temps = Distance / Vitesse = 450 / 120 = 3.75 heures = 3h45min
# 4. ArrivÃ©e = 14h + 3h45min = 17h45
```

### Few-Shot CoT

```python
FEW_SHOT_COT_PROMPT = """
Q: Dans un cafÃ©, il y a 23 clients. 17 partent et 9 arrivent. Combien reste-t-il de clients ?
A: CommenÃ§ons par identifier ce qu'on sait :
- Au dÃ©part : 23 clients
- Partent : 17 clients
- Arrivent : 9 clients

Calculons Ã©tape par Ã©tape :
1. AprÃ¨s les dÃ©parts : 23 - 17 = 6 clients
2. AprÃ¨s les arrivÃ©es : 6 + 9 = 15 clients

RÃ©ponse finale : 15 clients.

Q: Marie a 4 pommes. Elle en donne la moitiÃ© Ã  Jean, puis achÃ¨te 3 oranges. Combien de fruits a-t-elle ?
A: DÃ©composons le problÃ¨me :
- DÃ©but : 4 pommes
- Donne la moitiÃ© Ã  Jean : 4 / 2 = 2 pommes donnÃ©es, reste 2 pommes
- AchÃ¨te 3 oranges

Calcul final :
- Pommes restantes : 2
- Oranges : 3
- Total fruits : 2 + 3 = 5 fruits

RÃ©ponse finale : 5 fruits.

Q: {question}
A: """
```

### Self-Consistency : Ã‰chantillonner Plusieurs Raisonnements

**Principe** : GÃ©nÃ©rer plusieurs CoT, prendre la rÃ©ponse majoritaire.

```python
import openai
from collections import Counter

def self_consistency_cot(question, num_samples=5, temperature=0.7):
    """
    Self-consistency avec Chain-of-Thought.
    """
    prompt = f"""
Question: {question}

Let's think step by step:"""

    answers = []

    for _ in range(num_samples):
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=300
        )

        full_response = response.choices[0].message.content

        # Extraire rÃ©ponse finale (simplifiÃ©)
        # En pratique : parser avec regex ou demander format structurÃ©
        answer = extract_final_answer(full_response)
        answers.append(answer)

    # Vote majoritaire
    answer_counts = Counter(answers)
    most_common = answer_counts.most_common(1)[0][0]

    return {
        "answer": most_common,
        "confidence": answer_counts[most_common] / num_samples,
        "all_answers": dict(answer_counts)
    }

# Exemple
result = self_consistency_cot(
    "Un bus a 25 passagers. Ã€ l'arrÃªt 1, 8 descendent et 13 montent. Ã€ l'arrÃªt 2, 5 descendent. Combien reste-t-il de passagers ?"
)
print(f"RÃ©ponse: {result['answer']} (confiance: {result['confidence']:.0%})")
```

---

## Techniques AvancÃ©es

### ReAct : Reasoning + Acting

**Principe** : Alterner raisonnement et actions (appels API, recherche web, etc.).

```python
REACT_PROMPT = """
Tu rÃ©sous des problÃ¨mes en alternant PensÃ©e (Thought), Action, et Observation.

Outils disponibles:
- search(query): Recherche Google
- calculate(expression): Calculatrice
- wikipedia(topic): Recherche Wikipedia

Exemple:
Question: Quelle est la population de la capitale du Japon en 2023 ?

Thought: Je dois d'abord identifier la capitale du Japon
Action: wikipedia("Japon capitale")
Observation: La capitale du Japon est Tokyo

Thought: Maintenant je cherche la population de Tokyo en 2023
Action: search("population Tokyo 2023")
Observation: La population de Tokyo est environ 14 millions (2023)

Thought: J'ai la rÃ©ponse
Final Answer: 14 millions d'habitants

---

Question: {question}

Thought:"""

def react_agent(question, max_iterations=5):
    """
    Agent ReAct simple.
    """
    prompt = REACT_PROMPT.format(question=question)
    history = []

    for i in range(max_iterations):
        # GÃ©nÃ©rer pensÃ©e + action
        response = call_llm(prompt)

        # Parser
        thought, action, params = parse_react_response(response)

        history.append({"thought": thought, "action": action})

        # ExÃ©cuter action
        if action == "search":
            observation = google_search(params)
        elif action == "calculate":
            observation = eval(params)  # Attention: unsafe en production!
        elif action == "wikipedia":
            observation = wikipedia_search(params)
        elif action == "FINISH":
            return {"answer": params, "history": history}

        # Ajouter observation au prompt
        prompt += f"\nObservation: {observation}\n\nThought:"

    return {"answer": "Max iterations atteinte", "history": history}
```

### Tree of Thoughts (ToT)

**Principe** : Explorer plusieurs chemins de raisonnement en arbre.

```python
class TreeOfThoughts:
    """
    Tree of Thoughts pour exploration de solutions.
    """
    def __init__(self, problem, num_branches=3, depth=3):
        self.problem = problem
        self.num_branches = num_branches
        self.depth = depth

    def generate_thoughts(self, state, depth):
        """GÃ©nÃ¨re N pensÃ©es possibles depuis un Ã©tat."""
        prompt = f"""
ProblÃ¨me: {self.problem}

Ã‰tat actuel: {state}

GÃ©nÃ¨re {self.num_branches} prochaines Ã©tapes de raisonnement possibles.
Format:
1. [Ã‰tape 1]
2. [Ã‰tape 2]
3. [Ã‰tape 3]
"""

        response = call_llm(prompt)
        thoughts = parse_thoughts(response)
        return thoughts

    def evaluate_thought(self, thought):
        """Ã‰value la promesse d'une pensÃ©e (0-10)."""
        prompt = f"""
ProblÃ¨me: {self.problem}
PensÃ©e: {thought}

Sur une Ã©chelle de 0 Ã  10, Ã©value la probabilitÃ© que cette pensÃ©e mÃ¨ne Ã  la solution correcte.
Score:"""

        response = call_llm(prompt)
        score = int(response.strip())
        return score

    def search(self):
        """Recherche en profondeur avec Ã©lagage."""
        best_solution = None
        best_score = -1

        def dfs(state, depth, path):
            nonlocal best_solution, best_score

            if depth == self.depth:
                # Ã‰valuer solution finale
                score = self.evaluate_thought(state)
                if score > best_score:
                    best_score = score
                    best_solution = path
                return

            # GÃ©nÃ©rer et Ã©valuer pensÃ©es
            thoughts = self.generate_thoughts(state, depth)
            scored_thoughts = [(t, self.evaluate_thought(t)) for t in thoughts]

            # Prendre les meilleures
            sorted_thoughts = sorted(scored_thoughts, key=lambda x: x[1], reverse=True)

            # Explorer rÃ©cursivement
            for thought, score in sorted_thoughts[:self.num_branches]:
                dfs(thought, depth + 1, path + [thought])

        dfs("", 0, [])
        return {"solution": best_solution, "score": best_score}

# Exemple
problem = "RÃ©soudre: x^2 + 5x + 6 = 0"
tot = TreeOfThoughts(problem, num_branches=3, depth=3)
result = tot.search()
```

---

## Gestion des Hallucinations

### Techniques de Mitigation

#### 1. Demander des Citations

```python
CITATION_PROMPT = """
RÃ©ponds Ã  la question suivante en citant tes sources.

Format:
RÃ©ponse: [Ta rÃ©ponse]
Sources: [Citation 1], [Citation 2], ...

Si tu n'es pas sÃ»r, dis "Je ne sais pas" plutÃ´t que d'inventer.

Question: {question}
"""
```

#### 2. Contraindre avec Contexte

```python
RAG_PROMPT = """
Contexte fourni:
{context}

RÃ¨gles:
- RÃ©ponds UNIQUEMENT en te basant sur le contexte ci-dessus
- Si l'information n'est pas dans le contexte, rÃ©ponds "Information non disponible dans le contexte fourni"
- Cite les passages pertinents entre guillemets

Question: {question}
RÃ©ponse:"""
```

#### 3. VÃ©rification Multi-Ã‰tapes

```python
def verify_response(question, answer):
    """
    VÃ©rifie la cohÃ©rence d'une rÃ©ponse.
    """
    verification_prompt = f"""
Question originale: {question}
RÃ©ponse donnÃ©e: {answer}

TÃ¢ches:
1. VÃ©rifier si la rÃ©ponse est cohÃ©rente avec la question
2. Identifier les affirmations factuelles dans la rÃ©ponse
3. Ã‰valuer la confiance pour chaque affirmation (faible/moyenne/Ã©levÃ©e)
4. Signaler les affirmations potentiellement fausses

Format JSON:
{{
  "coherent": true/false,
  "claims": [
    {{"text": "...", "confidence": "Ã©levÃ©e/moyenne/faible"}}
  ],
  "potential_hallucinations": [...]
}}
"""

    verification = call_llm(verification_prompt)
    return parse_verification(verification)
```

---

## Optimisation Automatique de Prompts

### Prompt Tuning : Recherche Automatique

```python
import itertools

class PromptOptimizer:
    """
    Optimise automatiquement un prompt via recherche.
    """
    def __init__(self, test_cases):
        """
        Args:
            test_cases: Liste de (input, expected_output)
        """
        self.test_cases = test_cases

    def evaluate_prompt(self, prompt_template):
        """Ã‰value un template de prompt."""
        correct = 0

        for input_data, expected in self.test_cases:
            prompt = prompt_template.format(input=input_data)
            output = call_llm(prompt)

            if self.is_correct(output, expected):
                correct += 1

        accuracy = correct / len(self.test_cases)
        return accuracy

    def is_correct(self, output, expected):
        """VÃ©rifie si output correspond Ã  expected."""
        # ImplÃ©mentation dÃ©pend de la tÃ¢che
        # Peut Ãªtre exact match, similaritÃ© sÃ©mantique, etc.
        return output.strip().lower() == expected.strip().lower()

    def optimize(self, prompt_variations):
        """
        Teste diffÃ©rentes variations de prompt.
        """
        results = []

        for variation in prompt_variations:
            accuracy = self.evaluate_prompt(variation)
            results.append((variation, accuracy))

        # Trier par accuracy
        results.sort(key=lambda x: x[1], reverse=True)

        return results

# Utilisation
test_cases = [
    ("Ce film est gÃ©nial", "positif"),
    ("Quelle dÃ©ception", "nÃ©gatif"),
    ("Pas mal", "neutre"),
    # ... 50+ exemples
]

optimizer = PromptOptimizer(test_cases)

# Variations Ã  tester
variations = [
    "Classifie le sentiment: {input}\nRÃ©ponse:",
    "Sentiment de ce texte: {input}\nRÃ©ponse:",
    "Analyse de sentiment:\nTexte: {input}\nSentiment:",
    "Tu es un expert en analyse de sentiment. Classifie:\n{input}\nRÃ©ponse:",
]

results = optimizer.optimize(variations)

print("Meilleur prompt:")
print(results[0][0])
print(f"Accuracy: {results[0][1]:.2%}")
```

### APE : Automatic Prompt Engineer

**Principe** : Utiliser un LLM pour gÃ©nÃ©rer et optimiser des prompts.

```python
def ape_generate_prompts(task_description, num_prompts=10):
    """
    GÃ©nÃ¨re automatiquement des prompts candidats.
    """
    meta_prompt = f"""
TÃ¢che: {task_description}

GÃ©nÃ¨re {num_prompts} prompts diffÃ©rents pour accomplir cette tÃ¢che.
Chaque prompt doit Ãªtre clair, prÃ©cis et optimisÃ© pour obtenir les meilleurs rÃ©sultats.

Format:
1. [Prompt 1]
2. [Prompt 2]
...
"""

    response = call_llm(meta_prompt)
    prompts = parse_prompts(response)
    return prompts

# Exemple
task = "Extraire les noms de personnes mentionnÃ©es dans un texte"
candidate_prompts = ape_generate_prompts(task, num_prompts=5)

# Ã‰valuer et sÃ©lectionner le meilleur
optimizer = PromptOptimizer(test_cases)
results = optimizer.optimize(candidate_prompts)
```

---

## Ã‰valuation de Prompts

### MÃ©triques

```python
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

class PromptEvaluator:
    """
    Ã‰value la qualitÃ© d'un prompt sur diffÃ©rentes mÃ©triques.
    """
    def __init__(self, test_set):
        self.test_set = test_set

    def evaluate(self, prompt_template):
        """
        Ã‰value un prompt.

        Returns:
            dict avec mÃ©triques
        """
        predictions = []
        ground_truth = []
        latencies = []
        costs = []

        for example in self.test_set:
            start_time = time.time()

            # GÃ©nÃ©rer prÃ©diction
            prompt = prompt_template.format(**example['input'])
            prediction = call_llm(prompt)

            # MÃ©triques
            latency = time.time() - start_time
            cost = estimate_cost(prompt, prediction)

            predictions.append(prediction)
            ground_truth.append(example['output'])
            latencies.append(latency)
            costs.append(cost)

        # Calculer mÃ©triques
        accuracy = accuracy_score(ground_truth, predictions)
        avg_latency = np.mean(latencies)
        total_cost = sum(costs)

        return {
            'accuracy': accuracy,
            'avg_latency_ms': avg_latency * 1000,
            'total_cost_usd': total_cost,
            'cost_per_example': total_cost / len(self.test_set)
        }

# Utilisation
evaluator = PromptEvaluator(test_set)

prompt_v1 = "Classifie: {text}"
prompt_v2 = "Tu es un expert. Analyse le sentiment de: {text}"

results_v1 = evaluator.evaluate(prompt_v1)
results_v2 = evaluator.evaluate(prompt_v2)

print("Prompt V1:", results_v1)
print("Prompt V2:", results_v2)
```

---

## BibliothÃ¨que de Prompts RÃ©utilisables

### Classification

```python
CLASSIFICATION_PROMPT = """
Classifie le texte suivant dans une des catÃ©gories: {categories}

Texte: "{text}"

RÃ©flÃ©chis Ã©tape par Ã©tape:
1. Quel est le sujet principal ?
2. Quels mots-clÃ©s indiquent la catÃ©gorie ?
3. Quelle catÃ©gorie correspond le mieux ?

CatÃ©gorie:"""
```

### Extraction d'Information

```python
NER_PROMPT = """
Extrais les entitÃ©s nommÃ©es du texte.

Texte: "{text}"

Retourne au format JSON:
{{
  "personnes": [...],
  "organisations": [...],
  "lieux": [...],
  "dates": [...]
}}

JSON:"""
```

### GÃ©nÃ©ration de Code

```python
CODE_GENERATION_PROMPT = """
Tu es un expert programmeur {language}.

TÃ¢che: {task}

Exigences:
- Code propre et commentÃ©
- Gestion des erreurs
- Tests unitaires
- ComplexitÃ© optimale
- Docstrings

Exemple d'utilisation:
{usage_example}

Code:
```{language}
"""
```

### RÃ©sumÃ©

```python
SUMMARY_PROMPT = """
RÃ©sume le texte suivant en {num_sentences} phrases.

Texte:
{text}

Consignes:
- Conserver les informations clÃ©s
- Ton {tone}
- Maximum {max_words} mots

RÃ©sumÃ©:"""
```

---

## ğŸ’¡ Analogie : Le Prompt comme une Recette de Cuisine

- **RÃ´le** = Chef (italien, pÃ¢tissier, vegan...)
- **TÃ¢che** = Type de plat (entrÃ©e, dessert)
- **Contexte** = Occasion (dÃ®ner formel, goÃ»ter enfants)
- **Exemples** = Photos du plat attendu
- **Format** = PrÃ©sentation (assiette, portion)
- **Contraintes** = Allergies, budget, temps

Un bon prompt, comme une bonne recette, est :
- **PrÃ©cis** : QuantitÃ©s exactes, Ã©tapes claires
- **ContextualisÃ©** : AdaptÃ© Ã  la situation
- **Reproductible** : MÃªme rÃ©sultat Ã  chaque fois
- **OptimisÃ©** : Efficient en temps et ressources

---

## Conclusion

### ğŸ­ Dialogue Final : Le Prompt Engineering, CompÃ©tence ClÃ©

**Alice** : Le prompt engineering, c'est vraiment un mÃ©tier maintenant ?

**Bob** : Absolument ! En 2024, "Prompt Engineer" peut payer $200k+/an. Pourquoi ?
1. **CoÃ»t** : Un bon prompt Ã©conomise des milliers en API calls
2. **Performance** : DiffÃ©rence entre 40% et 90% accuracy
3. **RapiditÃ©** : Prompting vs fine-tuning = heures vs semaines

**Alice** : Quels sont les principes clÃ©s ?

**Bob** :
1. **ClartÃ©** : SpÃ©cifique > vague
2. **Contexte** : Donner les informations nÃ©cessaires
3. **Exemples** : Few-shot > zero-shot pour tÃ¢ches complexes
4. **Structure** : CoT pour raisonnement
5. **ItÃ©ration** : Tester, mesurer, amÃ©liorer

**Alice** : Et le futur ?

**Bob** : **Prompts multimodaux** (texte + images + code), **auto-optimisation** (AI qui amÃ©liore ses propres prompts), **prompts universels** (fonctionnent sur GPT, Claude, LLaMA...).

Le prompt engineering Ã©volue de l'art vers la science.

---

## Ressources

### ğŸ“š Papers Fondamentaux

1. **"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"** (Wei et al., 2022)
2. **"Large Language Models are Zero-Shot Reasoners"** (Kojima et al., 2022) - "Let's think step by step"
3. **"ReAct: Synergizing Reasoning and Acting in Language Models"** (Yao et al., 2022)
4. **"Tree of Thoughts: Deliberate Problem Solving with Large Language Models"** (Yao et al., 2023)

### ğŸ› ï¸ Outils

```bash
# Frameworks de prompting
pip install langchain guidance

# Ã‰valuation
pip install prompttools

# Optimisation
pip install dspy-ai
```

### ğŸ”— Ressources

- **Prompt Engineering Guide** : https://www.promptingguide.ai/
- **OpenAI Prompt Examples** : https://platform.openai.com/examples
- **Awesome Prompts** : https://github.com/f/awesome-chatgpt-prompts
- **Learn Prompting** : https://learnprompting.org/

---

**ğŸ“ Bravo !** Vous maÃ®trisez maintenant le prompt engineering, l'interface cruciale entre humains et LLMs. Prochain chapitre : **Chapitre 12 - RAG (Retrieval-Augmented Generation)** pour combiner prompting et recherche d'information ! ğŸš€


# CHAPITRE 14 : AGENTS LLM ET REACT

> *¬´ The question of whether a computer can think is no more interesting than the question of whether a submarine can swim. ¬ª*
> ‚Äî Edsger W. Dijkstra

---

## Introduction : De la G√©n√©ration de Texte √† l'Action

Un LLM seul est puissant, mais **limit√©** : il peut g√©n√©rer du texte, raisonner sur des concepts, √©crire du code. Mais il ne peut pas :
- Ex√©cuter ce code
- Chercher des informations en temps r√©el sur le web
- Acc√©der √† une base de donn√©es
- Envoyer un email
- R√©server un vol
- Commander une pizza

**Et si on donnait des "mains" √† notre LLM ?** Et si on le transformait en **agent autonome** capable d'interagir avec le monde ext√©rieur ?

C'est exactement ce que font les **LLM Agents** : des syst√®mes qui combinent la puissance de raisonnement d'un LLM avec la capacit√© d'**agir** sur l'environnement via des outils (APIs, bases de donn√©es, calculatrices, navigateurs web, etc.).

Dans ce chapitre, nous explorerons :
- L'architecture des agents LLM
- Le framework **ReAct** (Reasoning + Acting)
- Les patterns d'impl√©mentation
- Les d√©fis et solutions (erreurs, boucles infinies, co√ªts)
- Des impl√©mentations compl√®tes en production

Bienvenue dans l'√®re des **agents autonomes**.

---

## 1. Qu'est-ce qu'un Agent LLM ?

### üé≠ Dialogue : La M√©taphore de l'Assistant

**Alice** : Bob, j'ai utilis√© ChatGPT pour g√©n√©rer du code Python. Mais ensuite, je dois copier-coller le code, l'ex√©cuter moi-m√™me, voir les erreurs, revenir √† ChatGPT pour les corriger... C'est fastidieux !

**Bob** : Exactement. C'est parce que ChatGPT est un **LLM pur** : il g√©n√®re du texte, mais il ne peut pas **agir**.

**Alice** : Tu veux dire qu'il ne peut pas ex√©cuter le code lui-m√™me ?

**Bob** : Pr√©cis√©ment. Mais imagine maintenant qu'on donne √† ChatGPT acc√®s √† un **interpr√©teur Python**. Il pourrait :
1. G√©n√©rer le code
2. L'ex√©cuter
3. Voir les erreurs
4. Les corriger automatiquement
5. R√©essayer jusqu'√† ce que √ßa marche

**Alice** : √áa ressemble √† un d√©veloppeur junior qui debug !

**Bob** : Exactement ! Et si on va plus loin, on peut lui donner acc√®s √† d'autres **outils** :
- Une calculatrice pour les calculs pr√©cis
- Un moteur de recherche pour les infos √† jour
- Une base de donn√©es pour stocker/r√©cup√©rer des donn√©es
- Un navigateur web pour interagir avec des sites
- Une API d'envoi d'emails

**Alice** : Donc il devient un vrai **agent** capable d'accomplir des t√¢ches complexes ?

**Bob** : Voil√† ! On passe de "g√©n√©rateur de texte" √† "assistant autonome".

---

### 1.1 D√©finition Formelle

Un **Agent LLM** est un syst√®me compos√© de :

1. **Un LLM** (le "cerveau") : raisonne, planifie, d√©cide
2. **Des outils** (les "mains") : APIs, fonctions, bases de donn√©es
3. **Une boucle de contr√¥le** : perception ‚Üí raisonnement ‚Üí action ‚Üí observation
4. **Une m√©moire** (optionnelle) : historique des actions et observations

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   AGENT LLM                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ    LLM      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   Memory    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  (Cerveau)  ‚îÇ         ‚îÇ (Historique)‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ         ‚îÇ                                       ‚îÇ
‚îÇ         ‚îÇ D√©cision                              ‚îÇ
‚îÇ         ‚ñº                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ      Tool Selection             ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ  (Quel outil utiliser ?)        ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ           ‚îÇ                                     ‚îÇ
‚îÇ           ‚ñº                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ          TOOLS                     ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Calculator                      ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Web Search                      ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Python Interpreter              ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Database Query                  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ API Calls                       ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ           ‚îÇ                                     ‚îÇ
‚îÇ           ‚îÇ Observation (r√©sultat)              ‚îÇ
‚îÇ           ‚ñº                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ   Update Memory & Loop          ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### üìú Anecdote Historique : SHRDLU (1968-1970)

**MIT, Cambridge, Massachusetts, 1968** : Terry Winograd, √©tudiant en doctorat, d√©veloppe **SHRDLU**, l'un des premiers syst√®mes d'IA conversationnelle capable d'**agir** dans un monde (virtuel).

SHRDLU contr√¥le un bras robotique virtuel dans un monde de blocs g√©om√©triques color√©s. L'utilisateur peut donner des commandes en langage naturel :

```
Utilisateur : "Pick up a big red block."
SHRDLU : [ex√©cute l'action, saisit le bloc rouge]

Utilisateur : "Grasp the pyramid."
SHRDLU : "I don't understand which pyramid you mean."

Utilisateur : "Find a block which is taller than the one you are holding and put it into the box."
SHRDLU : [analyse, planifie, ex√©cute plusieurs actions]
```

**Innovation** : SHRDLU ne se contente pas de **comprendre** le langage, il **agit** dans son environnement et **raisonne** sur les cons√©quences de ses actions.

**56 ans plus tard**, les agents LLM modernes utilisent les m√™mes principes ‚Äî mais √† une √©chelle infiniment plus grande, avec des capacit√©s de raisonnement bien plus sophistiqu√©es.

---

## 2. Le Framework ReAct : Reasoning + Acting

### 2.1 Le Probl√®me des LLMs Purs

Un LLM seul peut **halluciner** des informations :

```python
# Question n√©cessitant des infos √† jour
question = "Combien d'habitants compte Tokyo en 2026 ?"

# LLM pur (GPT-4) :
# ‚Üí "Tokyo compte environ 14 millions d'habitants."
#    (Bas√© sur ses donn√©es d'entra√Ænement, potentiellement obsol√®tes)
```

**Probl√®me** : Le LLM ne peut pas v√©rifier ses informations. Il g√©n√®re ce qui est **statistiquement probable**, pas ce qui est **factuellement correct**.

**Solution ReAct** : Permettre au LLM de **chercher** l'information avant de r√©pondre.

---

### 2.2 ReAct : L'Approche

**ReAct** (Yao et al., 2022) = **Rea**soning + **Act**ing

Le LLM alterne entre :
- **Thought** (Pens√©e) : raisonnement sur la t√¢che
- **Action** : ex√©cution d'un outil
- **Observation** : r√©sultat de l'action

```python
# Exemple de trace ReAct

Task: "Combien d'habitants compte Tokyo en 2026 ?"

Thought 1: Je dois chercher l'information la plus r√©cente sur la population de Tokyo.
Action 1: Search["population Tokyo 2026"]
Observation 1: "La population de Tokyo en 2026 est estim√©e √† 14,1 millions d'habitants dans les 23 arrondissements sp√©ciaux."

Thought 2: J'ai trouv√© l'information. Je peux maintenant r√©pondre.
Action 2: Finish["Tokyo compte environ 14,1 millions d'habitants en 2026."]
```

**Avantages** :
- ‚úÖ R√©ponses factuelles et v√©rifiables
- ‚úÖ Transparence (on voit le raisonnement)
- ‚úÖ Capacit√© √† r√©soudre des t√¢ches multi-√©tapes
- ‚úÖ Auto-correction (si une action √©choue, le LLM peut r√©essayer)

---

### 2.3 Impl√©mentation de Base

```python
from typing import List, Dict, Callable, Optional
import re

class Tool:
    """Classe de base pour un outil."""

    def __init__(self, name: str, description: str, func: Callable):
        self.name = name
        self.description = description
        self.func = func

    def run(self, query: str) -> str:
        """Ex√©cute l'outil."""
        try:
            result = self.func(query)
            return str(result)
        except Exception as e:
            return f"Error: {str(e)}"


class ReActAgent:
    """
    Agent ReAct simple.

    Alterne entre raisonnement (Thought), action (Action), et observation (Observation).
    """

    def __init__(self, llm, tools: List[Tool], max_steps: int = 10, verbose: bool = True):
        """
        Args:
            llm: Mod√®le de langage (OpenAI, Anthropic, etc.)
            tools: Liste d'outils disponibles
            max_steps: Nombre maximum d'it√©rations
            verbose: Afficher les traces
        """
        self.llm = llm
        self.tools = {tool.name: tool for tool in tools}
        self.max_steps = max_steps
        self.verbose = verbose

    def _build_tool_description(self) -> str:
        """Construit la description des outils pour le prompt."""
        descriptions = []
        for tool in self.tools.values():
            descriptions.append(f"- {tool.name}: {tool.description}")
        return "\n".join(descriptions)

    def _parse_action(self, text: str) -> Optional[tuple]:
        """
        Parse l'action du LLM.

        Format attendu : Action: ToolName[argument]

        Returns:
            (tool_name, argument) ou None si format invalide
        """
        # Regex pour capturer : Action: ToolName[argument]
        match = re.search(r'Action:\s*(\w+)\[(.*?)\]', text, re.DOTALL)
        if match:
            tool_name = match.group(1)
            argument = match.group(2).strip()
            return (tool_name, argument)
        return None

    def _check_finish(self, text: str) -> Optional[str]:
        """V√©rifie si le LLM a termin√©."""
        match = re.search(r'Action:\s*Finish\[(.*?)\]', text, re.DOTALL)
        if match:
            return match.group(1).strip()
        return None

    def run(self, task: str) -> str:
        """
        Ex√©cute une t√¢che en utilisant ReAct.

        Args:
            task: Description de la t√¢che

        Returns:
            R√©ponse finale
        """
        # Historique des pens√©es/actions/observations
        scratchpad = []

        for step in range(self.max_steps):
            # Construire le prompt
            prompt = self._build_prompt(task, scratchpad)

            # G√©n√©rer la r√©ponse du LLM
            response = self.llm.generate(prompt)

            if self.verbose:
                print(f"\n{'='*60}")
                print(f"STEP {step + 1}")
                print(f"{'='*60}")
                print(response)

            # V√©rifier si termin√©
            final_answer = self._check_finish(response)
            if final_answer:
                if self.verbose:
                    print(f"\n‚úÖ FINAL ANSWER: {final_answer}")
                return final_answer

            # Parser l'action
            action = self._parse_action(response)
            if not action:
                scratchpad.append(f"Error: Could not parse action from response.")
                continue

            tool_name, argument = action

            # Ex√©cuter l'outil
            if tool_name not in self.tools:
                observation = f"Error: Tool '{tool_name}' not found. Available tools: {list(self.tools.keys())}"
            else:
                tool = self.tools[tool_name]
                observation = tool.run(argument)

            if self.verbose:
                print(f"\nObservation: {observation}")

            # Ajouter au scratchpad
            scratchpad.append(f"{response}\nObservation: {observation}")

        # Max steps atteint
        return f"Failed to complete task within {self.max_steps} steps."

    def _build_prompt(self, task: str, scratchpad: List[str]) -> str:
        """Construit le prompt pour le LLM."""
        tools_desc = self._build_tool_description()
        history = "\n\n".join(scratchpad) if scratchpad else "No actions yet."

        prompt = f"""You are an AI agent that can use tools to accomplish tasks.

Available tools:
{tools_desc}
- Finish: Use when you have the final answer. Format: Action: Finish[answer]

Instructions:
1. Think step by step about what you need to do
2. Choose an appropriate tool and provide an argument
3. Observe the result
4. Repeat until you can provide a final answer

Format:
Thought: [your reasoning]
Action: ToolName[argument]

Task: {task}

Previous actions:
{history}

Now, what should you do next?

Thought:"""

        return prompt


# --- D√©finition des outils ---

def calculator(expression: str) -> float:
    """√âvalue une expression math√©matique."""
    # S√©curis√© : utilise ast.literal_eval pour √©viter l'ex√©cution de code arbitraire
    import ast
    import operator

    ops = {
        ast.Add: operator.add,
        ast.Sub: operator.sub,
        ast.Mult: operator.mul,
        ast.Div: operator.truediv,
        ast.Pow: operator.pow
    }

    def eval_expr(node):
        if isinstance(node, ast.Num):
            return node.n
        elif isinstance(node, ast.BinOp):
            return ops[type(node.op)](eval_expr(node.left), eval_expr(node.right))
        elif isinstance(node, ast.UnaryOp):
            return -eval_expr(node.operand)
        else:
            raise ValueError(f"Unsupported expression: {node}")

    tree = ast.parse(expression, mode='eval')
    return eval_expr(tree.body)


def web_search(query: str) -> str:
    """Recherche sur le web (simulation)."""
    # En production, utiliser une vraie API (SerpAPI, Google Custom Search, etc.)
    mock_results = {
        "population Tokyo 2026": "La population de Tokyo en 2026 est estim√©e √† 14,1 millions d'habitants.",
        "capital of France": "The capital of France is Paris.",
        "Python release date": "Python was first released on February 20, 1991.",
    }

    for key, value in mock_results.items():
        if key.lower() in query.lower():
            return value

    return f"No results found for '{query}'."


def python_interpreter(code: str) -> str:
    """Ex√©cute du code Python (ATTENTION : dangereux en production sans sandbox)."""
    # En production : utiliser un environnement isol√© (Docker, E2B, etc.)
    try:
        # Rediriger stdout
        from io import StringIO
        import sys

        old_stdout = sys.stdout
        sys.stdout = StringIO()

        # Ex√©cuter
        exec(code, {"__builtins__": __builtins__})

        # R√©cup√©rer l'output
        output = sys.stdout.getvalue()
        sys.stdout = old_stdout

        return output if output else "Code executed successfully (no output)."
    except Exception as e:
        return f"Error: {str(e)}"


# --- Exemple d'utilisation ---

# Mock LLM pour l'exemple (en production, utiliser OpenAI/Anthropic)
class MockLLM:
    """LLM simul√© pour la d√©mo."""

    def __init__(self):
        self.step = 0
        self.responses = [
            # Step 1 : Calcul simple
            """Thought: I need to calculate 157 * 23. I'll use the Calculator tool.
Action: Calculator[157 * 23]""",

            # Step 2 : R√©ponse finale
            """Thought: The calculator returned 3611. This is the final answer.
Action: Finish[157 √ó 23 = 3611]"""
        ]

    def generate(self, prompt: str) -> str:
        response = self.responses[self.step] if self.step < len(self.responses) else "Action: Finish[Done]"
        self.step += 1
        return response


# Cr√©er les outils
tools = [
    Tool("Calculator", "Evaluates mathematical expressions. Example: Calculator[2+2]", calculator),
    Tool("Search", "Searches the web for information. Example: Search[population of Tokyo]", web_search),
    Tool("Python", "Executes Python code. Example: Python[print(2+2)]", python_interpreter),
]

# Cr√©er l'agent
llm = MockLLM()
agent = ReActAgent(llm, tools, max_steps=5, verbose=True)

# Ex√©cuter une t√¢che
result = agent.run("What is 157 multiplied by 23?")
print(f"\n\nüéØ R√âSULTAT FINAL : {result}")
```

**Sortie** :
```
============================================================
STEP 1
============================================================
Thought: I need to calculate 157 * 23. I'll use the Calculator tool.
Action: Calculator[157 * 23]

Observation: 3611

============================================================
STEP 2
============================================================
Thought: The calculator returned 3611. This is the final answer.
Action: Finish[157 √ó 23 = 3611]

‚úÖ FINAL ANSWER: 157 √ó 23 = 3611


üéØ R√âSULTAT FINAL : 157 √ó 23 = 3611
```

---

## 3. Architectures d'Agents Avanc√©es

### 3.1 Agent avec M√©moire (Conversationnel)

Un agent sans m√©moire oublie tout entre les t√¢ches. Ajoutons une **m√©moire persistante** :

```python
class MemoryReActAgent(ReActAgent):
    """Agent ReAct avec m√©moire conversationnelle."""

    def __init__(self, llm, tools, max_steps=10, verbose=True):
        super().__init__(llm, tools, max_steps, verbose)
        self.conversation_history = []

    def run(self, task: str) -> str:
        """Ex√©cute une t√¢che en utilisant l'historique de conversation."""
        # Ajouter la t√¢che √† l'historique
        self.conversation_history.append(f"User: {task}")

        # Ex√©cuter ReAct (en incluant l'historique dans le prompt)
        result = super().run(task)

        # Sauvegarder la r√©ponse
        self.conversation_history.append(f"Assistant: {result}")

        return result

    def _build_prompt(self, task: str, scratchpad: List[str]) -> str:
        """Override pour inclure l'historique conversationnel."""
        tools_desc = self._build_tool_description()
        history = "\n\n".join(scratchpad) if scratchpad else "No actions yet."

        # Historique conversationnel
        conv_history = "\n".join(self.conversation_history[-10:])  # Garder les 10 derniers tours

        prompt = f"""You are an AI agent with memory of previous conversations.

Conversation history:
{conv_history}

Available tools:
{tools_desc}
- Finish: Use when you have the final answer. Format: Action: Finish[answer]

Current task: {task}

Previous actions for this task:
{history}

What should you do next?

Thought:"""

        return prompt


# Exemple : conversation multi-tours
agent_with_memory = MemoryReActAgent(MockLLM(), tools, verbose=False)

# Tour 1
response1 = agent_with_memory.run("What is the capital of France?")
print(f"User: What is the capital of France?")
print(f"Agent: {response1}\n")

# Tour 2 (r√©f√©rence au tour pr√©c√©dent)
response2 = agent_with_memory.run("What is its population?")
print(f"User: What is its population?")
print(f"Agent: {response2}")
# L'agent sait que "its" fait r√©f√©rence √† Paris gr√¢ce √† la m√©moire
```

---

### 3.2 Multi-Agent Systems

Plusieurs agents sp√©cialis√©s collaborent pour r√©soudre une t√¢che complexe.

```python
class MultiAgentSystem:
    """
    Syst√®me multi-agents : chaque agent a une sp√©cialit√©.

    Exemple :
    - ResearchAgent : cherche des informations
    - CodeAgent : √©crit du code
    - AnalysisAgent : analyse des donn√©es
    """

    def __init__(self, agents: Dict[str, ReActAgent]):
        """
        Args:
            agents: Dictionnaire {nom_agent: agent}
        """
        self.agents = agents
        self.coordinator_llm = None  # LLM qui d√©cide quel agent utiliser

    def run(self, task: str) -> str:
        """
        Coordonne plusieurs agents pour accomplir une t√¢che.

        Args:
            task: T√¢che √† accomplir

        Returns:
            R√©sultat final
        """
        # 1. Le coordinateur d√©cide quel agent utiliser
        agent_choice = self._choose_agent(task)

        # 2. D√©l√©guer la t√¢che √† l'agent choisi
        selected_agent = self.agents[agent_choice]
        result = selected_agent.run(task)

        return result

    def _choose_agent(self, task: str) -> str:
        """Choisit l'agent appropri√© pour la t√¢che."""
        # Simplifi√© : bas√© sur des mots-cl√©s
        task_lower = task.lower()

        if "search" in task_lower or "find" in task_lower:
            return "research"
        elif "code" in task_lower or "python" in task_lower:
            return "code"
        elif "analyze" in task_lower or "calculate" in task_lower:
            return "analysis"
        else:
            return "general"


# Exemple
research_agent = ReActAgent(llm, [Tool("Search", "...", web_search)])
code_agent = ReActAgent(llm, [Tool("Python", "...", python_interpreter)])
analysis_agent = ReActAgent(llm, [Tool("Calculator", "...", calculator)])

multi_system = MultiAgentSystem({
    "research": research_agent,
    "code": code_agent,
    "analysis": analysis_agent,
    "general": ReActAgent(llm, tools)
})

# Utilisation
result = multi_system.run("Search for the population of Tokyo")
# ‚Üí D√©l√®gue automatiquement au research_agent
```

---

### 3.3 Plan-and-Execute

Au lieu de r√©agir √† chaque √©tape, l'agent **planifie** d'abord toutes les √©tapes, puis les ex√©cute.

```python
class PlanAndExecuteAgent:
    """
    Agent qui planifie avant d'agir.

    1. D√©compose la t√¢che en sous-t√¢ches
    2. Ex√©cute chaque sous-t√¢che s√©quentiellement
    3. Ajuste le plan si n√©cessaire
    """

    def __init__(self, llm, tools):
        self.llm = llm
        self.executor = ReActAgent(llm, tools, verbose=False)

    def run(self, task: str) -> str:
        """
        Planifie puis ex√©cute.

        Args:
            task: T√¢che complexe

        Returns:
            R√©sultat final
        """
        # 1. Planifier
        plan = self._create_plan(task)
        print(f"üìã PLAN:\n{plan}\n")

        # 2. Ex√©cuter chaque √©tape
        results = []
        for i, step in enumerate(plan):
            print(f"‚ñ∂Ô∏è  Executing step {i+1}: {step}")
            result = self.executor.run(step)
            results.append(result)
            print(f"‚úÖ Result: {result}\n")

        # 3. Synth√©tiser
        final_answer = self._synthesize(task, results)
        return final_answer

    def _create_plan(self, task: str) -> List[str]:
        """Cr√©e un plan d'action."""
        prompt = f"""Break down the following task into a sequence of simple steps.

Task: {task}

Steps:
1."""

        response = self.llm.generate(prompt)

        # Parser les √©tapes (simplifi√©)
        steps = [line.strip() for line in response.split('\n') if line.strip() and line[0].isdigit()]
        return steps

    def _synthesize(self, task: str, results: List[str]) -> str:
        """Synth√©tise les r√©sultats."""
        prompt = f"""Given the following task and intermediate results, provide a final answer.

Task: {task}

Intermediate results:
{chr(10).join(f'{i+1}. {r}' for i, r in enumerate(results))}

Final answer:"""

        return self.llm.generate(prompt)
```

---

## 4. Gestion des Erreurs et Robustesse

### üé≠ Dialogue : Quand √áa Se Passe Mal

**Alice** : Bob, j'ai impl√©ment√© un agent ReAct, mais parfois il tourne en boucle ou g√©n√®re des erreurs bizarres. Comment g√©rer √ßa ?

**Bob** : Tr√®s bonne question ! Les agents peuvent √©chouer de plusieurs mani√®res :

**Bob** : 1. **Boucles infinies** : l'agent r√©p√®te la m√™me action sans progresser.

**Alice** : Comment d√©tecter √ßa ?

**Bob** : On garde un historique des actions. Si la m√™me action est r√©p√©t√©e 3 fois de suite, on intervient.

**Bob** : 2. **Hallucination d'outils** : l'agent invente un outil qui n'existe pas.

**Alice** : Genre "Action: MagicSolver[problem]" ?

**Bob** : Exactement ! Solution : valider que l'outil existe avant d'ex√©cuter, et retourner un message d'erreur clair.

**Bob** : 3. **Arguments invalides** : l'agent utilise le bon outil mais avec de mauvais arguments.

**Alice** : Comme "Calculator[deux plus deux]" au lieu de "Calculator[2+2]" ?

**Bob** : Pr√©cis√©ment. Il faut valider les arguments et donner des exemples clairs dans le prompt.

**Bob** : 4. **Timeout** : certains outils (recherche web, API) peuvent prendre trop de temps.

**Alice** : On met un timeout sur chaque outil ?

**Bob** : Oui, et on retourne une observation comme "Error: Tool timed out after 30s".

**Alice** : Et si aucune de ces solutions ne fonctionne ?

**Bob** : On a toujours un **max_steps**. Apr√®s N it√©rations, on arr√™te et on retourne "Task failed" avec les logs pour debug.

---

### 4.1 Impl√©mentation Robuste

```python
from collections import Counter
import time

class RobustReActAgent(ReActAgent):
    """Agent ReAct avec gestion d'erreurs avanc√©e."""

    def __init__(self, llm, tools, max_steps=10, verbose=True,
                 tool_timeout=30, max_retries=2):
        super().__init__(llm, tools, max_steps, verbose)
        self.tool_timeout = tool_timeout
        self.max_retries = max_retries
        self.action_history = []

    def run(self, task: str) -> str:
        """Ex√©cute avec gestion d'erreurs robuste."""
        scratchpad = []

        for step in range(self.max_steps):
            try:
                # V√©rifier les boucles infinies
                if self._is_stuck():
                    return self._handle_stuck(task, scratchpad)

                # G√©n√©rer la r√©ponse
                prompt = self._build_prompt(task, scratchpad)
                response = self.llm.generate(prompt)

                if self.verbose:
                    print(f"\n{'='*60}\nSTEP {step + 1}\n{'='*60}\n{response}")

                # V√©rifier si termin√©
                final_answer = self._check_finish(response)
                if final_answer:
                    return final_answer

                # Parser l'action
                action = self._parse_action(response)
                if not action:
                    scratchpad.append(self._handle_parse_error(response))
                    continue

                tool_name, argument = action
                self.action_history.append((tool_name, argument))

                # Ex√©cuter l'outil avec timeout et retry
                observation = self._execute_tool_safe(tool_name, argument)

                if self.verbose:
                    print(f"\nObservation: {observation}")

                scratchpad.append(f"{response}\nObservation: {observation}")

            except Exception as e:
                # Erreur inattendue
                error_msg = f"Unexpected error in step {step}: {str(e)}"
                print(f"‚ö†Ô∏è  {error_msg}")
                scratchpad.append(f"Error: {error_msg}")
                continue

        return f"Failed to complete task within {self.max_steps} steps."

    def _is_stuck(self) -> bool:
        """D√©tecte si l'agent est bloqu√© dans une boucle."""
        if len(self.action_history) < 3:
            return False

        # V√©rifier si les 3 derni√®res actions sont identiques
        last_3 = self.action_history[-3:]
        if len(set(last_3)) == 1:
            return True

        # V√©rifier si on alterne entre 2 actions (A->B->A->B)
        if len(self.action_history) >= 4:
            last_4 = self.action_history[-4:]
            if last_4[0] == last_4[2] and last_4[1] == last_4[3]:
                return True

        return False

    def _handle_stuck(self, task: str, scratchpad: List[str]) -> str:
        """G√®re le cas o√π l'agent est bloqu√©."""
        print("‚ö†Ô∏è  Agent appears to be stuck in a loop. Attempting recovery...")

        # Demander au LLM de r√©fl√©chir diff√©remment
        recovery_prompt = f"""You seem to be stuck repeating the same actions.

Task: {task}

Previous actions:
{chr(10).join(str(a) for a in self.action_history[-5:])}

Think of a DIFFERENT approach to solve this task. What else could you try?

Thought:"""

        response = self.llm.generate(recovery_prompt)

        return f"Recovery attempt: {response}"

    def _execute_tool_safe(self, tool_name: str, argument: str) -> str:
        """Ex√©cute un outil avec timeout et retry."""
        if tool_name not in self.tools:
            available = ", ".join(self.tools.keys())
            return f"Error: Tool '{tool_name}' not found. Available tools: {available}"

        tool = self.tools[tool_name]

        # Retry logic
        for attempt in range(self.max_retries):
            try:
                result = tool.run(argument)
                return result

            except TimeoutError as e:
                if attempt < self.max_retries - 1:
                    print(f"‚ö†Ô∏è  Tool timed out, retrying ({attempt + 1}/{self.max_retries})...")
                    time.sleep(1)
                else:
                    return f"Error: {str(e)}"

            except Exception as e:
                return f"Error executing {tool_name}: {str(e)}"

        return "Error: Max retries exceeded"

    def _handle_parse_error(self, response: str) -> str:
        """G√®re les erreurs de parsing."""
        return f"""Error: Could not parse action from response.

Your response: {response}

Please use the correct format:
Thought: [your reasoning]
Action: ToolName[argument]

Example:
Thought: I need to search for information about Python.
Action: Search[Python programming language]"""
```

---

## 5. Optimisation des Co√ªts et Performances

### 5.1 Le Probl√®me du Co√ªt

Chaque appel au LLM co√ªte de l'argent :
- GPT-4 : ~$0.03 / 1K tokens input, $0.06 / 1K tokens output
- Un agent qui fait 10 it√©rations avec 2K tokens/it√©ration = 20K tokens
- Co√ªt : ~$0.60-$1.20 par t√¢che

**Solution 1** : Caching des r√©sultats

```python
import hashlib
import json

class CachedTool(Tool):
    """Outil avec cache pour √©viter les appels redondants."""

    def __init__(self, name, description, func):
        super().__init__(name, description, func)
        self.cache = {}

    def run(self, query: str) -> str:
        """Ex√©cute avec cache."""
        # Hash de la query
        cache_key = hashlib.md5(query.encode()).hexdigest()

        if cache_key in self.cache:
            print(f"üíæ Cache hit for {self.name}")
            return self.cache[cache_key]

        # Ex√©cuter
        result = super().run(query)

        # Sauvegarder
        self.cache[cache_key] = result

        return result
```

**Solution 2** : Utiliser un mod√®le plus petit pour les t√¢ches simples

```python
class HybridAgent(ReActAgent):
    """Agent qui utilise GPT-4 pour la planification, GPT-3.5 pour l'ex√©cution."""

    def __init__(self, planner_llm, executor_llm, tools, **kwargs):
        super().__init__(planner_llm, tools, **kwargs)
        self.executor_llm = executor_llm

    def run(self, task: str) -> str:
        """Utilise le planner pour d√©cider, l'executor pour agir."""
        # √âtape 1 : Planifier avec GPT-4 (cher mais intelligent)
        plan = self.planner_llm.generate(f"Create a plan for: {task}")

        # √âtape 2 : Ex√©cuter avec GPT-3.5 (moins cher)
        # ... (logique d'ex√©cution)

        return result
```

**Solution 3** : Limiter la longueur du contexte

```python
def _build_prompt(self, task: str, scratchpad: List[str]) -> str:
    """Optimis√© : garde uniquement les N derni√®res observations."""
    # Garder seulement les 3 derni√®res actions au lieu de tout l'historique
    recent_history = scratchpad[-3:] if len(scratchpad) > 3 else scratchpad

    # ... (reste du prompt)
```

---

## üß† Quiz Interactif

### Question 1
**Quelle est la diff√©rence entre un LLM et un Agent LLM ?**

A) Un Agent LLM est plus grand (plus de param√®tres)
B) Un Agent LLM peut interagir avec des outils externes
C) Un Agent LLM est plus rapide
D) Aucune diff√©rence, ce sont des synonymes

<details>
<summary>üëâ Voir la r√©ponse</summary>

**R√©ponse : B**

Un **LLM** (comme GPT-4) g√©n√®re du texte bas√© sur un prompt. Il raisonne mais ne peut pas **agir**.

Un **Agent LLM** combine un LLM avec des **outils** (APIs, calculatrices, bases de donn√©es) qui lui permettent d'interagir avec l'environnement externe.

**Analogie** :
- LLM = Un expert qui r√©fl√©chit et conseille
- Agent LLM = Un assistant qui r√©fl√©chit ET ex√©cute des actions
</details>

---

### Question 2
**Que signifie "ReAct" ?**

A) Reactive Acting
B) Reasoning + Acting
C) Real-time Action
D) Recursive Activation

<details>
<summary>üëâ Voir la r√©ponse</summary>

**R√©ponse : B**

**ReAct** = **Rea**soning + **Act**ing

C'est un framework o√π l'agent alterne entre :
1. **Thought** (Reasoning) : r√©fl√©chir √† la prochaine √©tape
2. **Action** (Acting) : ex√©cuter un outil
3. **Observation** : observer le r√©sultat

Cette boucle continue jusqu'√† obtenir la r√©ponse finale.

**Paper original** : "ReAct: Synergizing Reasoning and Acting in Language Models" (Yao et al., 2022)
</details>

---

### Question 3
**Pourquoi un agent peut-il tomber dans une boucle infinie ?**

A) Le LLM oublie ce qu'il a d√©j√† fait
B) Les outils donnent toujours les m√™mes r√©sultats
C) L'agent r√©p√®te la m√™me action sans progresser vers la solution
D) C'est impossible avec les agents modernes

<details>
<summary>üëâ Voir la r√©ponse</summary>

**R√©ponse : C**

Un agent peut se bloquer en r√©p√©tant les m√™mes actions si :
- Le LLM ne r√©alise pas que l'approche ne fonctionne pas
- Les observations ne fournissent pas assez d'informations pour progresser
- Le prompt ne guide pas suffisamment le LLM

**Solutions** :
1. D√©tecter les r√©p√©titions dans l'historique d'actions
2. Limiter le nombre d'it√©rations (`max_steps`)
3. Impl√©menter une strat√©gie de "recovery" (essayer une approche diff√©rente)
4. Am√©liorer le prompt pour encourager la diversit√© des approches
</details>

---

### Question 4
**Quel est l'avantage principal d'un syst√®me multi-agents ?**

A) Moins cher en tokens
B) Sp√©cialisation : chaque agent est expert dans son domaine
C) Plus rapide
D) Aucun avantage, c'est juste plus complexe

<details>
<summary>üëâ Voir la r√©ponse</summary>

**R√©ponse : B**

Un **syst√®me multi-agents** permet de :
- Avoir des agents **sp√©cialis√©s** (ResearchAgent, CodeAgent, AnalysisAgent)
- Chaque agent a ses propres outils et expertise
- D√©l√©guer les sous-t√¢ches √† l'agent le plus comp√©tent
- Parall√©liser les t√¢ches (plusieurs agents travaillent en m√™me temps)

**Exemple** :
- Une t√¢che complexe : "Analyser les tendances du march√© crypto et g√©n√©rer un rapport Python"
- ResearchAgent ‚Üí cherche les donn√©es
- AnalysisAgent ‚Üí analyse les chiffres
- CodeAgent ‚Üí g√©n√®re le script Python
- WriterAgent ‚Üí r√©dige le rapport final
</details>

---

### Question 5
**Comment optimiser les co√ªts d'un agent qui fait beaucoup d'appels LLM ?**

A) Utiliser un mod√®le plus petit pour les t√¢ches simples
B) Cacher les r√©sultats des outils
C) Limiter la longueur du contexte (garder seulement les derni√®res N actions)
D) Toutes les r√©ponses ci-dessus

<details>
<summary>üëâ Voir la r√©ponse</summary>

**R√©ponse : D**

Toutes ces strat√©gies r√©duisent les co√ªts :

**A) Mod√®le hybride** :
- GPT-4 pour la planification (t√¢ches complexes)
- GPT-3.5-turbo pour l'ex√©cution (t√¢ches simples)
- √âconomie : ~10x moins cher pour les actions basiques

**B) Caching** :
- Si l'outil est appel√© 2 fois avec le m√™me argument, utiliser le r√©sultat en cache
- Exemple : chercher "population Tokyo" ‚Üí pas besoin de refaire l'API call

**C) Contexte limit√©** :
- Au lieu d'envoyer tout l'historique (1000+ tokens), garder seulement les 3-5 derni√®res actions
- R√©duit la taille du prompt de 70-80%

**Bonus** : Batching (traiter plusieurs t√¢ches en un seul appel si possible)
</details>

---

### Question 6
**Qu'est-ce qu'une architecture "Plan-and-Execute" ?**

A) L'agent planifie toutes les √©tapes avant de les ex√©cuter
B) L'agent ex√©cute d'abord, puis planifie
C) L'agent ne planifie jamais, il r√©agit uniquement
D) C'est juste un autre nom pour ReAct

<details>
<summary>üëâ Voir la r√©ponse</summary>

**R√©ponse : A**

**Plan-and-Execute** :
1. **Phase de planification** : Le LLM d√©compose la t√¢che en sous-t√¢ches
   - "Trouver la population de Tokyo"
   - "Diviser par 50,000"
   - "Formater la r√©ponse"

2. **Phase d'ex√©cution** : Ex√©cuter chaque sous-t√¢che s√©quentiellement

**Avantages** :
- Plus structur√© que ReAct (qui d√©cide au fur et √† mesure)
- Bon pour les t√¢ches complexes n√©cessitant plusieurs √©tapes
- Permet de parall√©liser certaines sous-t√¢ches

**Inconv√©nients** :
- Moins flexible (si une √©tape √©choue, le plan peut devenir invalide)
- N√©cessite 2 appels LLM (planification + ex√©cution)

**ReAct vs Plan-and-Execute** :
- ReAct = r√©actif, adaptatif, interleaved reasoning
- Plan-and-Execute = proactif, structur√©, upfront planning
</details>

---

## üíª Exercices Pratiques

### Exercice 1 : Cr√©er un Agent Multi-Outils

**Objectif** : Impl√©menter un agent ReAct avec 3 outils : Calculator, Wikipedia Search, et Weather API.

**Consignes** :
1. Impl√©menter les 3 outils
2. Cr√©er un agent ReAct
3. Tester avec des t√¢ches complexes n√©cessitant plusieurs outils

<details>
<summary>üëâ Voir la solution compl√®te</summary>

Solution fournie dans le code ci-dessus. Utilisez la classe `ReActAgent` avec les outils appropri√©s et testez avec des t√¢ches multi-√©tapes comme calculer des int√©r√™ts compos√©s combin√©s avec des recherches Wikipedia.
</details>

---

### Exercice 2 : Impl√©menter la D√©tection de Boucles

**Objectif** : Am√©liorer l'agent pour d√©tecter et g√©rer les boucles infinies.

<details>
<summary>üëâ Voir la solution</summary>

Voir la classe `RobustReActAgent` impl√©ment√©e dans la section 4.1.

**Points cl√©s** :
1. Garder un historique des actions
2. D√©tecter si les 3 derni√®res actions sont identiques
3. D√©tecter les alternances A‚ÜíB‚ÜíA‚ÜíB
4. Proposer une strat√©gie de recovery
</details>

---

## üìö R√©sum√© du Chapitre

### Points Cl√©s

1. **Agent LLM** = LLM (cerveau) + Outils (mains) + Boucle de contr√¥le

2. **ReAct** = Reasoning (pens√©e) + Acting (action) + Observation
   - Alterne entre raisonnement et ex√©cution d'outils
   - Transparent et tra√ßable
   - Auto-correctif

3. **Architectures avanc√©es** :
   - Agents avec m√©moire (conversationnels)
   - Multi-agents (sp√©cialisation)
   - Plan-and-Execute (planification upfront)

4. **D√©fis** :
   - Boucles infinies ‚Üí d√©tection et recovery
   - Erreurs d'outils ‚Üí retry et fallback
   - Co√ªts ‚Üí caching, mod√®les hybrides, contexte limit√©

5. **Production** :
   - Logging complet
   - M√©triques (success rate, latence, co√ªts)
   - Persistence des traces
   - Gestion d'erreurs robuste

---

## üöÄ Prochaine √âtape

Dans le **Chapitre 15 : D√©ploiement et Production**, nous explorerons :
- Servir un LLM en production (FastAPI, vLLM, TGI)
- Optimisations d'inf√©rence (quantization, batching)
- Monitoring et observabilit√©
- Scaling horizontal et vertical
- Co√ªts et SLAs

**√Ä tr√®s bient√¥t !** üéâ

---

## üìñ R√©f√©rences

### Papers Fondamentaux
1. Yao et al. (2022). *ReAct: Synergizing Reasoning and Acting in Language Models*
2. Schick et al. (2023). *Toolformer: Language Models Can Teach Themselves to Use Tools*
3. Nakano et al. (2021). *WebGPT: Browser-assisted question-answering with human feedback*
4. Significant-Gravitas. *AutoGPT* (2023) ‚Äî Premier agent autonome viral

### Frameworks
- **LangChain** : Framework Python pour agents LLM
- **AutoGPT** : Agent autonome open-source
- **BabyAGI** : Agent minimaliste avec planification
- **AgentGPT** : Interface web pour agents autonomes

### Outils Utiles
- **SerpAPI** : API de recherche Google
- **E2B** : Environnement d'ex√©cution de code s√©curis√©
- **LangSmith** : Debugging et monitoring d'agents

---

*Fin du Chapitre 14*

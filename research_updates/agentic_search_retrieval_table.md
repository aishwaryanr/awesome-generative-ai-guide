# :star2: Agentic Search and Retrieval Papers
### (January 2025 to February 2026)

The field of Agentic Search and Retrieval has emerged as a transformative paradigm, moving beyond traditional keyword-based search to intelligent systems powered by autonomous AI agents. These agents leverage reasoning, planning, tool use, and multi-agent collaboration to tackle complex information-seeking tasks that require multi-step synthesis, iterative retrieval, and dynamic adaptation. This table provides summaries of impactful papers published between January 2025 and February 2026, covering various aspects of agentic systems for search and retrieval.

The key research areas include:

1. **Agentic Search Survey**: Comprehensive overviews of agentic search and retrieval methods.
2. **Agentic Search Enhancement**: Methods and frameworks for improving agentic search capabilities.
3. **Deep Research Agents**: Agents capable of multi-step research, synthesis, and report generation.
4. **Agent Benchmarks & Evaluation**: Assessment frameworks for measuring agent capabilities.
5. **Multi-Agent Systems**: Systems using multiple cooperating agents for information seeking.
6. **Web Agents**: Agents specialized for web navigation and search tasks.
7. **Agent Memory & Reasoning**: Memory systems and reasoning capabilities for agents.
8. **Agent Frameworks**: Open-source tools and frameworks for building agentic systems.
9. **Long-Horizon Agents**: Agents designed for extended, complex tasks.
10. **Interactive Agents**: Agents that actively interact with users or systems.

This table will continue to be updated regularly, so stay tuned for more updates!

| Title | Description | Tags | Month |
|-------|-------------|------|------|
| [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634) | This paper proposes WideSeek-R1, a multi-agent system trained via reinforcement learning that introduces "width scaling" as a complementary dimension to depth scaling for broad information-seeking tasks. The lead-agent-subagent framework achieves 40.0% F1 score on the WideSearch benchmark with a 4B model, matching the performance of DeepSeek-R1-671B (a much larger single agent) through effective parallelization with isolated contexts and specialized tools. The approach demonstrates consistent performance gains with increased parallel subagents. | Multi-Agent Systems | February 2026 |
| [A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces](https://arxiv.org/abs/2602.03442) | This paper introduces an agentic RAG framework that exposes hierarchical retrieval interfaces (keyword search, semantic search, and chunk read) directly to the model, allowing it to dynamically adapt retrieval decisions across multiple granularities. The approach achieves 94.5% on HotpotQA and 89.7% on 2WikiMultiHop with GPT-4o-mini while using comparable or fewer retrieved tokens than existing methods, demonstrating efficient scaling with model improvements. | Deep Research Agents | February 2026 |
| [MARS: Modular Agent with Reflective Search for Automated AI Research](https://arxiv.org/abs/2602.02660) | This paper presents MARS, a modular framework for automating AI research that uses budget-aware planning via cost-constrained Monte Carlo Tree Search, modular construction through a Design-Decompose-Implement pipeline, and comparative reflective memory to address credit assignment. MARS achieves state-of-the-art performance among open-source frameworks on MLE-Bench, with 63% of utilized lessons originating from cross-branch transfer, demonstrating effective generalization of insights across different search paths. | Deep Research Agents | February 2026 |
| [SAGE: Benchmarking and Improving Retrieval for Deep Research Agents](https://arxiv.org/abs/2602.05975) | This paper introduces a benchmark for scientific literature retrieval with 1,200 queries across four domains and a 200,000 paper corpus, revealing that traditional BM25 significantly outperforms LLM-based retrievers by approximately 30% because existing agents generate keyword-oriented sub-queries. The paper proposes a corpus-level test-time scaling framework using LLMs to augment documents with metadata and keywords, achieving 8% improvement on short-form questions and 2% improvement on open-ended questions. | Agent Benchmarks & Evaluation | February 2026 |
| [DeepResearchEval: An Automated Framework for Deep Research Task Construction and Agentic Evaluation](https://arxiv.org/abs/2601.09688) | This paper presents an automated framework for creating complex research tasks through persona-driven generation with two-stage filtering (task qualification and search necessity) and evaluating them through adaptive point-wise quality evaluation that dynamically derives task-specific dimensions and criteria. The framework includes active fact-checking that autonomously extracts and verifies report statements via web search even when citations are missing, addressing the challenge of evaluating deep research systems without annotation-intensive task construction or static evaluation dimensions. | Agent Benchmarks & Evaluation | January 2026 |
| [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538) | This paper explores agentic reasoning capabilities for large language models, examining how LLMs can be enhanced with autonomous reasoning, planning, and decision-making abilities to tackle complex tasks requiring multi-step inference and adaptive strategies. The work investigates the integration of reasoning mechanisms into agentic workflows for improved performance on knowledge-intensive and reasoning-demanding tasks. | Agent Memory & Reasoning | January 2026 |
| [Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning](https://arxiv.org/abs/2601.06943) | This paper introduces a benchmark for evaluating agentic video reasoning systems that combine video understanding with web search capabilities. The benchmark tests agents' ability to analyze video content, identify information gaps, formulate search queries, and synthesize findings from multiple sources to answer complex questions about video content, representing a novel multimodal extension of deep research capabilities. | Agent Benchmarks & Evaluation | January 2026 |
| [InteractComp: Evaluating Search Agents With Ambiguous Queries](https://arxiv.org/abs/2510.24668) | This paper introduces InteractComp, a benchmark with 210 expert-curated questions across 9 domains using target-distractor methodology to evaluate whether search agents can recognize query ambiguity and actively interact to resolve it. Evaluation of 17 models reveals the best model achieves only 13.73% accuracy with ambiguous queries (versus 71.50% with complete context), exposing systematic overconfidence. Forced interaction produces dramatic accuracy gains, demonstrating latent capabilities that current strategies fail to engage. | Agent Benchmarks & Evaluation | October 2025 |
| [WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research](https://arxiv.org/abs/2509.13312) | This paper presents WebWeaver, a dual-agent framework that emulates human research processes through a Planner Agent (iteratively interleaving evidence acquisition with outline optimization) and a Writer Agent (executing hierarchical retrieval and section-by-section composition). The framework addresses limitations of static pipelines and one-shot generation by performing targeted retrieval of only necessary evidence for each section, achieving state-of-the-art results on DeepResearch Bench, DeepConsult, and DeepResearchGym. | Deep Research Agents | September 2025 |
| [WideSearch: Benchmarking Agentic Broad Info-Seeking](https://arxiv.org/abs/2508.07999) | This paper introduces WideSearch, a benchmark with 200 manually curated questions (100 English, 100 Chinese) from 15+ domains designed to evaluate agent reliability on large-scale information collection tasks. Testing 10+ state-of-the-art systems including single-agent, multi-agent frameworks, and end-to-end commercial systems reveals most achieve ~0% success rate with the best performer reaching only 5%, while human testers achieve near 100% success, demonstrating critical deficiencies in current LLM-based search agents. | Agent Benchmarks & Evaluation | August 2025 |
| [Deep Research: A Survey of Autonomous Research Agents](https://arxiv.org/abs/2508.12752) | This comprehensive survey examines how large language models power autonomous agents through four stages: planning, question development, web exploration, and report generation. The paper documents key challenges at each stage, categorizes methods addressing them, summarizes recent optimization techniques and benchmarks, and discusses open challenges for developing more capable and trustworthy deep research agents. The work provides a systematic roadmap for understanding and advancing autonomous research systems. | Agentic Search Survey | August 2025 |
| [WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent](https://arxiv.org/abs/2508.05748) | This paper presents WebWatcher, a vision-language agent designed for deep research and web exploration that can process both textual and visual information during research tasks. The system represents an advancement in multimodal deep research capabilities, enabling agents to analyze images, charts, and diagrams alongside text to gather comprehensive information for complex research questions. | Deep Research Agents | August 2025 |
| [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414) | This paper introduces Cognitive Kernel-Pro, a fully open-source multi-module agent framework that addresses accessibility limitations of closed-source systems. The framework curates high-quality training data (queries, trajectories, verifiable answers) across web, file, code, and general reasoning domains, and introduces novel test-time strategies including agent reflection and voting mechanisms. The 8B-parameter model achieves state-of-the-art performance on GAIA benchmark, surpassing previous systems like WebDancer and WebSailor while maintaining maximum accessibility for the research community. | Agent Frameworks | August 2025 |
| [ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning](https://arxiv.org/abs/2508.10419) | This paper introduces ComoRAG, a cognitive-inspired RAG system that mimics human reasoning through iterative cycles while interacting with a dynamic memory workspace. The system generates probing queries, retrieves evidence, and consolidates insights into a global memory pool to support coherent context for complex narrative comprehension. Evaluated on four long-context benchmarks (200K+ tokens), ComoRAG outperforms strong RAG baselines with up to 11% relative gains, particularly excelling on queries requiring global comprehension. | Agent Memory & Reasoning | August 2025 |
| [From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents](https://arxiv.org/abs/2506.18959) | This paper argues for a paradigm shift from traditional keyword-based search to interactive, agent-based systems where LLMs endowed with reasoning and agentic capabilities enable autonomous reasoning combined with iterative retrieval and synthesis in feedback loops. The work introduces a test-time scaling law framework to measure how computational depth affects reasoning and search performance, demonstrating that agentic deep research significantly outperforms existing approaches. The paper curates community resources including industry products, research papers, benchmark datasets, and open-source implementations. | Agentic Search Survey | June 2025 |
| [Open Deep Search: Democratizing Search with Open-source Reasoning Agents](https://arxiv.org/abs/2503.20201) | This paper introduces Open Deep Search (ODS), a two-component framework consisting of a novel web search tool and an open reasoning agent that interprets tasks and orchestrates action sequences. Working with any base LLM (demonstrated with DeepSeek-R1), ODS improves GPT-4o Search Preview by 9.7% accuracy on the FRAMES benchmark, achieving 88.3% on SimpleQA (vs 82.4% for DeepSeek-R1 alone) and 75.3% on FRAMES (vs 30.1% alone). The work demonstrates that open-source solutions can achieve state-of-the-art performance, democratizing access to advanced search capabilities previously dominated by proprietary systems. | Agentic Search Enhancement | March 2025 |
| [Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning](https://arxiv.org/abs/2503.09516) | This paper extends DeepSeek-R1 by training LLMs to autonomously generate multiple search queries during step-by-step reasoning using reinforcement learning. The approach optimizes multi-turn retrieval interaction through retrieved token masking for stable RL training and simple outcome-based rewards. Search-R1 achieves significant improvements across seven QA datasets: 26% for Qwen2.5-7B, 21% for Qwen2.5-3B, and 10% for LLaMA3.2-3B, outperforming state-of-the-art baselines while providing empirical insights into RL optimization methods and response dynamics in retrieval-augmented reasoning. | Agentic Search Enhancement | March 2025 |
| [PaSa: An LLM Agent for Comprehensive Academic Paper Search](https://arxiv.org/abs/2501.10120) | This paper presents PaSa, an advanced Paper Search agent powered by LLMs that autonomously invokes search tools, reads papers, and selects relevant references for comprehensive scholarly queries. Optimized using reinforcement learning on AutoScholarQuery (35k fine-grained academic queries) and RealScholarQuery benchmark, PaSa-7B surpasses Google with GPT-4o by 37.78% in recall@20 and 39.90% in recall@50, outperforming baselines including Google Scholar, GPT-4o, GPT-o1, and ChatGPT. The model, datasets, and code are publicly available, currently supporting Computer Science with additional fields planned. | Deep Research Agents | January 2025 |
| [Search-o1: Agentic Search-Enhanced Large Reasoning Models](https://arxiv.org/abs/2501.05366) | This paper introduces Search-o1, the first framework to integrate agentic search workflow into o1-like reasoning processes, addressing knowledge insufficiency during extended reasoning by enabling dynamic retrieval when the model encounters uncertain knowledge points. The framework combines an agentic RAG mechanism with a Reason-in-Documents module that analyzes retrieved information before injection, minimizing noise while preserving coherent reasoning flow. Search-o1 demonstrates strong performance across five complex reasoning domains (science, mathematics, coding) and six open-domain QA benchmarks, improving trustworthiness and applicability of large reasoning models. | Agentic Search Enhancement | January 2025 |
| [Agent Laboratory: Using LLM Agents as Research Assistants](https://arxiv.org/abs/2501.04227) | This paper presents Agent Laboratory, an LLM-based autonomous framework that accelerates scientific research by automating the entire process from initial idea to final report through three stages: literature review, experimentation, and report writing. Driven by o1-preview, the framework generates the highest quality research outcomes, with generated ML code achieving state-of-the-art performance compared to existing methods. Human feedback at each stage significantly improves research quality while achieving an 84% decrease in research expenses compared to previous autonomous research methods, enabling researchers to focus more on creative ideation. | Deep Research Agents | January 2025 |


<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>State of Applied AI in 2025</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="progress-bar" id="progress"></div>

    <div class="presentation" id="presentation">

        <!-- SLIDE 1: Title -->
        <div class="slide active slide-title">
            <h1>State of Applied AI<br><span class="muted" style="font-size: 0.7em;">in 2025</span></h1>
            <p class="subtitle">2025 Trends, Applied AI Challenges, and What to Look Forward to in 2026</p>
        </div>
        
        <!-- SLIDE 2: The Big Question -->
        <div class="slide slide-statement">
            <h2>What was the real breakthrough of 2025?</h2>
        </div>
        
        <!-- SLIDE 3: Not What You Think -->
        <div class="slide slide-statement">
            <h2>It wasn't just new model releases.</h2>
            <p class="small">Models got better, but that wasn't what moved the needle for teams actually shipping AI.</p>
        </div>
        
        <!-- SLIDE 4: The Answer -->
        <div class="slide slide-statement">
            <h2>It was <span class="blue">plumbing</span>.</h2>
            <p class="small">Standards emerged. Integration got easier. The boring work of making agents actually work finally started paying off. The unglamorous infrastructure work became the competitive advantage.</p>
        </div>
        
        <!-- SLIDE 5: What This Means -->
        <div class="slide slide-statement">
            <h2>The teams that shipped weren't the ones with the best models.</h2>
            <p class="small">They weren't stuck contemplating which model to use. They knew how to connect everything together:and that's what mattered.</p>
        </div>
        
        <!-- SLIDE 6: The Practitioner Reality -->
        <div class="slide slide-list">
            <h2>A Few Honest Lessons from 2025</h2>
            <ul>
                <li class="blue"><strong>Most of your time goes to integration.</strong> Not prompts, not model selection:connecting systems and handling edge cases.</li>
                <li class="green"><strong>Reliability beats capability.</strong> A predictable system is far better than something accurate but chaotic.</li>
                <li class="orange"><strong>The model is the easy part.</strong> The hard part is everything around it:context, tools, evaluation, deployment.</li>
                <li class="purple"><strong>Start narrower than you think.</strong> Build up to complex agents: making 10-step agents on day one only makes debugging harder.</li>
            </ul>
        </div>
        
        <!-- SLIDE 7: The Gap -->
        <div class="slide slide-vs">
            <div class="vs-box old">
                <span class="tag">What Most Teams Build</span>
                <h3>Impressive demos</h3>
                <p>Works in notebooks, fails in production. 95% never ship.</p>
            </div>
            <span class="vs-arrow">→</span>
            <div class="vs-box new">
                <span class="tag">What Actually Ships</span>
                <h3>Boring reliability</h3>
                <p>Predictable, observable, recoverable. Does less, works always.</p>
            </div>
        </div>
        
        <!-- SLIDE 9: Framework Visual -->
        <div class="slide slide-visual">
            <h2>The Applied AI Stack</h2>
            <svg class="framework-svg" viewBox="0 0 950 480" xmlns="http://www.w3.org/2000/svg" style="max-width: 1100px;">
                <g class="framework-layer">
                    <rect x="20" y="15" width="750" height="95" rx="8" fill="#3b82f6" opacity="0.15" stroke="#3b82f6" stroke-width="2"/>
                    <text x="30" y="38" fill="#3b82f6" font-weight="700" font-size="14">INPUT LAYER</text>
                    <rect x="30" y="50" width="170" height="50" rx="6" fill="#3b82f6"/><text x="115" y="80" text-anchor="middle" fill="white" font-size="11" font-weight="500">Multimodal Inputs</text>
                    <rect x="210" y="50" width="180" height="50" rx="6" fill="#3b82f6"/><text x="300" y="80" text-anchor="middle" fill="white" font-size="11" font-weight="500">Context Engineering</text>
                    <rect x="400" y="50" width="170" height="50" rx="6" fill="#3b82f6"/><text x="485" y="80" text-anchor="middle" fill="white" font-size="11" font-weight="500">Meta Prompting</text>
                    <rect x="580" y="50" width="180" height="50" rx="6" fill="#3b82f6"/><text x="670" y="80" text-anchor="middle" fill="white" font-size="10" font-weight="500">Auto Prompt Optimization</text>
                </g>
                <g class="framework-layer">
                    <rect x="20" y="120" width="750" height="95" rx="8" fill="#10b981" opacity="0.15" stroke="#10b981" stroke-width="2"/>
                    <text x="30" y="143" fill="#10b981" font-weight="700" font-size="14">DATA AND MODEL LAYER</text>
                    <rect x="30" y="155" width="115" height="50" rx="6" fill="#10b981"/><text x="87" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">Foundation Models</text>
                    <rect x="155" y="155" width="110" height="50" rx="6" fill="#10b981"/><text x="210" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">Long Context</text>
                    <rect x="275" y="155" width="90" height="50" rx="6" fill="#10b981"/><text x="320" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">RL + RLVR</text>
                    <rect x="375" y="155" width="110" height="50" rx="6" fill="#10b981"/><text x="430" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">Fine-Tuning</text>
                    <rect x="495" y="155" width="130" height="50" rx="6" fill="#10b981"/><text x="560" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">Hybrid Reasoning</text>
                    <rect x="635" y="155" width="125" height="50" rx="6" fill="#10b981"/><text x="697" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">Quantization</text>
                </g>
                <g class="framework-layer">
                    <rect x="20" y="225" width="750" height="95" rx="8" fill="#f97316" opacity="0.15" stroke="#f97316" stroke-width="2"/>
                    <text x="30" y="248" fill="#f97316" font-weight="700" font-size="14">APPLICATION LAYER</text>
                    <rect x="30" y="260" width="140" height="50" rx="6" fill="#f97316"/><text x="100" y="290" text-anchor="middle" fill="white" font-size="11" font-weight="500">RAG</text>
                    <rect x="180" y="260" width="140" height="50" rx="6" fill="#f97316"/><text x="250" y="290" text-anchor="middle" fill="white" font-size="11" font-weight="500">Agents</text>
                    <rect x="330" y="260" width="140" height="50" rx="6" fill="#f97316"/><text x="400" y="290" text-anchor="middle" fill="white" font-size="11" font-weight="500">Tool Calling</text>
                    <rect x="480" y="260" width="140" height="50" rx="6" fill="#f97316"/><text x="550" y="290" text-anchor="middle" fill="white" font-size="11" font-weight="500">Skills</text>
                    <rect x="630" y="260" width="130" height="50" rx="6" fill="#f97316"/><text x="695" y="290" text-anchor="middle" fill="white" font-size="10" font-weight="500">Agentic Frameworks</text>
                </g>
                <g class="framework-layer">
                    <rect x="20" y="330" width="750" height="95" rx="8" fill="#8b5cf6" opacity="0.15" stroke="#8b5cf6" stroke-width="2"/>
                    <text x="30" y="353" fill="#8b5cf6" font-weight="700" font-size="14">OUTPUT LAYER</text>
                    <rect x="30" y="365" width="360" height="50" rx="6" fill="#8b5cf6"/><text x="210" y="395" text-anchor="middle" fill="white" font-size="11" font-weight="500">Evals</text>
                    <rect x="400" y="365" width="360" height="50" rx="6" fill="#8b5cf6"/><text x="580" y="395" text-anchor="middle" fill="white" font-size="11" font-weight="500">Production Monitoring</text>
                </g>
                <g class="framework-layer">
                    <rect x="790" y="15" width="145" height="410" rx="8" fill="#ef4444" opacity="0.15" stroke="#ef4444" stroke-width="2"/>
                    <text x="862" y="42" text-anchor="middle" fill="#ef4444" font-weight="700" font-size="13">CHALLENGES</text>
                    <rect x="800" y="55" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="80" text-anchor="middle" fill="white" font-size="10" font-weight="500">Hallucinations</text>
                    <rect x="800" y="100" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="125" text-anchor="middle" fill="white" font-size="10" font-weight="500">Inconsistent Reasoning</text>
                    <rect x="800" y="145" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="170" text-anchor="middle" fill="white" font-size="10" font-weight="500">Over-Autonomy</text>
                    <rect x="800" y="190" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="215" text-anchor="middle" fill="white" font-size="10" font-weight="500">Poor Tool Grounding</text>
                    <rect x="800" y="235" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="260" text-anchor="middle" fill="white" font-size="10" font-weight="500">Long Context Drift</text>
                    <rect x="800" y="280" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="305" text-anchor="middle" fill="white" font-size="10" font-weight="500">Retrieval Issues</text>
                    <rect x="800" y="325" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="350" text-anchor="middle" fill="white" font-size="10" font-weight="500">Multi-Agent Errors</text>
                    <rect x="800" y="370" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="395" text-anchor="middle" fill="white" font-size="10" font-weight="500">Debugging</text>
                </g>
            </svg>
            <p class="caption">Four layers of the stack, plus the challenges that cut across all of them</p>
        </div>
        
        <!-- SLIDE 10: Agenda -->
        <div class="slide slide-list">
            <h2>What We'll Cover</h2>
            <ul>
                <li class="blue"><strong>Input Layer</strong> : From prompts to context engineering, meta-prompting, and multimodal</li>
                <li class="green"><strong>Model Layer</strong> : Foundation models, long context, RLVR, fine-tuning, and hybrid reasoning</li>
                <li class="orange"><strong>Application Layer</strong> : Agents that actually ship, tool calling, and patterns that work</li>
                <li class="purple"><strong>Output Layer</strong> : Trust as engineering, reliability math, and security frameworks</li>
                <li class="red"><strong>What's Still Broken</strong> : Hallucinations, RAG stagnation, and the production gap</li>
                <li class="purple"><strong>Road Ahead</strong> : What 2026 looks like and how to prepare</li>
            </ul>
        </div>
        


        <!-- ============================================ -->
        <!-- SECTION 1: INPUT LAYER -->
        <!-- ============================================ -->

        <!-- SLIDE: Section Break -->
        <div class="slide slide-section">
            <p class="label blue">Section 1</p>
            <h2>Input Layer</h2>
            <p class="sub">From Prompt Craft to Context Engineering</p>
            <div class="framework-container">
                <svg class="framework-svg" viewBox="0 0 950 480" xmlns="http://www.w3.org/2000/svg" style="max-width: 1100px;">
                    <g class="framework-layer">
                        <rect x="20" y="15" width="750" height="95" rx="8" fill="#3b82f6" opacity="0.15" stroke="#3b82f6" stroke-width="2"/>
                        <text x="30" y="38" fill="#3b82f6" font-weight="700" font-size="14">INPUT LAYER</text>
                        <rect x="30" y="50" width="170" height="50" rx="6" fill="#3b82f6"/><text x="115" y="80" text-anchor="middle" fill="white" font-size="11" font-weight="500">Multimodal Inputs</text>
                        <rect x="210" y="50" width="180" height="50" rx="6" fill="#3b82f6"/><text x="300" y="80" text-anchor="middle" fill="white" font-size="11" font-weight="500">Context Engineering</text>
                        <rect x="400" y="50" width="170" height="50" rx="6" fill="#3b82f6"/><text x="485" y="80" text-anchor="middle" fill="white" font-size="11" font-weight="500">Meta Prompting</text>
                        <rect x="580" y="50" width="180" height="50" rx="6" fill="#3b82f6"/><text x="670" y="80" text-anchor="middle" fill="white" font-size="10" font-weight="500">Auto Prompt Optimization</text>
                    </g>
                    <rect class="highlight-ring active" x="15" y="10" width="760" height="105" rx="12"/>
                    <g class="framework-layer dimmed"><rect x="20" y="120" width="750" height="95" rx="8" fill="#10b981" opacity="0.15" stroke="#10b981" stroke-width="2"/><text x="30" y="143" fill="#10b981" font-weight="700" font-size="14">DATA AND MODEL LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="225" width="750" height="95" rx="8" fill="#f97316" opacity="0.15" stroke="#f97316" stroke-width="2"/><text x="30" y="248" fill="#f97316" font-weight="700" font-size="14">APPLICATION LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="330" width="750" height="95" rx="8" fill="#8b5cf6" opacity="0.15" stroke="#8b5cf6" stroke-width="2"/><text x="30" y="353" fill="#8b5cf6" font-weight="700" font-size="14">OUTPUT LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="790" y="15" width="145" height="410" rx="8" fill="#ef4444" opacity="0.15" stroke="#ef4444" stroke-width="2"/><text x="862" y="220" text-anchor="middle" fill="#ef4444" font-weight="700" font-size="13">CHALLENGES</text></g>
                </svg>
            </div>
        </div>

        <!-- SLIDE: Section Overview -->
        <div class="slide slide-list">
            <h2>What Changed in the Input Layer</h2>
            <ul>
                <li class="blue"><strong>Prompt engineering evolved.</strong> From brittle skill-based craft to automated optimization.</li>
                <li class="blue"><strong>Meta-prompting emerged.</strong> Models now generate and refine prompts automatically.</li>
                <li class="blue"><strong>Automatic prompt optimization.</strong> Tools that iterate and improve prompts without human intervention.</li>
                <li class="blue"><strong>Context engineering matters more.</strong> What you put in the prompt matters more than how you phrase it.</li>
                <li class="blue"><strong>Multimodal became table stakes.</strong> Images, audio, and video as inputs moved from experimental to expected.</li>
            </ul>
        </div>

        <!-- ============================================ -->
        <!-- PART 1: PROMPTING IN 2024 -->
        <!-- ============================================ -->

        <!-- SLIDE: Prompting in 2024 -->
        <div class="slide slide-statement">
            <span class="topic-tag blue">Prompting 2024</span>
            <h2>In 2024, prompting was a <span class="orange">craft</span>.</h2>
            <p class="small">Models were sensitive. Small changes in wording produced wildly different outputs. Prompt engineering was a skill that took months to master.</p>
        </div>

        <!-- SLIDE: 2024 Prompting Characteristics -->
        <div class="slide slide-cards">
            <span class="topic-tag blue">Prompting 2024</span>
            <h2>Prompting in 2024: A Fragile Art</h2>
            <div class="cards-grid stacked">
                <div class="card" style="border-left: 4px solid var(--orange);">
                    <h3>Brittle & Model-Specific</h3>
                    <p>Prompts that worked on GPT-4 failed on Claude. Minor updates broke production systems. Every model needed different phrasing.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--blue);">
                    <h3>Skill-Based Techniques</h3>
                    <p>Chain-of-Thought, Tree-of-Thought, ReAct patterns. Researchers published papers on prompting techniques. It was a specialized skill.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--purple);">
                    <h3>Manual Iteration</h3>
                    <p>Teams spent weeks A/B testing prompts. Small word changes = big output differences. Prompt engineering was expensive and slow.</p>
                </div>
            </div>
        </div>

        <!-- SLIDE: Famous Techniques -->
        <div class="slide slide-visual">
            <span class="topic-tag blue">Prompting 2024</span>
            <h2>Some Research Papers That Defined 2024</h2>
            <img src="images/Prompting_Techniques_2024.png" alt="Prompting Techniques: CoT, ToT, ReAct, Self-Consistency">
            <p class="caption">These techniques worked, but required expertise to implement correctly. Most teams struggled to replicate paper results.</p>
        </div>

        <!-- ============================================ -->
        <!-- PART 2: THE 2025 SHIFT -->
        <!-- ============================================ -->

        <!-- SLIDE: 2025 Shift Statement -->
        <div class="slide slide-statement">
            <span class="topic-tag blue">2025 Shift</span>
            <h2>Then models got <span class="green">smarter</span>.</h2>
            <p class="small">2025 models are less brittle. They understand intent better. Careful phrasing matters less. And we found ways to automate the optimization.</p>
        </div>

        <!-- SLIDE: What Changed -->
        <div class="slide slide-vs">
            <span class="topic-tag blue">2025 Shift</span>
            <div class="vs-box old">
                <span class="tag">2024 Approach</span>
                <h3>"How do I phrase this?"</h3>
                <p>Manually crafting prompts, testing variations, hoping it works across models</p>
            </div>
            <span class="vs-arrow">→</span>
            <div class="vs-box new">
                <span class="tag">2025 Approach</span>
                <h3>"Let the model write it"</h3>
                <p>Meta-prompting and automated optimization. Models generate better prompts than humans.</p>
            </div>
        </div>

        <!-- ============================================ -->
        <!-- PART 3: META-PROMPTING -->
        <!-- ============================================ -->

        <!-- SLIDE: Meta-Prompting Intro -->
        <div class="slide slide-statement">
            <span class="topic-tag blue">Meta-Prompting</span>
            <h2>What is <span class="blue">Meta-Prompting</span>?</h2>
            <p class="small">A meta-prompt instructs the model to create a good prompt based on your task description. Instead of writing prompts yourself, you describe what you want and the model generates an optimized prompt.</p>
        </div>

        <!-- SLIDE: Meta-Prompting How It Works -->
        <div class="slide slide-content">
            <span class="topic-tag blue">Meta-Prompting</span>
            <h2>Meta-Prompting: How It Works</h2>
            <div class="body">
                <div class="text">
                    <p><strong>The idea is simple:</strong> Use a prompt to generate prompts.</p>
                    <p>OpenAI's Playground uses meta-prompts behind the "Generate" button. You describe your task, and it creates a complete, optimized prompt.</p>
                    <p class="muted" style="font-size: 0.9rem; margin-top: 1rem;">The meta-prompt includes best practices:</p>
                    <ul>
                        <li>Understand the task objectives and constraints</li>
                        <li>Encourage reasoning before conclusions</li>
                        <li>Include high-quality examples with placeholders</li>
                        <li>Specify output format explicitly</li>
                        <li>Add edge cases and important notes</li>
                    </ul>
                </div>
                <div class="visual" style="display: flex; flex-direction: column; align-items: center; justify-content: center;">
                    <div class="equation" style="width: 100%;">
                        <div class="formula" style="font-size: 1.5rem;">Task Description → Meta-Prompt → Optimized Prompt</div>
                        <p class="explain">Models generate better prompts than most humans can write manually</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- SLIDE: Meta-Prompting Example -->
        <div class="slide slide-two-col">
            <span class="topic-tag blue">Meta-Prompting</span>
            <h2>Meta-Prompting: Before & After</h2>
            <div class="cols">
                <div class="col">
                    <h3 class="red">What You Write</h3>
                    <div style="background: var(--card); border: 1px solid var(--border); border-radius: 8px; padding: 16px; margin-top: 12px;">
                        <p style="font-family: monospace; font-size: 0.9rem; color: var(--text-muted);">"I need a prompt for sentiment analysis of customer reviews"</p>
                    </div>
                    <p style="font-size: 0.85rem; color: var(--text-dim); margin-top: 12px;">Just describe your task in plain language. No prompt engineering expertise required.</p>
                </div>
                <div class="col">
                    <h3 class="green">What the Model Generates</h3>
                    <div style="background: var(--card); border: 1px solid var(--border); border-radius: 8px; padding: 16px; margin-top: 12px; font-size: 0.8rem;">
                        <p style="font-family: monospace; color: var(--text-muted); line-height: 1.5;">Analyze customer review sentiment.<br><br># Steps<br>1. Read the review carefully<br>2. Identify emotional indicators<br>3. Consider context and nuance<br>4. Classify as positive/negative/neutral<br><br># Output Format<br>JSON with sentiment and confidence score<br><br># Examples<br>[Detailed examples with edge cases...]</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- SLIDE: OpenAI Meta-Prompt Structure -->
        <div class="slide slide-list">
            <span class="topic-tag blue">Meta-Prompting</span>
            <h2>What OpenAI's Meta-Prompt Does</h2>
            <ul>
                <li class="blue"><strong>Understands the task:</strong> Grasps objectives, requirements, constraints, and expected output.</li>
                <li class="green"><strong>Enforces reasoning order:</strong> Reasoning steps before conclusions. Never start examples with answers.</li>
                <li class="orange"><strong>Includes examples:</strong> High-quality examples with placeholders for complex elements.</li>
                <li class="purple"><strong>Specifies output format:</strong> Explicit length, syntax (JSON, markdown, etc.), structure.</li>
                <li class="blue"><strong>Preserves user content:</strong> Keeps any details, guidelines, or examples you provide.</li>
            </ul>
            <p class="subtext">Source: OpenAI Prompt Generation Guide — the meta-prompt behind their Playground's Generate button.</p>
        </div>

        <!-- SLIDE: Why Meta-Prompting Matters -->
        <div class="slide slide-cards">
            <span class="topic-tag blue">Meta-Prompting</span>
            <h2>Why Meta Prompting is Super Valuable</h2>
            <div class="cards-grid stacked">
                <div class="card" style="border-left: 4px solid var(--green);">
                    <h3>Faster Iteration</h3>
                    <p>Generate 10 prompt variations in seconds. Test all of them. Pick the winner. What took days now takes minutes.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--blue);">
                    <h3>Best Practices Built-In</h3>
                    <p>Meta-prompts encode years of prompt engineering research. You get chain-of-thought, examples, and structure automatically.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--purple);">
                    <h3>Democratized Expertise</h3>
                    <p>You don't need to be a prompt engineer. Describe what you want in plain English. The model handles the craft.</p>
                </div>
            </div>
        </div>

        <!-- ============================================ -->
        <!-- PART 4: AUTOMATIC PROMPT OPTIMIZATION -->
        <!-- ============================================ -->

        <!-- SLIDE: Auto Prompt Optimization Intro -->
        <div class="slide slide-statement">
            <span class="topic-tag blue">Auto Optimization</span>
            <h2>Beyond meta-prompting: <span class="purple">Automatic Optimization</span></h2>
            <p class="small">Meta-prompting generates prompts. But what if you could automatically iterate and improve them based on actual performance? That's automatic prompt optimization.</p>
        </div>

        <!-- SLIDE: What is DSPy -->
        <div class="slide slide-statement">
            <span class="topic-tag blue">Auto Optimization</span>
            <h2>DSPy: <span class="purple">Automated A/B Testing</span> for Prompts</h2>
            <p class="small">Instead of manually tweaking prompts and hoping they work, DSPy automatically tries different variations, measures which ones perform best, and keeps the winners. It's like having a tireless intern who tests thousands of prompt variations for you.</p>
        </div>

        <!-- SLIDE: The Problem DSPy Solves -->
        <div class="slide slide-vs">
            <span class="topic-tag blue">Auto Optimization</span>
            <div class="vs-box old">
                <span class="tag">Manual Prompting</span>
                <h3>Guess and Check</h3>
                <p>Write a prompt. Test it. Doesn't work well? Tweak it. Test again. Repeat for hours. Still breaks on edge cases.</p>
            </div>
            <span class="vs-arrow">→</span>
            <div class="vs-box new">
                <span class="tag">DSPy</span>
                <h3>Automatic Optimization</h3>
                <p>Give examples of what "good" looks like. DSPy tries hundreds of prompt variations automatically and finds what works best.</p>
            </div>
        </div>

        <!-- SLIDE: How DSPy Optimization Works -->
        <div class="slide slide-visual">
            <span class="topic-tag blue">Auto Optimization</span>
            <h2>How DSPy Finds the Best Prompt</h2>
            <img src="images/dspy_process.png" alt="DSPy Optimization Process">
            <p class="caption">You provide task + data. DSPy generates prompt variations. The loop scores, selects best, and repeats until optimized.</p>
        </div>

        <!-- SLIDE: DSPy Example -->
        <div class="slide slide-two-col">
            <span class="topic-tag blue">Auto Optimization</span>
            <h2>DSPy in Action</h2>
            <div class="cols">
                <div class="col">
                    <h3 class="blue">What You Write</h3>
                    <div style="background: var(--card); border: 1px solid var(--border); border-radius: 8px; padding: 16px; margin-top: 12px;">
                        <p style="font-family: monospace; font-size: 0.8rem; color: var(--text-muted); line-height: 1.6;">
                            <span style="color: var(--blue);"># Define: question in, answer out</span><br>
                            qa = dspy.ChainOfThought("question -> answer")<br><br>
                            <span style="color: var(--blue);"># Give 10-20 examples</span><br>
                            examples = [...]<br><br>
                            <span style="color: var(--blue);"># Let DSPy optimize</span><br>
                            optimized = dspy.compile(qa, examples)
                        </p>
                    </div>
                </div>
                <div class="col">
                    <h3 class="green">What DSPy Figures Out</h3>
                    <div style="background: var(--card); border: 1px solid var(--border); border-radius: 8px; padding: 16px; margin-top: 12px;">
                        <p style="font-family: monospace; font-size: 0.8rem; color: var(--text-muted); line-height: 1.6;">
                            "Given the question, reason step-by-step. First identify the key concepts. Then consider relevant facts. Finally, synthesize into a clear answer. Format: <br><br>
                            Reasoning: [your reasoning]<br>
                            Answer: [concise answer]"
                        </p>
                    </div>
                    <p style="font-size: 0.85rem; color: var(--text-dim); margin-top: 12px;">DSPy discovered this works better than simpler prompts.</p>
                </div>
            </div>
        </div>

        <!-- SLIDE: Why DSPy Matters -->
        <div class="slide slide-cards">
            <span class="topic-tag blue">Auto Optimization</span>
            <h2>Why This Matters</h2>
            <div class="cards-grid stacked">
                <div class="card" style="border-left: 4px solid var(--blue);">
                    <h3>No More Prompt Guessing</h3>
                    <p>Stop spending hours tweaking wording. Give examples of what "good" looks like, and let the machine find the best way to ask for it.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--green);">
                    <h3>Gets Better Over Time</h3>
                    <p>Collected more examples? Re-run optimization. Found edge cases? Add them and re-compile. Your prompts improve as your data grows.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--purple);">
                    <h3>Works Across Models</h3>
                    <p>Switching from GPT-4 to Claude? Re-optimize with the same examples. DSPy finds what works best for each model automatically.</p>
                </div>
            </div>
        </div>

        <!-- ============================================ -->
        <!-- PART 5: CONTEXT ENGINEERING -->
        <!-- ============================================ -->

        <!-- SLIDE: Context Engineering Intro -->
        <div class="slide slide-statement">
            <span class="topic-tag blue">Context Engineering</span>
            <h2>Prompting skills matter. But <span class="blue">context</span> matters more.</h2>
            <p class="small">For agentic systems, the clever phrasing is less important than what information you provide. This is context engineering.</p>
        </div>

        <!-- SLIDE: Context Engineering Visual -->
        <div class="slide slide-visual">
            <span class="topic-tag blue">Context Engineering</span>
            <h2>Context Engineering: What Goes Into the Prompt</h2>
            <img src="images/context_engineering.png" alt="Context Engineering Diagram">
            <p class="caption">Source: <a href="https://x.com/toaboricua/status/1903478376592859633" target="_blank" style="color: #aaa;">@toaboricua on X</a></p>
        </div>

        <!-- SLIDE: Context Engineering Definition -->
        <div class="slide slide-content">
            <span class="topic-tag blue">Context Engineering</span>
            <h2>Context Engineering: The New Discipline</h2>
            <div class="body">
                <div class="text">
                    <p><strong>"The art and science of filling the context window with just the right information at each step."</strong></p>
                    <p>Not about clever phrasing — it's about what information the model needs and when it needs it.</p>
                    <p class="muted" style="font-size: 0.85rem; margin-top: 1rem;">Three types of context matter:</p>
                    <ul>
                        <li><strong>Instructions:</strong> Prompts, memories, examples</li>
                        <li><strong>Knowledge:</strong> Facts, retrieved information</li>
                        <li><strong>Tools:</strong> Feedback from tool calls and actions</li>
                    </ul>
                </div>
                <div class="visual" style="display: flex; flex-direction: column; align-items: center;">
                    <img src="https://blog.langchain.com/content/images/size/w1000/2025/07/image-1.png" alt="Context Engineering">
                    <p style="font-size: 0.7rem; color: #888; margin-top: 0.5rem;">Source: <a href="https://blog.langchain.com/context-engineering-for-agents/" target="_blank" style="color: #aaa;">LangChain Blog</a></p>
                </div>
            </div>
        </div>

        <!-- SLIDE: Context Engineering Strategies -->
        <div class="slide slide-content">
            <span class="topic-tag blue">Context Engineering</span>
            <h2>Four Strategies for Managing Context</h2>
            <div class="body">
                <div class="text">
                    <ul>
                        <li><strong>Write:</strong> Save information outside the context window. Use scratchpads and memories to persist across sessions.</li>
                        <li><strong>Select:</strong> Pull only relevant context in. Use embeddings, knowledge graphs, and careful filtering.</li>
                        <li><strong>Compress:</strong> Reduce tokens through summarization and trimming. Prevent context overload.</li>
                        <li><strong>Isolate:</strong> Split context across multiple agents or sandboxed environments.</li>
                    </ul>
                    <p class="muted" style="font-size: 0.85rem; margin-top: 1rem;">The goal: give agents exactly what they need, nothing more.</p>
                </div>
                <div class="visual" style="display: flex; flex-direction: column; align-items: center;">
                    <img src="https://blog.langchain.com/content/images/size/w1000/2025/07/image.png" alt="Context Engineering Strategies">
                    <p style="font-size: 0.7rem; color: #888; margin-top: 0.5rem;">Source: <a href="https://blog.langchain.com/context-engineering-for-agents/" target="_blank" style="color: #aaa;">LangChain Blog</a></p>
                </div>
            </div>
        </div>

        <!-- ============================================ -->
        <!-- PART 6: MULTIMODAL INPUTS -->
        <!-- (Placeholder for McKinsey content) -->
        <!-- ============================================ -->

        <!-- SLIDE: Multimodal Statement -->
        <div class="slide slide-statement">
            <span class="topic-tag blue">Multimodal</span>
            <h2>Text-only AI systems are <span class="red">legacy</span>.</h2>
            <p class="small">In 2024, processing images alongside text was a differentiator. In 2025, it's table stakes. Systems that only handle text are increasingly inadequate for real-world use cases.</p>
        </div>

        <!-- SLIDE: Multimodal Use Cases -->
        <div class="slide slide-cards">
            <span class="topic-tag blue">Multimodal</span>
            <h2>What Multimodal Inputs Enable</h2>
            <div class="cards-grid stacked">
                <div class="card" style="border-left: 4px solid var(--blue);">
                    <h3>Customer Service</h3>
                    <p>User sends a screenshot of an error message with their complaint. The model sees both, understands the context, and provides a relevant solution. No more "please describe what you see."</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--green);">
                    <h3>Code & Development</h3>
                    <p>Share a photo of a whiteboard diagram and ask "implement this architecture." Upload a UI mockup and get working code. The model understands visual intent, not just text descriptions.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--purple);">
                    <h3>Document Processing</h3>
                    <p>Feed invoices, receipts, contracts — the model reads text, understands layout, interprets signatures and stamps. No need to extract text first; it sees the whole document.</p>
                </div>
            </div>
        </div>

        <!-- SLIDE: Why Now -->
        <div class="slide slide-content">
            <span class="topic-tag blue">Multimodal</span>
            <h2>Why Multimodal Works Now</h2>
            <div class="body">
                <div class="text">
                    <p><strong>2024 models could see images. 2025 models understand them.</strong></p>
                    <p>The latest models (GPT-5.2, Claude Opus 4.5, Gemini 3) have native multimodal understanding — images, audio, and video are first-class inputs, not bolted-on features.</p>
                    <ul>
                        <li><strong>Better accuracy:</strong> Models reason about visual and text context together, reducing hallucinations</li>
                        <li><strong>Lower latency:</strong> No separate OCR or vision pipeline needed — one model handles everything</li>
                        <li><strong>Richer context:</strong> A picture is worth a thousand tokens of description you don't have to write</li>
                    </ul>
                </div>
                <div class="visual" style="display: flex; flex-direction: column; align-items: center; justify-content: center;">
                    <div class="equation" style="width: 100%;">
                        <div class="formula" style="font-size: 1.3rem;">Image + Text → Understanding</div>
                        <p class="explain">Not image-to-text + text-to-understanding anymore</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- ============================================ -->
        <!-- INPUT LAYER TAKEAWAYS -->
        <!-- ============================================ -->

        <!-- SLIDE: Input Layer Takeaways -->
        <div class="slide slide-list">
            <h2 class="blue">Input Layer: Key Takeaways</h2>
            <ul>
                <li class="green"><strong>Let models write your prompts.</strong> Meta-prompting generates better prompts than manual crafting. Use it.</li>
                <li class="green"><strong>Automate prompt optimization.</strong> Tools like DSPy iterate faster than humans. Stop manual A/B testing.</li>
                <li class="green"><strong>Focus on context, not phrasing.</strong> What you put in the prompt matters more than how you say it.</li>
                <li class="green"><strong>Plan for multimodal now.</strong> If your AI system only handles text, you're building technical debt.</li>
            </ul>
        </div>



        <!-- ============================================ -->
        <!-- SECTION 2: MODEL LAYER -->
        <!-- ============================================ -->

        <!-- SLIDE: Section Break -->
        <div class="slide slide-section">
            <p class="label green">Section 2</p>
            <h2>Model & Data Layer</h2>
            <p class="sub">From "bigger is better" to "think before you speak"</p>
            <div class="framework-container">
                <svg class="framework-svg" viewBox="0 0 950 480" xmlns="http://www.w3.org/2000/svg" style="max-width: 1100px;">
                    <g class="framework-layer dimmed"><rect x="20" y="15" width="750" height="95" rx="8" fill="#3b82f6" opacity="0.15" stroke="#3b82f6" stroke-width="2"/><text x="30" y="38" fill="#3b82f6" font-weight="700" font-size="14">INPUT LAYER</text></g>
                    <g class="framework-layer">
                        <rect x="20" y="120" width="750" height="95" rx="8" fill="#10b981" opacity="0.15" stroke="#10b981" stroke-width="2"/>
                        <text x="30" y="143" fill="#10b981" font-weight="700" font-size="14">DATA AND MODEL LAYER</text>
                        <rect x="30" y="155" width="140" height="50" rx="6" fill="#10b981"/><text x="100" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">System 2 Reasoning</text>
                        <rect x="180" y="155" width="100" height="50" rx="6" fill="#10b981"/><text x="230" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">RLVR</text>
                        <rect x="290" y="155" width="120" height="50" rx="6" fill="#10b981"/><text x="350" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">Long Context</text>
                        <rect x="420" y="155" width="120" height="50" rx="6" fill="#10b981"/><text x="480" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">Quantization</text>
                        <rect x="550" y="155" width="210" height="50" rx="6" fill="#10b981"/><text x="655" y="185" text-anchor="middle" fill="white" font-size="10" font-weight="500">Fine-Tuning & Distillation</text>
                    </g>
                    <rect class="highlight-ring active" x="15" y="115" width="760" height="105" rx="12"/>
                    <g class="framework-layer dimmed"><rect x="20" y="225" width="750" height="95" rx="8" fill="#f97316" opacity="0.15" stroke="#f97316" stroke-width="2"/><text x="30" y="248" fill="#f97316" font-weight="700" font-size="14">APPLICATION LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="330" width="750" height="95" rx="8" fill="#8b5cf6" opacity="0.15" stroke="#8b5cf6" stroke-width="2"/><text x="30" y="353" fill="#8b5cf6" font-weight="700" font-size="14">OUTPUT LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="790" y="15" width="145" height="410" rx="8" fill="#ef4444" opacity="0.15" stroke="#ef4444" stroke-width="2"/><text x="862" y="220" text-anchor="middle" fill="#ef4444" font-weight="700" font-size="13">CHALLENGES</text></g>
                </svg>
            </div>
        </div>

        <!-- SLIDE: Section Overview -->
        <div class="slide slide-list">
            <h2>What Changed in the Model Layer</h2>
            <ul>
                <li class="green"><strong>Models learned to think.</strong> System 2 reasoning emerged: models that allocate compute dynamically based on problem difficulty.</li>
                <li class="green"><strong>RLVR changed training.</strong> Reinforcement Learning with Verifiable Rewards proved you can train reasoning without human labels.</li>
                <li class="green"><strong>Context windows hit 1M tokens.</strong> But effective use of long context requires more than just bigger windows.</li>
                <li class="green"><strong>Efficiency became a priority.</strong> Quantization and distillation made frontier capabilities accessible on consumer hardware.</li>
            </ul>
        </div>

        <!-- ============================================ -->
        <!-- SYSTEM 1 → SYSTEM 2 REASONING -->
        <!-- ============================================ -->

        <!-- SLIDE: System 2 Intro -->
        <div class="slide slide-statement">
            <span class="topic-tag green">System 2 Reasoning</span>
            <h2>The biggest shift in 2025: models that <span class="green">think before they speak</span>.</h2>
            <p class="small">Instead of generating tokens as fast as possible, these models allocate more compute to harder problems. The result: dramatically better reasoning on complex tasks.</p>
        </div>

        <!-- SLIDE: System 1 vs System 2 -->
        <div class="slide slide-vs">
            <span class="topic-tag green">System 2 Reasoning</span>
            <div class="vs-box old">
                <span class="tag">System 1</span>
                <h3>Fast, Intuitive</h3>
                <p>Immediate responses. Pattern matching. Great for simple queries, but prone to confident errors on hard problems.</p>
            </div>
            <span class="vs-arrow">→</span>
            <div class="vs-box new">
                <span class="tag">System 2</span>
                <h3>Slow, Deliberate</h3>
                <p>Models allocate thinking time proportional to difficulty. More reliable on complex reasoning, but 3-5x slower.</p>
            </div>
        </div>

        <!-- SLIDE: Why System 2 Matters -->
        <div class="slide slide-cards">
            <span class="topic-tag green">System 2 Reasoning</span>
            <h2>Why System 2 Reasoning Matters</h2>
            <div class="cards-grid stacked">
                <div class="card" style="border-left: 4px solid var(--green);">
                    <h3>Dynamic Compute Allocation</h3>
                    <p>Simple questions get quick answers. Complex problems trigger extended reasoning chains. The model decides how hard to think based on the task.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--blue);">
                    <h3>Visible Thinking Process</h3>
                    <p>You can see the model's reasoning in its "thinking" tokens. This makes debugging easier and helps identify where reasoning goes wrong.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--purple);">
                    <h3>Trade Speed for Accuracy</h3>
                    <p>For tasks where correctness matters more than latency—code generation, complex analysis, multi-step reasoning—the tradeoff is worth it.</p>
                </div>
            </div>
        </div>

        <!-- SLIDE: Test-Time Compute -->
        <div class="slide slide-content" style="justify-content: center;">
            <span class="topic-tag green">System 2 Reasoning</span>
            <div class="equation" style="max-width: 850px; margin: 0 auto;">
                <p class="formula">Test-Time Compute = <span class="green">Thinking Time</span> × <span class="blue">Tokens</span></p>
                <p class="explain">The new scaling law: you can improve outputs by letting models think longer</p>
            </div>
            <div style="text-align: center; margin-top: 1.5rem; color: var(--text-muted); font-size: 1.05rem; max-width: 750px; margin-left: auto; margin-right: auto;">
                <p>2024's scaling law was about training compute. 2025's insight: <strong>inference compute matters too</strong>.</p>
                <p style="margin-top: 0.5rem;">Models can solve harder problems by spending more compute at inference time, not just at training time.</p>
            </div>
        </div>

        <!-- ============================================ -->
        <!-- RLVR -->
        <!-- ============================================ -->

        <!-- SLIDE: RLHF Context -->
        <div class="slide slide-statement">
            <span class="topic-tag green">RLVR</span>
            <h2>2024 was the year of RLHF.</h2>
            <p class="small">Reinforcement Learning from Human Feedback. Humans rank model outputs. The model learns what humans prefer. This gave us helpful, harmless assistants—but it doesn't scale, and "sounds good" isn't the same as "is correct."</p>
        </div>

        <!-- SLIDE: RLVR Intro -->
        <div class="slide slide-statement">
            <span class="topic-tag green">RLVR</span>
            <h2>2025 introduced RLVR: rewards you can verify automatically.</h2>
            <p class="small">Reinforcement Learning with Verifiable Rewards. Give the model problems with checkable answers—math proofs, code that compiles, logic puzzles. Tell it only right or wrong. No human labelers needed. Scales with compute, not headcount.</p>
        </div>

        <!-- SLIDE: RLHF vs RLVR Visual -->
        <div class="slide slide-visual">
            <span class="topic-tag green">RLVR</span>
            <h2>RLHF vs RLVR: The Key Difference</h2>
            <img src="images/rlhf_rlvr.png" alt="RLHF vs RLVR Comparison">
            <p class="caption">RLHF asks "which sounds better?" RLVR asks "is this correct?" One requires humans. One requires only a verifier.</p>
        </div>

        <!-- SLIDE: RLVR Insight -->
        <div class="slide slide-statement">
            <span class="topic-tag green">RLVR</span>
            <h2>RLVR compresses search into intuition.</h2>
            <p class="small">What looks like "reasoning" is actually learned search patterns. The model isn't thinking step-by-step—it's pattern matching on solution strategies it learned during training.</p>
        </div>

        <!-- SLIDE: Self-Correction -->
        <div class="slide slide-content">
            <span class="topic-tag green">RLVR</span>
            <h2>The Self-Correction Breakthrough</h2>
            <div class="body">
                <div class="text">
                    <p>RLVR-trained models learned something unexpected: <strong>how to catch and correct their own mistakes</strong>.</p>
                    <ul>
                        <li>Models detect when reasoning is going wrong</li>
                        <li>They backtrack and try different approaches</li>
                        <li>This emerged naturally from the training process</li>
                    </ul>
                    <p style="margin-top: 1rem;"><strong>The results:</strong></p>
                    <ul>
                        <li>40-60% fewer hallucinations in trained domains</li>
                        <li>Models express uncertainty instead of fabricating</li>
                        <li>Graceful degradation on hard problems</li>
                    </ul>
                </div>
                <div class="visual" style="flex-direction: column; gap: 16px;">
                    <div class="card" style="background: rgba(16, 185, 129, 0.1); border-color: rgba(16, 185, 129, 0.3); text-align: center; width: 100%;">
                        <p style="font-size: 0.85rem; color: var(--green); margin-bottom: 0.5rem;">RLVR excels at</p>
                        <p style="font-size: 1.05rem;">Code • Math • Logic • Structured Tasks</p>
                    </div>
                    <div class="card" style="background: rgba(239, 68, 68, 0.1); border-color: rgba(239, 68, 68, 0.3); text-align: center; width: 100%;">
                        <p style="font-size: 0.85rem; color: var(--red); margin-bottom: 0.5rem;">RLVR struggles with</p>
                        <p style="font-size: 1.05rem;">Creative Writing • Subjective Tasks</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- ============================================ -->
        <!-- LONG CONTEXT -->
        <!-- ============================================ -->

        <!-- SLIDE: Long Context Intro -->
        <div class="slide slide-stat">
            <span class="topic-tag green">Long Context</span>
            <p class="num green">1M</p>
            <p class="label">tokens in a single context window</p>
            <p class="context">That's ~700 pages. Entire codebases. Full research papers with all citations. But there's a catch.</p>
        </div>

        <!-- SLIDE: Context Windows -->
        <div class="slide slide-cards">
            <span class="topic-tag green">Long Context</span>
            <h2>Context Windows Exploded in 2025</h2>
            <div class="cards-grid">
                <div class="card" style="text-align: center;">
                    <p class="num green">1M</p>
                    <p style="font-weight: 600;">Gemini 3 Pro</p>
                    <p style="font-size: 0.85rem; color: var(--muted);">~700 pages input</p>
                </div>
                <div class="card" style="text-align: center;">
                    <p class="num blue">400K</p>
                    <p style="font-weight: 600;">GPT-5.2</p>
                    <p style="font-size: 0.85rem; color: var(--muted);">~128K output cap</p>
                </div>
                <div class="card" style="text-align: center;">
                    <p class="num purple">200K</p>
                    <p style="font-weight: 600;">Claude Opus 4.5</p>
                    <p style="font-size: 0.85rem; color: var(--muted);">Up to 1M enterprise</p>
                </div>
            </div>
            <p class="subtext muted" style="text-align: center; margin-top: 1.5rem;">Entire codebases in context. Multi-document analysis without chunking. Complex reasoning across long dependencies.</p>
        </div>

        <!-- SLIDE: Effective vs Claimed -->
        <div class="slide slide-statement">
            <span class="topic-tag green">Long Context</span>
            <h2>Claimed context ≠ effective context.</h2>
            <p class="small">Models can accept 1M tokens. That doesn't mean they use them well. Information in the middle gets lost. Retrieval quality degrades with distance. Test your specific use case.</p>
        </div>

        <!-- SLIDE: Long Context Challenges -->
        <div class="slide slide-list">
            <span class="topic-tag green">Long Context</span>
            <h2>The Long Context Reality Check</h2>
            <ul>
                <li class="orange"><strong>"Lost in the middle" problem persists.</strong> Models remember beginnings and ends better than middles. Structure your context accordingly.</li>
                <li class="blue"><strong>Costs scale linearly.</strong> 10x more context = 10x higher cost. Strategic context management still matters.</li>
                <li class="purple"><strong>Latency increases.</strong> Longer context means slower first-token response. Plan for user experience.</li>
                <li class="green"><strong>Quality varies by model.</strong> Some models handle 1M well. Others degrade at 100K. Benchmark your specific tasks.</li>
            </ul>
        </div>

        <!-- ============================================ -->
        <!-- EFFICIENCY & QUANTIZATION -->
        <!-- ============================================ -->

        <!-- SLIDE: Efficiency Intro -->
        <div class="slide slide-statement">
            <span class="topic-tag green">Efficiency</span>
            <h2>2025's hidden story: frontier capabilities on consumer hardware.</h2>
            <p class="small">Quantization, distillation, and mixture-of-experts made models 10x more accessible.</p>
        </div>

        <!-- SLIDE: Quantization -->
        <div class="slide slide-visual">
            <span class="topic-tag green">Efficiency</span>
            <h2>Quantization: Smaller Without Losing Quality</h2>
            <img src="images/quantization.png" alt="Quantization comparison showing 32-bit, 8-bit, and 4-bit models">
            <p class="caption">Reduce precision from 32-bit to 4-bit. Same model, 8x smaller, runs on consumer hardware. Quality loss is minimal for most production tasks.</p>
        </div>

        <!-- ============================================ -->
        <!-- FINE-TUNING & DISTILLATION -->
        <!-- ============================================ -->

        <!-- SLIDE: Fine-tuning Intro -->
        <div class="slide slide-statement">
            <span class="topic-tag green">Fine-Tuning</span>
            <h2>Fine-tuning: training a model on your specific data.</h2>
            <p class="small">Take a general-purpose model. Train it further on domain-specific examples. The result: a model that speaks your industry's language, follows your formats, and understands your context—often matching larger models at a fraction of the cost.</p>
        </div>

        <!-- SLIDE: Fine-tuning in Practice -->
        <div class="slide slide-list">
            <span class="topic-tag green">Fine-Tuning</span>
            <h2>Where Fine-Tuning Made the Difference in 2025</h2>
            <ul>
                <li class="green"><strong>Healthcare:</strong> Harvard researchers fine-tuned smaller LLMs to scan medical records for social determinants of health—outperforming larger general models with less bias.</li>
                <li class="blue"><strong>Finance:</strong> Banks fine-tuned models on earnings reports and risk assessments using internal terminology that general models couldn't understand.</li>
                <li class="purple"><strong>Legal:</strong> LegiLM, fine-tuned for data privacy regulations, interprets compliance requirements that general models miss.</li>
                <li class="orange"><strong>Chemistry:</strong> LlaSMol, a Mistral-based model fine-tuned for molecular science, substantially outperformed non-fine-tuned models on chemistry tasks.</li>
            </ul>
        </div>

        <!-- SLIDE: Fine-tuning Guidance -->
        <div class="slide slide-statement">
            <span class="topic-tag green">Fine-Tuning</span>
            <h2>But always start with prompting. Fine-tune only when you have to.</h2>
            <p class="small">Prompting is faster to iterate, requires no training data, and works for most use cases. Fine-tune when you're running the same task at massive scale, need consistent output formats, or require domain knowledge the base model lacks.</p>
        </div>

        <!-- SLIDE: Distillation Trend -->
        <div class="slide slide-statement">
            <span class="topic-tag green">Distillation</span>
            <h2>Distillation became the default deployment strategy.</h2>
            <p class="small">Use a large model to generate training data. Train a smaller model on that data. Deploy the small model at 10x lower cost. This pattern—70B teacher to 7B student—drove most production cost optimizations in 2025.</p>
        </div>

        <!-- SLIDE: Domain Experts -->
        <div class="slide slide-cards">
            <span class="topic-tag green">Distillation</span>
            <h2>Where Domain-Specific Models Shine</h2>
            <div class="cards-grid two">
                <div class="card" style="border-left: 4px solid var(--green);">
                    <h3>Healthcare</h3>
                    <p>Medical coding from clinical notes. Drug interaction checking. Radiology report generation. Anywhere regulatory precision matters.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--blue);">
                    <h3>Legal</h3>
                    <p>Contract clause extraction. Case law research. Compliance document review. Tasks requiring jurisdiction-specific knowledge.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--purple);">
                    <h3>Finance</h3>
                    <p>Earnings call summarization. Risk factor analysis. Regulatory filing generation. Domain jargon and format requirements.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--orange);">
                    <h3>Code</h3>
                    <p>Repository-specific assistants. Internal API documentation. Company coding standards enforcement. Codebase-aware refactoring.</p>
                </div>
            </div>
            <p class="subtext muted" style="text-align: center; margin-top: 1rem;">The pattern: General models for exploration, specialized models for production.</p>
        </div>

        <!-- ============================================ -->
        <!-- TAKEAWAYS -->
        <!-- ============================================ -->

        <!-- SLIDE: Model Takeaways -->
        <div class="slide slide-list">
            <h2 class="green">Model Layer: Key Takeaways</h2>
            <ul>
                <li class="green"><strong>System 2 reasoning trades speed for accuracy.</strong> Use thinking models for complex tasks where correctness matters more than latency.</li>
                <li class="green"><strong>RLVR enables self-correction.</strong> Models trained with verifiable rewards catch their own mistakes on structured tasks.</li>
                <li class="green"><strong>Long context ≠ infinite context.</strong> Test effective context length for your use case. The middle gets lost.</li>
                <li class="green"><strong>Small + specialized beats large + general.</strong> Fine-tuned 7B often outperforms 70B at 10% the cost.</li>
            </ul>
        </div>



        <!-- ============================================ -->
        <!-- SECTION 3: APPLICATION LAYER -->
        <!-- ============================================ -->

        <!-- SLIDE: Section Break -->
        <div class="slide slide-section">
            <p class="label orange">Section 3</p>
            <h2>Application Layer</h2>
            <p class="sub">From "Which model?" to "Can it do real work?"</p>
            <div class="framework-container">
                <svg class="framework-svg" viewBox="0 0 950 480" xmlns="http://www.w3.org/2000/svg" style="max-width: 1100px;">
                    <g class="framework-layer dimmed"><rect x="20" y="15" width="750" height="95" rx="8" fill="#3b82f6" opacity="0.15" stroke="#3b82f6" stroke-width="2"/><text x="30" y="38" fill="#3b82f6" font-weight="700" font-size="14">INPUT LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="120" width="750" height="95" rx="8" fill="#10b981" opacity="0.15" stroke="#10b981" stroke-width="2"/><text x="30" y="143" fill="#10b981" font-weight="700" font-size="14">DATA AND MODEL LAYER</text></g>
                    <g class="framework-layer">
                        <rect x="20" y="225" width="750" height="95" rx="8" fill="#f97316" opacity="0.15" stroke="#f97316" stroke-width="2"/>
                        <text x="30" y="248" fill="#f97316" font-weight="700" font-size="14">APPLICATION LAYER</text>
                        <rect x="30" y="260" width="100" height="50" rx="6" fill="#f97316"/><text x="80" y="290" text-anchor="middle" fill="white" font-size="10" font-weight="500">RAG</text>
                        <rect x="140" y="260" width="100" height="50" rx="6" fill="#f97316"/><text x="190" y="290" text-anchor="middle" fill="white" font-size="10" font-weight="500">Agents</text>
                        <rect x="250" y="260" width="100" height="50" rx="6" fill="#f97316"/><text x="300" y="290" text-anchor="middle" fill="white" font-size="10" font-weight="500">Tool Calling</text>
                        <rect x="360" y="260" width="100" height="50" rx="6" fill="#f97316"/><text x="410" y="290" text-anchor="middle" fill="white" font-size="10" font-weight="500">Skills</text>
                        <rect x="470" y="260" width="140" height="50" rx="6" fill="#f97316"/><text x="540" y="290" text-anchor="middle" fill="white" font-size="10" font-weight="500">Agentic Frameworks</text>
                        <rect x="620" y="260" width="140" height="50" rx="6" fill="#f97316"/><text x="690" y="290" text-anchor="middle" fill="white" font-size="10" font-weight="500">Standards (MCP/A2A)</text>
                    </g>
                    <rect class="highlight-ring active" x="15" y="220" width="760" height="105" rx="12"/>
                    <g class="framework-layer dimmed"><rect x="20" y="330" width="750" height="95" rx="8" fill="#8b5cf6" opacity="0.15" stroke="#8b5cf6" stroke-width="2"/><text x="30" y="353" fill="#8b5cf6" font-weight="700" font-size="14">OUTPUT LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="790" y="15" width="145" height="410" rx="8" fill="#ef4444" opacity="0.15" stroke="#ef4444" stroke-width="2"/><text x="862" y="220" text-anchor="middle" fill="#ef4444" font-weight="700" font-size="13">CHALLENGES</text></g>
                </svg>
            </div>
        </div>

        <!-- SLIDE: Section Overview -->
        <div class="slide slide-list">
            <h2>What Changed in the Application Layer</h2>
            <ul>
                <li class="orange"><strong>Delegation replaced answers.</strong> Book the meeting, pull the numbers, draft the doc. The success metric moved from good responses to completed outcomes.</li>
                <li class="orange"><strong>RAG matured into a real subsystem.</strong> Naive "add embeddings and pray" died. Hybrid retrieval, reranking, and agentic workflows became the norm.</li>
                <li class="orange"><strong>Agent types diversified.</strong> Deep agents for long-horizon work. Ambient agents for always-on automation. Browser agents for UI control.</li>
                <li class="orange"><strong>Standards emerged from protocol wars.</strong> MCP and A2A moved to open governance. Fragmentation started consolidating.</li>
            </ul>
        </div>

        <!-- SLIDE: The Shift -->
        <div class="slide slide-statement">
            <h2>People wanted delegation, not answers.</h2>
            <p class="small">Book the meeting. Pull the numbers. Draft the doc. Update the ticket. Reconcile the spreadsheet. The success metric moved from "a good response" to "a completed outcome."</p>
        </div>

        <!-- ============================================ -->
        <!-- RAG IN 2025 -->
        <!-- ============================================ -->

        <!-- SLIDE: RAG Didn't Die -->
        <div class="slide slide-statement">
            <span class="topic-tag orange">RAG</span>
            <h2>RAG didn't die. Naive RAG did.</h2>
            <p class="small">The shift was from "add embeddings and pray" to "engineer retrieval like a real subsystem." What showed up in practice: hybrid retrieval, serious chunking strategies, metadata filtering, and access control.</p>
        </div>

        <!-- SLIDE: What Changed in RAG -->
        <div class="slide slide-cards">
            <span class="topic-tag orange">RAG</span>
            <h2>How RAG Matured in 2025</h2>
            <div class="cards-grid stacked">
                <div class="card" style="border-left: 4px solid var(--blue);">
                    <h3>Hybrid Retrieval Became Normal</h3>
                    <p>Sparse retrieval (BM25) for exact matches. Dense embeddings for semantic matches. Reranking to pick the final context. Better retrieval wasn't just better embeddings—it was better input to retrieval.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--orange);">
                    <h3>RAG Became a Workflow, Not a Single Call</h3>
                    <p>The system rewrites the query, does multi-step retrieval, picks sources, verifies results, then answers. One-pass retrieval fails silently. The workflow approach makes failure visible and recoverable.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--purple);">
                    <h3>Graph-Based Retrieval Got Attention</h3>
                    <p>Traditional RAG is good at "find me the paragraph." It struggles at "summarize the themes" or "how do these concepts relate." GraphRAG builds structure over your data for corpus-level questions.</p>
                </div>
            </div>
        </div>

        <!-- SLIDE: Long Context + RAG -->
        <div class="slide slide-statement">
            <span class="topic-tag orange">RAG</span>
            <h2>Long context is a bigger desk. RAG is choosing the right papers to put on it.</h2>
            <p class="small">Long context reduces complexity for small, stable datasets. But enterprise needs—cost control, freshness, access control, auditability—kept retrieval relevant. Most teams landed on hybrid: use long context as a reasoning workspace, but still retrieve curated slices into it.</p>
        </div>

        <!-- SLIDE: Why RAG Stayed -->
        <div class="slide slide-list">
            <span class="topic-tag orange">RAG</span>
            <h2>Why Retrieval Stayed Relevant</h2>
            <ul>
                <li class="blue"><strong>Cost control.</strong> Passing huge context is expensive and often wasteful. Retrieval lets you pay only for what you need.</li>
                <li class="green"><strong>Freshness.</strong> If data changes daily, you don't want to keep repacking massive context. Fetch what's current.</li>
                <li class="purple"><strong>Access control.</strong> "Put it all in the prompt" breaks down when different users have different permissions.</li>
                <li class="orange"><strong>Auditability.</strong> Retrieval makes it easier to show what sources were used and why.</li>
            </ul>
        </div>

        <!-- ============================================ -->
        <!-- AGENT TYPES -->
        <!-- ============================================ -->

        <!-- SLIDE: Agent Types Intro -->
        <div class="slide slide-statement">
            <span class="topic-tag orange">Agents</span>
            <h2>2025 was the year agent work split into distinct categories.</h2>
            <p class="small">"Agent" stopped meaning "LLM that can call a tool" and started meaning "a system that can complete work across many steps, over time, with integration, and with guardrails."</p>
        </div>

        <!-- SLIDE: Deep Agents -->
        <div class="slide slide-content">
            <span class="topic-tag orange">Agents</span>
            <h2>Deep Agents: Long-Horizon Work</h2>
            <div class="body">
                <div class="text">
                    <p>Deep agents handle tasks that take minutes to hours, with many steps, context management, and delegation.</p>
                    <p style="margin-top: 1rem;"><strong>What they do:</strong></p>
                    <ul>
                        <li>Hold state and artifacts, not just chat history</li>
                        <li>Decompose goals into sub-tasks</li>
                        <li>Recover from failure, retry safely, continue</li>
                        <li>Use memory and filesystems to avoid context collapse</li>
                    </ul>
                    <p style="margin-top: 1rem;"><strong>Example:</strong> OpenAI shipped "deep research" as an agentic capability—multi-step research that browses and synthesizes, returning a report with citations.</p>
                </div>
                <div class="visual" style="flex-direction: column; gap: 16px; justify-content: center;">
                    <div class="card" style="background: rgba(249, 115, 22, 0.1); border-color: rgba(249, 115, 22, 0.3); text-align: center;">
                        <p style="font-weight: 700; color: var(--orange); font-size: 1.1rem;">A shallow agent answers.</p>
                        <p style="font-weight: 700; color: var(--orange); font-size: 1.1rem; margin-top: 0.5rem;">A deep agent produces.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- SLIDE: Ambient Agents -->
        <div class="slide slide-content">
            <span class="topic-tag orange">Agents</span>
            <h2>Ambient Agents: Always-On Automation</h2>
            <div class="body">
                <div class="text">
                    <p>Ambient agents run in the background and act on events rather than waiting for prompts.</p>
                    <p style="margin-top: 1rem;"><strong>They respond to:</strong></p>
                    <ul>
                        <li>Event streams, logs, monitoring alerts</li>
                        <li>Tickets breaching SLA, churn signals spiking</li>
                        <li>Build failures, incident starts, contract renewals</li>
                    </ul>
                    <p style="margin-top: 1rem;"><strong>Core ingredients:</strong></p>
                    <ul>
                        <li>Triggers: event streams, schedules, webhooks</li>
                        <li>Policies: what it can do automatically vs. what needs approval</li>
                        <li>Memory of ongoing state: what's already handled</li>
                    </ul>
                </div>
                <div class="visual" style="flex-direction: column; gap: 16px; justify-content: center;">
                    <div class="card" style="background: rgba(139, 92, 246, 0.1); border-color: rgba(139, 92, 246, 0.3); text-align: center;">
                        <p style="font-size: 0.9rem; color: var(--purple); margin-bottom: 0.5rem;">Where they win</p>
                        <p style="font-size: 1rem;">IT ops triage • Security alert routing • SLA management • Compliance checks</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- SLIDE: Coding Agents -->
        <div class="slide slide-statement">
            <span class="topic-tag orange">Agents</span>
            <h2>Coding agents became the first place many teams experienced real agents.</h2>
            <p class="small">Why? Software work has the perfect control surface: repos, tests, CI, and pull requests. Every step is visible. Humans steer via PR review. Governance is built in.</p>
        </div>

        <!-- SLIDE: Coding Agent Types -->
        <div class="slide slide-cards">
            <span class="topic-tag orange">Agents</span>
            <h2>Three Surfaces for Coding Agents</h2>
            <div class="cards-grid stacked">
                <div class="card" style="border-left: 4px solid var(--blue);">
                    <h3>IDE Agents</h3>
                    <p>Multi-step work inside your editor. Finds relevant files, proposes edits across multiple files, runs terminal commands and tests, watches errors, fixes and retries in a loop. Cursor and Copilot agent mode run multiple agents in parallel.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--green);">
                    <h3>Repo & PR Agents</h3>
                    <p>Work through issues and pull requests in a GitHub Actions environment. Produce PRs, logs, and reviewable commits. This is where autonomy becomes governable—every step visible in commits, humans steer via PR review.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--purple);">
                    <h3>Terminal Agents</h3>
                    <p>Agentic coding from the command line. Understands your codebase, helps with routine tasks and git workflows through natural language. Works with existing bash environment and can act as both MCP server and client.</p>
                </div>
            </div>
        </div>

        <!-- SLIDE: Browser Agents -->
        <div class="slide slide-content">
            <span class="topic-tag orange">Agents</span>
            <h2>Browser Agents: UI Control</h2>
            <div class="body">
                <div class="text">
                    <p>Agents that operate the real surface area people use: browsers and SaaS UIs.</p>
                    <p style="margin-top: 1rem;"><strong>OpenAI Operator</strong> (January 2025)</p>
                    <ul>
                        <li>Uses screenshots to "see" and virtual mouse/keyboard to interact</li>
                        <li>Books reservations, fills forms, places orders</li>
                        <li>Later integrated into ChatGPT as "agent mode"</li>
                    </ul>
                    <p style="margin-top: 1rem;"><strong>Google Project Mariner</strong></p>
                    <ul>
                        <li>Chrome extension with sidebar interface</li>
                        <li>Runs up to 10 parallel task streams</li>
                        <li>"Teach & Repeat" learns demonstrated workflows</li>
                    </ul>
                </div>
                <div class="visual" style="flex-direction: column; gap: 16px; justify-content: center;">
                    <div class="card" style="background: rgba(239, 68, 68, 0.1); border-color: rgba(239, 68, 68, 0.3); text-align: center;">
                        <p style="font-size: 0.9rem; color: var(--red); margin-bottom: 0.5rem;">The risk</p>
                        <p style="font-size: 1rem;">UI brittleness, broad access requirements, irreversible actions. Require approvals for anything permanent.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- SLIDE: Multi-Agent -->
        <div class="slide slide-two-col">
            <span class="topic-tag orange">Agents</span>
            <h2>Multi-Agent: When It Helps, When It Hurts</h2>
            <div class="cols">
                <div class="col">
                    <h3 class="green">When It Helps</h3>
                    <ul>
                        <li><strong>Parallel research:</strong> Multiple agents gather evidence simultaneously, then consolidate</li>
                        <li><strong>Role separation:</strong> Planner, executor, reviewer as distinct agents</li>
                        <li><strong>Tool specialization:</strong> Different agents with different permissions or domains</li>
                    </ul>
                </div>
                <div class="col">
                    <h3 class="red">When It Hurts</h3>
                    <ul>
                        <li><strong>Non-determinism:</strong> Outcomes vary more with multiple agents</li>
                        <li><strong>Coordination overhead:</strong> Agents disagree or duplicate work</li>
                        <li><strong>Error amplification:</strong> One agent's wrong assumption spreads</li>
                        <li><strong>Cost:</strong> You pay for parallel runs</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- ============================================ -->
        <!-- SKILLS -->
        <!-- ============================================ -->

        <!-- SLIDE: Skills Intro -->
        <div class="slide slide-two-col">
            <span class="topic-tag orange">Skills</span>
            <h2>Skills: Packaged Expertise for Agents</h2>
            <div class="cols">
                <div class="col">
                    <h3 class="orange">Agents execute.</h3>
                    <p>They reason, call tools, handle multi-step workflows. But agents are general-purpose—they don't inherently know your domain.</p>
                </div>
                <div class="col">
                    <h3 class="blue">Skills equip.</h3>
                    <p>Folders of instructions, scripts, and resources that agents load on demand. BigQuery queries. NDA review procedures. PDF extraction. Domain expertise, packaged and portable.</p>
                </div>
            </div>
        </div>

        <!-- SLIDE: Skills Visual -->
        <div class="slide slide-visual">
            <span class="topic-tag orange">Skills</span>
            <h2>How Skills Fit Into Agent Architecture</h2>
            <img src="../../images/skills_architecture.webp" alt="Agent + Skills + Virtual Machine">
            <p class="caption">Agent configuration includes equipped skills and MCP servers. Skills live as directories in the agent's file system—loaded when relevant. Source: Anthropic</p>
        </div>

        <!-- ============================================ -->
        <!-- AGENTIC FRAMEWORKS -->
        <!-- ============================================ -->

        <!-- SLIDE: Agentic Frameworks -->
        <div class="slide slide-statement">
            <span class="topic-tag orange">Frameworks</span>
            <h2>Frameworks moved from "loops" to explicit workflows.</h2>
            <p class="small">Early agent setups: plan, call tool, read output, repeat. In 2025, frameworks moved toward explicit graphs with named steps, clear transitions, and predictable control flow. Debugging a loop is painful. Debugging a workflow is tractable.</p>
        </div>

        <!-- SLIDE: What Changed in Frameworks -->
        <div class="slide slide-cards">
            <span class="topic-tag orange">Frameworks</span>
            <h2>What Changed in Agentic Frameworks</h2>
            <div class="cards-grid two">
                <div class="card" style="border-left: 4px solid var(--blue);">
                    <h3>State Became First-Class</h3>
                    <p>Checkpointing progress so you can resume after failures. Persisting intermediate artifacts. Supporting "pause and wait" for humans or slow systems. Real tasks span hours or days.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--green);">
                    <h3>Human-in-Loop: Designed In</h3>
                    <p>Approval gates, escalation paths, and fallbacks became built-in concepts. Better support for partial automation. Enterprises don't want full autonomy—they want safe delegation.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--purple);">
                    <h3>Tooling Got Structured</h3>
                    <p>Clear contracts for tools: inputs, outputs, errors. Better handling of failures and partial results. Moves toward portable tool ecosystems so apps don't rewrite integrations.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--orange);">
                    <h3>Multi-Agent: Supported, Not Default</h3>
                    <p>Better coordination primitives, message passing, role boundaries. More emphasis on controlling non-determinism. Multi-agent as an advanced pattern, not the starting point.</p>
                </div>
            </div>
        </div>

        <!-- ============================================ -->
        <!-- STANDARDS -->
        <!-- ============================================ -->

        <!-- SLIDE: Why Standards Matter -->
        <div class="slide slide-statement">
            <span class="topic-tag orange">Standards</span>
            <h2>2025 was the year everyone realized fragmentation would kill adoption.</h2>
            <p class="small">Two different interoperability problems emerged. How do AI apps talk to tools and data sources? How do agents coordinate with other agents? The industry started racing toward standard rails.</p>
        </div>

        <!-- SLIDE: MCP and A2A -->
        <div class="slide slide-two-col">
            <span class="topic-tag orange">Standards</span>
            <h2>Two Standards, Two Problems</h2>
            <div class="cols">
                <div class="col">
                    <h3 class="blue">MCP: Tool Connectivity</h3>
                    <p>A universal connector contract so AI apps can talk to tools and data sources consistently.</p>
                    <ul>
                        <li>Standardized tool descriptions</li>
                        <li>Any agent can understand any MCP-compatible tool</li>
                        <li>Reduces integration cost over time</li>
                    </ul>
                </div>
                <div class="col">
                    <h3 class="purple">A2A: Agent-to-Agent</h3>
                    <p>A protocol for agents coordinating with other agents across systems.</p>
                    <ul>
                        <li>Different layer than MCP</li>
                        <li>Enables multi-vendor agent collaboration</li>
                        <li>Critical for complex enterprise workflows</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- SLIDE: Protocol Wars Timeline -->
        <div class="slide slide-list">
            <span class="topic-tag orange">Standards</span>
            <h2>The Protocol Wars: From Fragmentation to Open Governance</h2>
            <ul>
                <li class="blue"><strong>April 2025:</strong> Google announces Agent2Agent (A2A) protocol. The agent-to-agent communication problem gets a proposed standard.</li>
                <li class="green"><strong>June 2025:</strong> Linux Foundation launches Agent2Agent protocol project. Microsoft publicly backs the open protocol.</li>
                <li class="purple"><strong>December 2025:</strong> Anthropic donates MCP to Linux Foundation's "Agentic AI Foundation." Positioned explicitly around neutrality and open governance.</li>
                <li class="orange"><strong>The pattern:</strong> Corporate-controlled APIs lose to open standards. Governance determines whether a standard becomes real infrastructure.</li>
            </ul>
        </div>

        <!-- SLIDE: Why This Matters -->
        <div class="slide slide-statement">
            <span class="topic-tag orange">Standards</span>
            <h2>Standards reduce vendor lock-in. Standards reduce integration cost. Open governance wins.</h2>
            <p class="small">The move to Linux Foundation wasn't just about technology. It was about trust. Enterprises adopt standards they can rely on outlasting any single vendor's strategy.</p>
        </div>

        <!-- ============================================ -->
        <!-- TAKEAWAYS -->
        <!-- ============================================ -->

        <!-- SLIDE: Application Takeaways -->
        <div class="slide slide-list">
            <h2 class="orange">Application Layer: Key Takeaways</h2>
            <ul>
                <li class="orange"><strong>RAG survived because enterprises need grounding, freshness, and control.</strong> What changed: RAG became an engineered system, not a trick.</li>
                <li class="orange"><strong>Agent types diversified.</strong> Deep for long-horizon work, ambient for always-on automation, browser for UI control, coding as the breakthrough success.</li>
                <li class="orange"><strong>Skills and frameworks matured.</strong> Reusable capabilities, explicit workflows, state management, and human-in-loop by design.</li>
                <li class="orange"><strong>Standards moved to open governance.</strong> MCP and A2A under Linux Foundation. The protocol wars are consolidating.</li>
            </ul>
        </div>



        <!-- ============================================ -->
        <!-- SECTION 4: OUTPUT LAYER - Evals & Monitoring -->
        <!-- ============================================ -->

        <!-- SLIDE: Section Break -->
        <div class="slide slide-section">
            <p class="label purple">Section 4</p>
            <h2>Output Layer</h2>
            <p class="sub">Evals & Production Monitoring</p>
            <div class="framework-container">
                <svg class="framework-svg" viewBox="0 0 950 480" xmlns="http://www.w3.org/2000/svg" style="max-width: 1100px;">
                    <g class="framework-layer dimmed"><rect x="20" y="15" width="750" height="95" rx="8" fill="#3b82f6" opacity="0.15" stroke="#3b82f6" stroke-width="2"/><text x="30" y="38" fill="#3b82f6" font-weight="700" font-size="14">INPUT LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="120" width="750" height="95" rx="8" fill="#10b981" opacity="0.15" stroke="#10b981" stroke-width="2"/><text x="30" y="143" fill="#10b981" font-weight="700" font-size="14">DATA AND MODEL LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="225" width="750" height="95" rx="8" fill="#f97316" opacity="0.15" stroke="#f97316" stroke-width="2"/><text x="30" y="248" fill="#f97316" font-weight="700" font-size="14">APPLICATION LAYER</text></g>
                    <g class="framework-layer">
                        <rect x="20" y="330" width="750" height="95" rx="8" fill="#8b5cf6" opacity="0.15" stroke="#8b5cf6" stroke-width="2"/>
                        <text x="30" y="353" fill="#8b5cf6" font-weight="700" font-size="14">OUTPUT LAYER</text>
                        <rect x="30" y="365" width="360" height="50" rx="6" fill="#8b5cf6"/><text x="210" y="395" text-anchor="middle" fill="white" font-size="11" font-weight="500">Evals</text>
                        <rect x="400" y="365" width="360" height="50" rx="6" fill="#8b5cf6"/><text x="580" y="395" text-anchor="middle" fill="white" font-size="11" font-weight="500">Production Monitoring</text>
                    </g>
                    <rect class="highlight-ring active" x="15" y="325" width="760" height="105" rx="12"/>
                    <g class="framework-layer dimmed"><rect x="790" y="15" width="145" height="410" rx="8" fill="#ef4444" opacity="0.15" stroke="#ef4444" stroke-width="2"/><text x="862" y="220" text-anchor="middle" fill="#ef4444" font-weight="700" font-size="13">CHALLENGES</text></g>
                </svg>
            </div>
        </div>

        <!-- SLIDE: Section Overview -->
        <div class="slide slide-list">
            <h2>What's in the Output Layer</h2>
            <ul>
                <li class="purple"><strong>Evals became the bottleneck.</strong> Teams that shipped fast had evals running before features, not after.</li>
                <li class="purple"><strong>Model evals vs product evals.</strong> Benchmarks tell you about the model. Production metrics tell you about your system.</li>
                <li class="purple"><strong>Agent evaluation got structured.</strong> Four buckets emerged for evaluating agentic systems systematically.</li>
                <li class="purple"><strong>Monitoring closed the loop.</strong> Real-time signals feeding back into development. The flywheel that compounds quality.</li>
            </ul>
        </div>

        <!-- SLIDE: Quality Verification Bottleneck -->
        <div class="slide slide-statement">
            <span class="topic-tag purple">Quality Verification</span>
            <h2>Quality verification became the bottleneck for shipping AI.</h2>
        </div>

        <!-- SLIDE: Model vs Product Evals -->
        <div class="slide slide-visual">
            <span class="topic-tag purple">Evals</span>
            <h2>Model Evals vs Product Evals</h2>
            <img src="images/model_vs_product_evaluation.png" alt="Model Evals vs Product Evals">
            <p class="caption">Model evals test the underlying model (benchmarks, capabilities). Product evals test your system (task completion, user success). Both matter—but product evals determine if you ship.</p>
        </div>

        <!-- SLIDE: Evals vs Monitoring -->
        <div class="slide slide-vs">
            <span class="topic-tag purple">Evals</span>
            <div class="vs-box" style="background: rgba(139, 92, 246, 0.1); border-color: rgba(139, 92, 246, 0.3);">
                <span class="tag" style="color: var(--purple);">Evals</span>
                <h3>Offline Quality Assurance</h3>
                <p>Run before deployment. Test against known datasets. Catch regressions before users see them. Answer: "Is this change safe to ship?"</p>
            </div>
            <span class="vs-arrow">→</span>
            <div class="vs-box" style="background: rgba(16, 185, 129, 0.1); border-color: rgba(16, 185, 129, 0.3);">
                <span class="tag" style="color: var(--green);">Monitoring</span>
                <h3>Online Quality Assurance</h3>
                <p>Run in production. Track real user interactions. Catch issues evals missed. Answer: "Is this working for actual users?"</p>
            </div>
        </div>

        <!-- SLIDE: Online vs Offline Timing -->
        <div class="slide slide-visual">
            <span class="topic-tag purple">Evals</span>
            <h2>Evals vs Monitoring: When They Run</h2>
            <img src="images/online_vs_offline_timing.png" alt="Online vs Offline Timing">
            <p class="caption">Evals run offline before deployment. Monitoring runs online in production. Both essential—different timing, different purpose.</p>
        </div>

        <!-- SLIDE: Eval Mental Model -->
        <div class="slide slide-statement">
            <span class="topic-tag purple">Evals</span>
            <h2>The eval mental model: What are you actually testing?</h2>
            <p class="small">Every eval answers one of three questions. (1) Can it do the task at all? Capability. (2) Does it still do the task after changes? Regression. (3) Does it do the task the way we want? Alignment. Know which question you're asking.</p>
        </div>

        <!-- SLIDE: Agent Evaluation Buckets -->
        <div class="slide slide-cards">
            <span class="topic-tag purple">Evals</span>
            <h2>Four Buckets for Agent Evaluation</h2>
            <div class="cards-grid two">
                <div class="card" style="border-left: 4px solid var(--blue);">
                    <h3>1. Task Completion</h3>
                    <p>Did the agent achieve the goal? Binary success/failure on well-defined objectives. The baseline metric.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--green);">
                    <h3>2. Trajectory Quality</h3>
                    <p>How did it get there? Efficient tool use, sensible step ordering, recovery from errors. The path matters.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--orange);">
                    <h3>3. Safety & Boundaries</h3>
                    <p>Did it stay in bounds? No unauthorized actions, proper escalation, respecting guardrails. Trust requires limits.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--purple);">
                    <h3>4. Resource Efficiency</h3>
                    <p>What did it cost? Tokens consumed, API calls made, time elapsed. Efficiency at scale.</p>
                </div>
            </div>
        </div>

        <!-- SLIDE: Grader Stack -->
        <div class="slide slide-visual">
            <span class="topic-tag purple">Evals</span>
            <h2>The Grader Stack: Who Evaluates?</h2>
            <img src="images/three_evaluation_approaches.png" alt="Three Evaluation Approaches">
            <p class="caption">Deterministic checks first (fast, cheap). LLM-as-judge for scale (the 2025 breakthrough). Human review for calibration and edge cases.</p>
        </div>

        <!-- SLIDE: Capability vs Regression -->
        <div class="slide slide-vs">
            <span class="topic-tag purple">Evals</span>
            <div class="vs-box" style="background: rgba(59, 130, 246, 0.1); border-color: rgba(59, 130, 246, 0.3);">
                <span class="tag" style="color: var(--blue);">Capability Evals</span>
                <h3>"Can it do new things?"</h3>
                <p>Testing new features. Expanding to new domains. Pushing boundaries. Run when adding capabilities.</p>
            </div>
            <span class="vs-arrow">↔</span>
            <div class="vs-box" style="background: rgba(239, 68, 68, 0.1); border-color: rgba(239, 68, 68, 0.3);">
                <span class="tag" style="color: var(--red);">Regression Evals</span>
                <h3>"Does it still work?"</h3>
                <p>Catching breakage. Model updates, prompt changes, dependency shifts. Run on every change. Non-negotiable.</p>
            </div>
        </div>

        <!-- SLIDE: The Flywheel -->
        <div class="slide slide-visual">
            <span class="topic-tag purple">Monitoring</span>
            <h2>The Eval Flywheel: How Quality Compounds</h2>
            <img src="images/continuous_improvement_flywheel.png" alt="Continuous Improvement Flywheel">
            <p class="caption">Ship → Observe → Curate failures into eval cases → Eval before next deploy → Improve → Ship again. Each cycle makes the system more robust.</p>
        </div>

        <!-- SLIDE: What to Look For -->
        <div class="slide slide-list">
            <span class="topic-tag purple">Building AI Products</span>
            <h2>If You're Building AI Products, Know This</h2>
            <ul>
                <li class="purple"><strong>Evals before features.</strong> You can't iterate fast without fast feedback. Build the eval harness first.</li>
                <li class="blue"><strong>LLM-as-judge scales.</strong> Human review doesn't. Calibrate your LLM graders against human judgment, then trust them.</li>
                <li class="green"><strong>Regression tests are sacred.</strong> Every production failure becomes a test case. The suite only grows.</li>
                <li class="orange"><strong>Monitor implicit signals.</strong> Users don't file bug reports. They regenerate, abandon, or leave. Watch behavior.</li>
                <li class="red"><strong>Close the loop.</strong> Production → evals → improvements → production. The flywheel compounds.</li>
            </ul>
        </div>

        <!-- SLIDE: Output Takeaways -->
        <div class="slide slide-list">
            <h2 class="purple">Output Layer: Key Takeaways</h2>
            <ul>
                <li class="purple"><strong>Evals are the shipping bottleneck.</strong> Fast eval cycles = fast iteration. Invest here first.</li>
                <li class="purple"><strong>Model evals ≠ product evals.</strong> Benchmarks don't tell you if users succeed. Test what matters.</li>
                <li class="purple"><strong>LLM-as-judge changed evaluation.</strong> Scale beyond human capacity. Calibrate carefully.</li>
                <li class="purple"><strong>The flywheel wins.</strong> Production failures → eval cases → prevented failures. Compound quality over time.</li>
            </ul>
        </div>



        <!-- ============================================ -->
        <!-- SECTION 5: WHAT'S BROKEN -->
        <!-- ============================================ -->

        <!-- SLIDE: Section Break -->
        <div class="slide slide-section">
            <p class="label red">Section 5</p>
            <h2>What's Still Broken</h2>
            <p class="sub">The Challenges That Remain</p>
            <div class="framework-container">
                <svg class="framework-svg" viewBox="0 0 950 480" xmlns="http://www.w3.org/2000/svg" style="max-width: 1100px;">
                    <g class="framework-layer dimmed"><rect x="20" y="15" width="750" height="95" rx="8" fill="#3b82f6" opacity="0.15" stroke="#3b82f6" stroke-width="2"/><text x="30" y="38" fill="#3b82f6" font-weight="700" font-size="14">INPUT LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="120" width="750" height="95" rx="8" fill="#10b981" opacity="0.15" stroke="#10b981" stroke-width="2"/><text x="30" y="143" fill="#10b981" font-weight="700" font-size="14">DATA AND MODEL LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="225" width="750" height="95" rx="8" fill="#f97316" opacity="0.15" stroke="#f97316" stroke-width="2"/><text x="30" y="248" fill="#f97316" font-weight="700" font-size="14">APPLICATION LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="330" width="750" height="95" rx="8" fill="#8b5cf6" opacity="0.15" stroke="#8b5cf6" stroke-width="2"/><text x="30" y="353" fill="#8b5cf6" font-weight="700" font-size="14">OUTPUT LAYER</text></g>
                    <g class="framework-layer">
                        <rect x="790" y="15" width="145" height="410" rx="8" fill="#ef4444" opacity="0.15" stroke="#ef4444" stroke-width="2"/>
                        <text x="862" y="42" text-anchor="middle" fill="#ef4444" font-weight="700" font-size="13">CHALLENGES</text>
                        <rect x="800" y="55" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="80" text-anchor="middle" fill="white" font-size="10" font-weight="500">Hallucinations</text>
                        <rect x="800" y="100" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="125" text-anchor="middle" fill="white" font-size="10" font-weight="500">Inconsistent Reasoning</text>
                        <rect x="800" y="145" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="170" text-anchor="middle" fill="white" font-size="10" font-weight="500">Over-Autonomy</text>
                        <rect x="800" y="190" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="215" text-anchor="middle" fill="white" font-size="10" font-weight="500">Poor Tool Grounding</text>
                        <rect x="800" y="235" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="260" text-anchor="middle" fill="white" font-size="10" font-weight="500">Long Context Drift</text>
                        <rect x="800" y="280" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="305" text-anchor="middle" fill="white" font-size="10" font-weight="500">Retrieval Issues</text>
                        <rect x="800" y="325" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="350" text-anchor="middle" fill="white" font-size="10" font-weight="500">Multi-Agent Errors</text>
                        <rect x="800" y="370" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="395" text-anchor="middle" fill="white" font-size="10" font-weight="500">Debugging</text>
                    </g>
                    <rect class="highlight-ring active" x="785" y="10" width="155" height="420" rx="12"/>
                </svg>
            </div>
        </div>

        <!-- SLIDE: Why Challenges Spiked in 2025 -->
        <div class="slide slide-content">
            <span class="topic-tag red">2025 Reality</span>
            <h2>Why These Challenges Spiked in 2025</h2>
            <div class="body">
                <div class="text">
                    <ul>
                        <li><strong>Systems crossed a threshold.</strong> They stopped being "text generators" and started being "workflow executors."</li>
                        <li><strong>Agents ran longer.</strong> Used tools. Operated across multiple context windows. Interacted with real environments.</li>
                        <li><strong>Manual testing hit a wall.</strong> Teams reached a breaking point—"flying blind" after changes, unable to distinguish regressions from noise.</li>
                        <li><strong>These aren't random problems.</strong> They are the predictable cost of systems getting more capable and more connected.</li>
                    </ul>
                </div>
                <div class="visual">
                    <img src="images/why_challenges_spiked.png" alt="Why Challenges Spiked in 2025">
                </div>
            </div>
        </div>

        <!-- SLIDE: Hallucinations Reframed -->
        <div class="slide slide-content">
            <span class="topic-tag red">Hallucinations</span>
            <h2>Hallucinations Became "False Claims About Actions"</h2>
            <div class="body">
                <div class="text">
                    <ul>
                        <li><strong>Not just fake facts anymore.</strong> In 2025, hallucinations showed up as false claims about what the system did inside a workflow.</li>
                        <li><strong>The dangerous pattern:</strong> Agent says "your flight has been booked"—but the reservation never appeared in the database.</li>
                        <li><strong>This is hallucinating the world state.</strong> The model confidently reports completing actions it never attempted.</li>
                        <li><strong>High-stakes domains exposed the risk.</strong> Legal, medical, and financial tools showed hallucination remains a major practical risk.</li>
                    </ul>
                </div>
                <div class="visual">
                    <img src="images/hallucinations_false_aciton.png" alt="Hallucinations as False Action Claims">
                </div>
            </div>
        </div>

        <!-- SLIDE: Inconsistent Reasoning -->
        <div class="slide slide-content">
            <span class="topic-tag red">Inconsistent Reasoning</span>
            <h2>Inconsistent Reasoning Became a Reliability Problem</h2>
            <div class="body">
                <div class="text">
                    <ul>
                        <li><strong>Inconsistency always existed.</strong> But 2025 made it visible because agent behavior is multi-step and path-dependent.</li>
                        <li><strong>Two runs, different outcomes.</strong> Same prompt can take different tool sequences and reach completely different results.</li>
                        <li><strong>Non-determinism is the default.</strong> Think in success rates across multiple trials—a task can pass once, fail the next.</li>
                        <li><strong>The key reframe:</strong> It's not enough to ask "did it work once." You need to ask "how often does it work."</li>
                    </ul>
                </div>
                <div class="visual">
                    <img src="images/inconsistent_reasoning.png" alt="Inconsistent Reasoning">
                </div>
            </div>
        </div>

        <!-- SLIDE: Over-Autonomy -->
        <div class="slide slide-content">
            <span class="topic-tag red">Over-Autonomy</span>
            <h2>Over-Autonomy: Capability Rose Faster Than Control</h2>
            <div class="body">
                <div class="text">
                    <ul>
                        <li><strong>2025 put "agency risk" on the map.</strong> Agents could take real actions—especially via browser and computer use.</li>
                        <li><strong>The pattern we saw:</strong> "Delete the test file" becomes "I've cleaned up all test files and reorganized your directory."</li>
                        <li><strong>The tradeoff became clear:</strong> Confirmation steps reduce autonomy but block high-risk operations. That's a feature, not a bug.</li>
                        <li><strong>Human approval gates became a design pattern.</strong> Not a nice-to-have—an explicit requirement for production systems.</li>
                    </ul>
                </div>
                <div class="visual">
                    <img src="images/over_autonomy.png" alt="Over-Autonomy">
                </div>
            </div>
        </div>

        <!-- SLIDE: Poor Tool Grounding -->
        <div class="slide slide-content">
            <span class="topic-tag red">Tool Grounding</span>
            <h2>Poor Tool Grounding: Tools Are Unforgiving</h2>
            <div class="body">
                <div class="text">
                    <ul>
                        <li><strong>Tool grounding became measurable.</strong> Systems used more tools more often—failures became obvious and quantifiable.</li>
                        <li><strong>Wrong tool selection:</strong> Models pick semantically similar tools that are functionally wrong.</li>
                        <li><strong>Malformed calls:</strong> Arguments in wrong formats, required fields missing, JSON that almost parses but doesn't.</li>
                        <li><strong>Phantom tools:</strong> Agents calling tools that don't exist—hallucinating capabilities based on what "should" be available.</li>
                    </ul>
                </div>
                <div class="visual">
                    <img src="images/tool_call_issues.png" alt="Tool Call Issues">
                </div>
            </div>
        </div>

        <!-- SLIDE: Long Context Drift -->
        <div class="slide slide-list">
            <span class="topic-tag red">Context Drift</span>
            <h2>Long Context Drift: More Context Increased Noise</h2>
            <ul>
                <li class="red"><strong>Long context grew fast.</strong> But 2025 proved longer context doesn't guarantee better use of information.</li>
                <li class="red"><strong>"Lost in the Middle" is real.</strong> Performance degrades when relevant information sits in the middle of long inputs. Best recall: beginning or end.</li>
                <li class="red"><strong>Context pollution compounds.</strong> Without structure, more context means more distraction. Compaction and structured notes help.</li>
                <li class="red"><strong>The 2025 lesson:</strong> Long context increased capacity, but without active management it increased noise.</li>
            </ul>
            <p class="subtext">Actionable: Structure your context. Put critical instructions at start and end. Compact aggressively over long horizons.</p>
        </div>

        <!-- SLIDE: Retrieval Issues -->
        <div class="slide slide-content">
            <span class="topic-tag red">Retrieval</span>
            <h2>Retrieval Issues: "Did We Retrieve" vs "Did We Use It"</h2>
            <div class="body">
                <div class="text">
                    <ul>
                        <li><strong>Retrieval got better, failures got subtler.</strong> The problem shifted from retrieval accuracy to end-to-end grounding.</li>
                        <li><strong>Semantic similarity ≠ relevance.</strong> Query "Q4 customer churn" and get docs about satisfaction, Q3 churn, Q4 revenue. All close. None useful.</li>
                        <li><strong>The new failure mode:</strong> Models sometimes fail to leverage retrieved passages—especially when irrelevant context is present.</li>
                        <li><strong>The ideal behavior is binary:</strong> Answer correctly OR say "I don't know" when info is missing.</li>
                    </ul>
                </div>
                <div class="visual">
                    <img src="images/retrieval_issues.png" alt="Retrieval Issues">
                </div>
            </div>
        </div>

        <!-- SLIDE: Multi-Agent Errors -->
        <div class="slide slide-list">
            <span class="topic-tag red">Multi-Agent</span>
            <h2>Multi-Agent Errors: Coordination as Failure Surface</h2>
            <ul>
                <li class="red"><strong>Multi-agent systems scaled in 2025.</strong> But coordination errors emerged as a new class of failures.</li>
                <li class="red"><strong>Error cascades:</strong> Agent A makes a small mistake. Agent B builds on it. By Agent D, the error is unrecognizable but catastrophic.</li>
                <li class="red"><strong>Coordination breakdowns:</strong> Agents assume what others will do. Assumptions conflict. Deadlocks and race conditions emerge.</li>
                <li class="red"><strong>The tradeoff:</strong> More agents = more parallelism, but also more contradiction risk, duplication risk, and propagation risk.</li>
            </ul>
            <p class="subtext">Actionable: Design coordination protocols explicitly. Don't assume agents will self-organize correctly.</p>
        </div>

        <!-- SLIDE: Debugging -->
        <div class="slide slide-list">
            <span class="topic-tag red">Debugging</span>
            <h2>Debugging: The Hardest Day-to-Day Challenge</h2>
            <ul>
                <li class="red"><strong>This is where all challenges compound.</strong> Debugging became painful because failures come from trajectories, not single outputs.</li>
                <li class="red"><strong>Without evals, debugging is reactive.</strong> Teams wait for complaints, reproduce manually, fix, and hope nothing else regressed.</li>
                <li class="red"><strong>Agent observability is immature.</strong> We need standardized metrics, traces, and logs—most teams are still building custom solutions.</li>
                <li class="red"><strong>Different roles need different views.</strong> Developers, testers, and ops all need visibility into the same system, but with different lenses.</li>
            </ul>
            <p class="subtext">If you can't trace what the system did, you don't control it. In 2025, teams stopped pretending otherwise.</p>
        </div>

        <!-- SLIDE: Challenges Takeaways -->
        <div class="slide slide-list">
            <h2 class="red">Challenges: Key Takeaways</h2>
            <ul>
                <li class="red"><strong>These challenges are predictable.</strong> More capability = more failure modes. Design for them upfront.</li>
                <li class="red"><strong>Hallucinations are now operational.</strong> Verify actions in target systems. Don't trust self-reports.</li>
                <li class="red"><strong>Think in success rates, not single runs.</strong> Product reliability depends on consistency across trials.</li>
                <li class="red"><strong>Build human gates before irreversible actions.</strong> Confirmation steps are a feature.</li>
                <li class="red"><strong>Invest in observability early.</strong> If you can't trace trajectories, you can't debug agents.</li>
            </ul>
        </div>



        <!-- ============================================ -->
        <!-- SECTION 6: ROAD AHEAD -->
        <!-- ============================================ -->

        <!-- SLIDE: Section Break -->
        <div class="slide slide-section">
            <p class="label purple">Section 6</p>
            <h2>The Road Ahead</h2>
            <p class="sub">What 2026 Looks Like</p>
        </div>

        <!-- SLIDE: Boring Infrastructure -->
        <div class="slide slide-statement">
            <span class="topic-tag purple">2026 Outlook</span>
            <h2>It will be <span class="blue">boring infrastructure</span> that works.</h2>
            <p class="small">Like databases in the 1990s. Like cloud computing in the 2010s. The technology will transition from competitive advantage to table stakes.</p>
        </div>

        <!-- SLIDE: Road Ahead Takeaways -->
        <div class="slide slide-list">
            <h2 class="purple">Road Ahead: Key Takeaways</h2>
            <ul>
                <li class="blue"><strong>AI becomes infrastructure.</strong> By 2027, asking "do you use AI?" will be like asking "do you use databases?"</li>
                <li class="blue"><strong>Integration quality determines success.</strong> The model choice matters less than how well you deploy it.</li>
                <li class="blue"><strong>Talent profiles evolve.</strong> Systems thinking and domain expertise beat pure ML knowledge.</li>
                <li class="blue"><strong>Regional approaches diverge.</strong> Privacy, efficiency, capability: different markets optimize differently.</li>
            </ul>
        </div>



        <!-- ============================================ -->
        <!-- CLOSING (Slides 73-80) -->
        <!-- ============================================ -->
        
        <!-- SLIDE 73: Final Takeaways Title -->
        <div class="slide slide-section">
            <p class="label purple">Final</p>
            <h2>What to Remember</h2>
        </div>
        
        <!-- SLIDE 74: Takeaway 1 -->
        <div class="slide slide-statement">
            <h2>AI will become standard infrastructure.</h2>
            <p class="small">Competitive advantage comes from how you use it, not whether you have it. The question isn't "are you using AI?" but "how well are you using AI?"</p>
        </div>
        
        <!-- SLIDE 75: Takeaway 2 -->
        <div class="slide slide-statement">
            <h2>Integration quality beats model selection.</h2>
            <p class="small">The best model poorly integrated loses to a good model well integrated. Invest in the plumbing. The unsexy infrastructure work is where the value is.</p>
        </div>
        
        <!-- SLIDE 76: Takeaway 3 -->
        <div class="slide slide-statement">
            <h2>Build evaluation, cost tracking, and safety into your stack now.</h2>
            <p class="small">Enterprises will require it. Production guarantees, SLAs, indemnification, predictable pricing:the age of experimentation gives way to operational discipline.</p>
        </div>
        
        <!-- SLIDE 77: Takeaway 4 -->
        <div class="slide slide-statement">
            <h2>Measure business outcomes, not AI capabilities.</h2>
            <p class="small">The most impressive deployments won't be the most technically sophisticated:they'll be the ones solving real problems for real users at sustainable costs.</p>
        </div>
        
        <!-- SLIDE 78: The Most Important Lesson -->
        <div class="slide slide-quote">
            <blockquote>"AI's value doesn't come from any single breakthrough but from making all the pieces work together."</blockquote>
            <p class="attr">The future belongs not to those with the best models, but to those who best integrate AI into the messy reality of human work.</p>
        </div>
        
        <!-- SLIDE 79: State of AI Summary -->
        <div class="slide slide-list">
            <h2>The State of Applied AI in 2025</h2>
            <ul>
                <li class="green"><strong>It works, mostly.</strong> Teams that shipped focused on narrow scope, human checkpoints, and boring reliability over impressive capabilities.</li>
                <li class="orange"><strong>It's expensive:but manageable.</strong> Cost optimization is a discipline now. Caching, quantization, and specialization make production viable.</li>
                <li class="purple"><strong>Most pilots fail.</strong> Not because AI doesn't work, but because integration, reliability, and cost weren't planned for.</li>
                <li class="blue"><strong>The foundations are solid.</strong> Standards like MCP exist. Patterns are documented. The wild experimentation gives way to disciplined engineering.</li>
            </ul>
            <p class="subtext">The gap between demo and production is where most projects die. Plan for it.</p>
        </div>
        
        <!-- SLIDE 80: Thank You -->
        <div class="slide slide-title">
            <h1>State of Applied AI in 2025</h1>
            <p class="subtitle" style="margin-top: 2rem;">Questions?</p>
            <p class="muted" style="margin-top: 3rem; font-size: 0.9rem;">Based on ICONIQ Growth GenAI Survey, State of AI Report 2025, MIT/Fortune research, Cleanlab production surveys, RAGFlow analysis</p>
        </div>


    </div>

    <nav class="nav">
        <button onclick="prevSlide()">← Prev</button>
        <span class="counter"><span id="current">1</span> / <span id="total">80</span></span>
        <button onclick="nextSlide()">Next →</button>
    </nav>

    <script src="script.js"></script>
</body>
</html>

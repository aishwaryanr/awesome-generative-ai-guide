        <!-- ============================================ -->
        <!-- SECTION 5: WHAT'S BROKEN -->
        <!-- ============================================ -->

        <!-- SLIDE: Section Break -->
        <div class="slide slide-section">
            <p class="label red">Section 5</p>
            <h2>What's Still Broken</h2>
            <p class="sub">The Challenges That Remain</p>
            <div class="framework-container">
                <svg class="framework-svg" viewBox="0 0 950 480" xmlns="http://www.w3.org/2000/svg" style="max-width: 1100px;">
                    <g class="framework-layer dimmed"><rect x="20" y="15" width="750" height="95" rx="8" fill="#3b82f6" opacity="0.15" stroke="#3b82f6" stroke-width="2"/><text x="30" y="38" fill="#3b82f6" font-weight="700" font-size="14">INPUT LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="120" width="750" height="95" rx="8" fill="#10b981" opacity="0.15" stroke="#10b981" stroke-width="2"/><text x="30" y="143" fill="#10b981" font-weight="700" font-size="14">DATA AND MODEL LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="225" width="750" height="95" rx="8" fill="#f97316" opacity="0.15" stroke="#f97316" stroke-width="2"/><text x="30" y="248" fill="#f97316" font-weight="700" font-size="14">APPLICATION LAYER</text></g>
                    <g class="framework-layer dimmed"><rect x="20" y="330" width="750" height="95" rx="8" fill="#8b5cf6" opacity="0.15" stroke="#8b5cf6" stroke-width="2"/><text x="30" y="353" fill="#8b5cf6" font-weight="700" font-size="14">OUTPUT LAYER</text></g>
                    <g class="framework-layer">
                        <rect x="790" y="15" width="145" height="410" rx="8" fill="#ef4444" opacity="0.15" stroke="#ef4444" stroke-width="2"/>
                        <text x="862" y="42" text-anchor="middle" fill="#ef4444" font-weight="700" font-size="13">CHALLENGES</text>
                        <rect x="800" y="55" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="80" text-anchor="middle" fill="white" font-size="10" font-weight="500">Hallucinations</text>
                        <rect x="800" y="100" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="125" text-anchor="middle" fill="white" font-size="10" font-weight="500">Inconsistent Reasoning</text>
                        <rect x="800" y="145" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="170" text-anchor="middle" fill="white" font-size="10" font-weight="500">Over-Autonomy</text>
                        <rect x="800" y="190" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="215" text-anchor="middle" fill="white" font-size="10" font-weight="500">Poor Tool Grounding</text>
                        <rect x="800" y="235" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="260" text-anchor="middle" fill="white" font-size="10" font-weight="500">Long Context Drift</text>
                        <rect x="800" y="280" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="305" text-anchor="middle" fill="white" font-size="10" font-weight="500">Retrieval Issues</text>
                        <rect x="800" y="325" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="350" text-anchor="middle" fill="white" font-size="10" font-weight="500">Multi-Agent Errors</text>
                        <rect x="800" y="370" width="125" height="38" rx="5" fill="#ef4444"/><text x="862" y="395" text-anchor="middle" fill="white" font-size="10" font-weight="500">Debugging</text>
                    </g>
                    <rect class="highlight-ring active" x="785" y="10" width="155" height="420" rx="12"/>
                </svg>
            </div>
        </div>

        <!-- SLIDE: Why Challenges Spiked in 2025 -->
        <div class="slide slide-list">
            <span class="topic-tag red">2025 Reality</span>
            <h2>Why These Challenges Spiked in 2025</h2>
            <ul>
                <li class="red"><strong>Systems crossed a threshold.</strong> They stopped being "text generators" and started being "workflow executors."</li>
                <li class="red"><strong>Agents ran longer.</strong> Used tools. Operated across multiple context windows. Interacted with real environments.</li>
                <li class="red"><strong>Manual testing hit a wall.</strong> Teams reached a breaking point—"flying blind" after changes, unable to distinguish real regressions from noise.</li>
                <li class="red"><strong>These red boxes aren't random.</strong> They are the predictable cost of systems getting more capable and more connected.</li>
            </ul>
        </div>

        <!-- SLIDE: Hallucinations Reframed -->
        <div class="slide slide-list">
            <span class="topic-tag red">Hallucinations</span>
            <h2>Hallucinations Became "False Claims About Actions"</h2>
            <ul>
                <li class="red"><strong>Not just fake facts anymore.</strong> In 2025, hallucinations showed up as false claims about what the system did inside a workflow.</li>
                <li class="red"><strong>The Anthropic example:</strong> Agent says "your flight has been booked"—but did the reservation actually appear in the database?</li>
                <li class="red"><strong>This is hallucinating the world state.</strong> Not hallucinating an answer. The model confidently reports actions it never completed.</li>
                <li class="red"><strong>High-stakes domains exposed the risk.</strong> Stanford's Legal RAG work showed hallucination remains a major practical risk even in tools marketed as "safer."</li>
            </ul>
            <p class="subtext">Actionable: Verify actions exist in the target system. Don't trust the model's self-report.</p>
        </div>

        <!-- SLIDE: Inconsistent Reasoning -->
        <div class="slide slide-list">
            <span class="topic-tag red">Inconsistent Reasoning</span>
            <h2>Inconsistent Reasoning Became a Product Reliability Problem</h2>
            <ul>
                <li class="red"><strong>Inconsistency always existed.</strong> But 2025 made it visible because agent behavior is multi-step and path-dependent.</li>
                <li class="red"><strong>Two runs, different outcomes.</strong> Same prompt can take different tool sequences and reach different results.</li>
                <li class="red"><strong>Non-determinism is the default.</strong> Anthropic recommends thinking in success rates across multiple trials—a task can pass in one run, fail in the next.</li>
                <li class="red"><strong>The key 2025 reframe:</strong> It's not enough to ask "did it work once." You need to ask "how often does it work."</li>
            </ul>
            <p class="subtext">Product reliability depends on tail cases, not best cases. Build for the 95th percentile.</p>
        </div>

        <!-- SLIDE: Over-Autonomy -->
        <div class="slide slide-list">
            <span class="topic-tag red">Over-Autonomy</span>
            <h2>Over-Autonomy: Capability Rose Faster Than Control</h2>
            <ul>
                <li class="red"><strong>2025 put "agency risk" on the map.</strong> Agents could take real actions—especially via browser and computer use.</li>
                <li class="red"><strong>OpenAI's Operator system card is explicit:</strong> Human oversight at key steps. Explicit confirmation before financial transactions, sending emails, deleting calendar events.</li>
                <li class="red"><strong>The tradeoff is documented:</strong> Confirmation steps reduce autonomy but block high-risk operations. That's a feature, not a bug.</li>
                <li class="red"><strong>The 2025 trendline:</strong> "Human approval gates" moved from nice safety idea to explicit design pattern.</li>
            </ul>
            <p class="subtext">Actionable: Build confirmation gates before irreversible actions. Don't trust the agent to know what's sensitive.</p>
        </div>

        <!-- SLIDE: Poor Tool Grounding -->
        <div class="slide slide-list">
            <span class="topic-tag red">Tool Grounding</span>
            <h2>Poor Tool Grounding: Tools Are Unforgiving</h2>
            <ul>
                <li class="red"><strong>Tool grounding became measurable.</strong> Systems used more tools more often—failures became obvious.</li>
                <li class="red"><strong>Wrong tool selection:</strong> EMNLP 2024 benchmark shows models using wrong tools or even non-existent tools during augmented tasks.</li>
                <li class="red"><strong>Tool exploration failures:</strong> AVATAR paper found ReAct-style agents select tools based on prior knowledge, struggle to explore better choices even with extensive reasoning.</li>
                <li class="red"><strong>Error loops:</strong> December 2025 research reports agents repeating the same tool misuse even when error messages provide explicit valid usage.</li>
            </ul>
            <p class="subtext">Tool failures aren't just model weaknesses. They're an interface + grounding + error recovery problem.</p>
        </div>

        <!-- SLIDE: Long Context Drift -->
        <div class="slide slide-list">
            <span class="topic-tag red">Context Drift</span>
            <h2>Long Context Drift: More Context Increased Noise</h2>
            <ul>
                <li class="red"><strong>Long context grew fast.</strong> But 2025 proved longer context doesn't guarantee better use of information.</li>
                <li class="red"><strong>"Lost in the Middle" is real.</strong> Performance degrades when relevant information sits in the middle of long inputs. Best performance: beginning or end.</li>
                <li class="red"><strong>Anthropic's context engineering:</strong> Frames this as a practical systems issue. Recommends compaction, structured note-taking to reduce context pollution.</li>
                <li class="red"><strong>The 2025 trendline:</strong> Long context increased capacity, but without structure it increased distraction.</li>
            </ul>
            <p class="subtext">Actionable: Structure your context. Put critical instructions at start and end. Compact aggressively over long horizons.</p>
        </div>

        <!-- SLIDE: Retrieval Issues -->
        <div class="slide slide-list">
            <span class="topic-tag red">Retrieval</span>
            <h2>Retrieval Issues: From "Did We Retrieve" to "Did We Use It"</h2>
            <ul>
                <li class="red"><strong>Retrieval got better, failures got subtler.</strong> The problem shifted from retrieval accuracy to end-to-end grounding.</li>
                <li class="red"><strong>Anthropic's contextual retrieval:</strong> Quantified improvements using contextual embeddings + BM25 + reranking. Large reductions in failed retrievals.</li>
                <li class="red"><strong>Google's RAG framing:</strong> Ideal behavior is answer correctly OR say "I don't know" when info is missing. Retrieval quality and sufficient context are central.</li>
                <li class="red"><strong>The new failure mode:</strong> Models sometimes fail to leverage retrieved passages—especially with irrelevant context present.</li>
            </ul>
            <p class="subtext">The problem moved from retrieval accuracy to end-to-end grounding and utilization.</p>
        </div>

        <!-- SLIDE: Multi-Agent Errors -->
        <div class="slide slide-list">
            <span class="topic-tag red">Multi-Agent</span>
            <h2>Multi-Agent Errors: Coordination Became the New Failure Surface</h2>
            <ul>
                <li class="red"><strong>Multi-agent systems scaled in 2025.</strong> But coordination errors emerged as a new class of issues.</li>
                <li class="red"><strong>Survey work documents open challenges:</strong> Collaboration mechanisms and coordination structures are not solved problems.</li>
                <li class="red"><strong>More agents = more risk vectors:</strong> Contradiction risk. Duplication risk. Error propagation risk.</li>
                <li class="red"><strong>The tradeoff:</strong> Parallelism and coverage increase, but so does coordination overhead—unless explicitly engineered.</li>
            </ul>
            <p class="subtext">Actionable: Design coordination protocols. Don't assume agents will self-organize correctly.</p>
        </div>

        <!-- SLIDE: Debugging -->
        <div class="slide slide-list">
            <span class="topic-tag red">Debugging</span>
            <h2>Debugging: The Hardest Day-to-Day Challenge</h2>
            <ul>
                <li class="red"><strong>This is where all the challenges compound.</strong> Debugging became painful because failures come from trajectories, not single outputs.</li>
                <li class="red"><strong>Without evals, debugging is reactive.</strong> Teams wait for complaints, reproduce manually, fix, and hope nothing else regressed.</li>
                <li class="red"><strong>OpenTelemetry published agent observability conventions:</strong> Standardized metrics, traces, logs so teams can integrate solutions and compare across frameworks.</li>
                <li class="red"><strong>AgentOps paper frames observability needs:</strong> Developers, testers, SREs all need different views into the same system.</li>
            </ul>
            <p class="subtext">If you can't trace what the system did, you don't control it. In 2025, people stopped pretending otherwise.</p>
        </div>

        <!-- SLIDE: Challenges Takeaways -->
        <div class="slide slide-list">
            <h2 class="red">Challenges: Key Takeaways</h2>
            <ul>
                <li class="red"><strong>These challenges are predictable.</strong> More capability = more failure modes. Design for them upfront.</li>
                <li class="red"><strong>Hallucinations are now operational.</strong> Verify actions in target systems. Don't trust self-reports.</li>
                <li class="red"><strong>Think in success rates, not single runs.</strong> Product reliability depends on consistency across trials.</li>
                <li class="red"><strong>Build human gates before irreversible actions.</strong> Confirmation steps are a feature.</li>
                <li class="red"><strong>Invest in observability early.</strong> If you can't trace trajectories, you can't debug agents.</li>
            </ul>
        </div>


# Index des Labs et Exercices Pratiques

Ce document r√©pertorie tous les labs et exercices pratiques du livre, organis√©s par partie.

---

## Partie 1 : Vision, panorama et mod√®les mentaux

### Exercice 1 : Analyse de cas d'usage
- **Objectif** : Formuler un cas d'usage LLM complet
- **Comp√©tences** : Analyse m√©tier, d√©finition de m√©triques
- **Localisation** : [Partie 1, Section 1.5](./partie-01/README.md#15-exercices-pratiques)

### Exercice 2 : Formuler des prompts
- **Objectif** : √âcrire des prompts efficaces pour diff√©rentes t√¢ches
- **Comp√©tences** : Prompt engineering
- **Localisation** : [Partie 1, Section 1.5](./partie-01/README.md#15-exercices-pratiques)

### Exercice 3 : Estimation de ressources
- **Objectif** : Calculer les besoins en m√©moire GPU
- **Comp√©tences** : Dimensionnement infrastructure
- **Localisation** : [Partie 1, Section 1.5](./partie-01/README.md#15-exercices-pratiques)

---

## Partie 2 : Fondations math√©matiques

### Lab 1 : Impl√©mentation de cross-entropy
- **Objectif** : Impl√©menter la fonction de loss from scratch
- **Comp√©tences** : NumPy, PyTorch, math√©matiques
- **Localisation** : [Partie 2, Section 2.6](./partie-02/README.md#26-exercices-pratiques)
- **Dur√©e estim√©e** : 1h

### Lab 2 : Visualisation de paysages de perte
- **Objectif** : Visualiser la surface de loss pour comprendre l'optimisation
- **Comp√©tences** : Matplotlib, optimisation
- **Localisation** : [Partie 2, Section 2.6](./partie-02/README.md#26-exercices-pratiques)
- **Dur√©e estim√©e** : 1-2h

### Lab 3 : Comparaison d'optimiseurs
- **Objectif** : Comparer SGD, Adam et AdamW
- **Comp√©tences** : PyTorch, optimisation
- **Localisation** : [Partie 2, Section 2.6](./partie-02/README.md#26-exercices-pratiques)
- **Dur√©e estim√©e** : 2-3h

---

## Partie 3 : Bases de deep learning

### Lab 1 : Character-level language model
- **Objectif** : Construire un LM simple pr√©disant le caract√®re suivant
- **Comp√©tences** : PyTorch, RNN/LSTM
- **Localisation** : [Partie 3, Section 3.5](./partie-03/README.md#35-labs--construire-un-mod√®le-de-langage-simple)
- **Dur√©e estim√©e** : 3-4h

### Lab 2 : Subword language model avec BPE
- **Objectif** : Entra√Æner un tokenizer BPE et un mod√®le LSTM
- **Comp√©tences** : Tokenization, LSTM
- **Localisation** : [Partie 3, Section 3.5](./partie-03/README.md#35-labs--construire-un-mod√®le-de-langage-simple)
- **Dur√©e estim√©e** : 4-5h

---

## Partie 4 : Architectures modernes

### Lab 1 : Impl√©menter un Transformer minimal
- **Objectif** : Coder un Transformer from scratch
- **Comp√©tences** : Architecture Transformer, attention
- **Localisation** : [Partie 4, Section 4.6](./partie-04/README.md#46-labs-pratiques)
- **Dur√©e estim√©e** : 5-8h

### Lab 2 : Comparer dense vs MoE
- **Objectif** : Mesurer latence, m√©moire et qualit√©
- **Comp√©tences** : MoE, benchmarking
- **Localisation** : [Partie 4, Section 4.6](./partie-04/README.md#46-labs-pratiques)
- **Dur√©e estim√©e** : 3-4h

### Lab 3 : Benchmarker FlashAttention
- **Objectif** : Comparer vitesse attention standard vs FlashAttention
- **Comp√©tences** : Optimisation, profiling
- **Localisation** : [Partie 4, Section 4.6](./partie-04/README.md#46-labs-pratiques)
- **Dur√©e estim√©e** : 2-3h

---

## Partie 5 : Donn√©es

### Lab 1 : Pipeline de d√©duplication
- **Objectif** : Impl√©menter d√©duplication exacte et near-duplicate
- **Comp√©tences** : MinHash, traitement de donn√©es
- **Localisation** : [Partie 5, Section 5.7](./partie-05/README.md#57-labs-pratiques)
- **Dur√©e estim√©e** : 4-6h

### Lab 2 : Analyse de distributions
- **Objectif** : Analyser et visualiser un corpus
- **Comp√©tences** : Statistiques, visualisation
- **Localisation** : [Partie 5, Section 5.7](./partie-05/README.md#57-labs-pratiques)
- **Dur√©e estim√©e** : 2-3h

### Lab 3 : Construire un m√©lange
- **Objectif** : Cr√©er un dataset mixte et sharder
- **Comp√©tences** : Data engineering
- **Localisation** : [Partie 5, Section 5.7](./partie-05/README.md#57-labs-pratiques)
- **Dur√©e estim√©e** : 3-4h

---

## Partie 6 : Pr√©-training

### Lab : Entra√Ænement complet d'un mod√®le small
- **Objectif** : Entra√Æner un mod√®le 125M from scratch avec FSDP
- **Comp√©tences** : Entra√Ænement distribu√©, monitoring
- **Localisation** : [Partie 6, Section 6.6](./partie-06/README.md#66-lab--entra√Ænement-complet-dun-mod√®le-small)
- **Dur√©e estim√©e** : 1-2 jours (+ compute)
- **Ressources** : 4-8 GPUs recommand√©s

---

## Partie 7 : Post-training et alignement

### Lab 1 : SFT sur un dataset synth√©tique
- **Objectif** : Fine-tuner avec des donn√©es g√©n√©r√©es
- **Comp√©tences** : SFT, g√©n√©ration synth√©tique
- **Localisation** : [Partie 7, Section 7.6](./partie-07/README.md#76-labs-pratiques)
- **Dur√©e estim√©e** : 1 jour

### Lab 2 : Comparer DPO vs PPO
- **Objectif** : Entra√Æner et comparer les deux approches
- **Comp√©tences** : DPO, PPO, √©valuation
- **Localisation** : [Partie 7, Section 7.6](./partie-07/README.md#76-labs-pratiques)
- **Dur√©e estim√©e** : 2-3 jours

### Lab 3 : Politique de refus
- **Objectif** : Impl√©menter des refus appropri√©s
- **Comp√©tences** : S√©curit√©, training-free alignment
- **Localisation** : [Partie 7, Section 7.6](./partie-07/README.md#76-labs-pratiques)
- **Dur√©e estim√©e** : 1 jour

---

## Partie 8 : Outils, agents et RAG

### Lab 1 : Pipeline RAG complet
- **Objectif** : Construire un syst√®me RAG de bout en bout
- **Comp√©tences** : Embeddings, retrieval, g√©n√©ration
- **Localisation** : [Partie 8, Section 8.5](./partie-08/README.md#85-labs-pratiques)
- **Dur√©e estim√©e** : 1-2 jours

### Lab 2 : Agent multi-outils
- **Objectif** : Cr√©er un agent utilisant plusieurs outils
- **Comp√©tences** : Function calling, orchestration
- **Localisation** : [Partie 8, Section 8.5](./partie-08/README.md#85-labs-pratiques)
- **Dur√©e estim√©e** : 1 jour

### Lab 3 : Syst√®me avec m√©moire
- **Objectif** : Chatbot avec m√©moire persistante
- **Comp√©tences** : Long-term memory, personnalisation
- **Localisation** : [Partie 8, Section 8.5](./partie-08/README.md#85-labs-pratiques)
- **Dur√©e estim√©e** : 1 jour

---

## Partie 9 : Inference et optimisation

### Lab 1 : Benchmarker vLLM vs TGI
- **Objectif** : Comparer performance des engines
- **Comp√©tences** : Benchmarking, serving
- **Localisation** : [Partie 9, Section 9.5](./partie-09/README.md#95-labs-pratiques)
- **Dur√©e estim√©e** : 0.5 jour

### Lab 2 : Speculative decoding
- **Objectif** : Impl√©menter et mesurer le speedup
- **Comp√©tences** : Optimisation inference
- **Localisation** : [Partie 9, Section 9.5](./partie-09/README.md#95-labs-pratiques)
- **Dur√©e estim√©e** : 1-2 jours

### Lab 3 : Quantization et √©valuation
- **Objectif** : Quantifier et √©valuer la perte de qualit√©
- **Comp√©tences** : Compression, benchmarking
- **Localisation** : [Partie 9, Section 9.5](./partie-09/README.md#95-labs-pratiques)
- **Dur√©e estim√©e** : 1 jour

---

## Partie 10 : D√©ploiement et LLMOps

### Lab 1 : API compl√®te avec monitoring
- **Objectif** : D√©ployer une API production-ready
- **Comp√©tences** : FastAPI, Prometheus, Grafana
- **Localisation** : [Partie 10, Section 10.6](./partie-10/README.md#106-labs-pratiques)
- **Dur√©e estim√©e** : 2-3 jours

### Lab 2 : D√©tection de d√©rive
- **Objectif** : D√©tecter automatiquement le drift
- **Comp√©tences** : Monitoring, ML ops
- **Localisation** : [Partie 10, Section 10.6](./partie-10/README.md#106-labs-pratiques)
- **Dur√©e estim√©e** : 1 jour

### Lab 3 : Optimisation des co√ªts
- **Objectif** : Impl√©menter caching et cascade
- **Comp√©tences** : Optimisation √©conomique
- **Localisation** : [Partie 10, Section 10.6](./partie-10/README.md#106-labs-pratiques)
- **Dur√©e estim√©e** : 1 jour

---

## R√©capitulatif par niveau de difficult√©

### D√©butant (1-2 jours)
- Partie 1 : Tous les exercices
- Partie 2 : Lab 1 (Cross-entropy)
- Partie 5 : Lab 2 (Analyse de distributions)
- Partie 9 : Lab 1 (Benchmarking)

### Interm√©diaire (2-5 jours)
- Partie 2 : Labs 2-3
- Partie 3 : Lab 1 (Char-level LM)
- Partie 4 : Lab 3 (FlashAttention)
- Partie 5 : Labs 1, 3
- Partie 7 : Lab 3 (Refus)
- Partie 8 : Labs 2-3
- Partie 9 : Lab 3 (Quantization)
- Partie 10 : Labs 2-3

### Avanc√© (5+ jours)
- Partie 3 : Lab 2 (Subword LM)
- Partie 4 : Labs 1-2
- Partie 6 : Lab complet (Pr√©-training)
- Partie 7 : Labs 1-2
- Partie 8 : Lab 1 (RAG)
- Partie 9 : Lab 2 (Speculative decoding)
- Partie 10 : Lab 1 (API compl√®te)

---

## Parcours sugg√©r√©s

### Parcours Research (focus qualit√© mod√®le)
1. Partie 2 : Tous les labs
2. Partie 3 : Labs 1-2
3. Partie 4 : Lab 1 (Transformer)
4. Partie 6 : Pr√©-training complet
5. Partie 7 : Labs 1-2 (SFT, DPO/PPO)

### Parcours Engineering (focus d√©ploiement)
1. Partie 5 : Tous les labs (donn√©es)
2. Partie 8 : Tous les labs (RAG, agents)
3. Partie 9 : Tous les labs (optimisation)
4. Partie 10 : Tous les labs (production)

### Parcours Full Stack (complet)
Suivre tous les labs dans l'ordre des parties.

**Dur√©e totale estim√©e** : 6-8 semaines √† temps plein

---

## Resources compl√©mentaires pour les labs

### Datasets
- [Hugging Face Datasets](https://huggingface.co/datasets)
- [The Pile](https://pile.eleuther.ai/)
- [OpenWebText](https://openwebtext2.readthedocs.io/)

### Compute
- [Google Colab](https://colab.research.google.com/) - Free GPUs
- [Kaggle Kernels](https://www.kaggle.com/) - Free GPUs/TPUs
- [Lambda Labs](https://lambdalabs.com/) - Cloud GPUs
- [RunPod](https://www.runpod.io/) - Affordable GPU rental

### Outils de monitoring
- [Weights & Biases](https://wandb.ai/)
- [TensorBoard](https://www.tensorflow.org/tensorboard)
- [MLflow](https://mlflow.org/)

---

**Bon apprentissage et bonne pratique !** üöÄ
